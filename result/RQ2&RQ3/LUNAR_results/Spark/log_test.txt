Start to parse logs
[PARAM]: pad_query: False
[PARAM]: add_skip_sim: False
[PARAM]: cluster_method: TopKToken
[PARAM]: cluster_topk: 3
[PARAM]: sample_method: lcu_sampling
[PARAM]: lcu_sample_size: 3
[PARAM]: lcu_lamb: 0.6
Save dir: ./saved_results/LUNAR-single
Input dir: ././datasets/Spark
Output dir: ./saved_results/LUNAR-single/Spark
# Variable Examples: 
- `/var/www/html/xxx` -> `{directory}`
- `/var/lib/zookeeper/log.000000001` -> `{file}`
- `blk_-1234567832142354978` -> `{blk_id}`
- `com.huawei.health.manager.Service@32a6bf8` -> `{api}`
- `2017-07-02 15:46:40.536` -> `{time}`
- `192.168.0.1:8008` -> `{ip_or_url}`

======================== Prompt ========================
VarExam
# Basic Requirements:
- I will provide multiple log messages, each delimited by backticks.
- You must identify and extract all dynamic variables in each log with {placeholder} and output static log templates.
- Identify the semantics of variables and compare the differences between logs to identify potential dynamic variables if they belong to the same template.
- Preserve any dynamic variables already marked by `<*>` or `{placeholder}`.
- Pay attention to the slightly different strings among logs, which have high possibility to be dynamic variable.
- Do not convert non-variables, especially when only one log is presented in the group.
# Advices on variables:
- Common variables: numbers, IP addresses, URLs, file paths, directories, hex values, usernames, etc.
- Full directory with filename, complex url with server address or domain should be recognize as one variable.
# Advices on non-variables:
- Error messages/types, java exceptions, detailed commands or interrupted messages are NOT dynamic variables as they contain important information.
- Specific actions or status words are NOT dynamic variables.
# Variable Examples: 
- `/var/www/html/xxx` -> `{directory}`
- `/var/lib/zookeeper/log.000000001` -> `{file}`
- `blk_-1234567832142354978` -> `{blk_id}`
- `com.huawei.health.manager.Service@32a6bf8` -> `{api}`
- `2017-07-02 15:46:40.536` -> `{time}`
- `192.168.0.1:8008` -> `{ip_or_url}`
# Output Constraints: 
- For each log line, output corresponding log template starting with LogTemplate[idx], no other line break. 
- Each input log's template is delimited by backticks. 

======================== Prompt ========================
Parsing file: ././datasets/Spark/Spark_full.log_structured.csv
Clustering load data
Clustering add regex before preprocess
Clustering by log length: 35
Clustering by log length: [425480, 417604, 4063287, 299591, 411359, 1356544, 2378050, 17906, 3903, 6362, 477164, 2650820, 3555397, 207, 33, 635, 5070, 685, 116, 4, 12, 189, 107, 1, 1, 36, 1, 3, 2, 1, 4, 1979, 2, 1, 2561]
--- Finished 2nd Level Clustering by top-3 tokens: 12 clusters, Total/Min/Max: 425480/128/412107 Logs. Last cluster logs: 256
--- Finished 2nd Level Clustering by top-3 tokens: 87 clusters, Total/Min/Max: 417604/102/380270 Logs. Last cluster logs: 422
--- Finished 2nd Level Clustering by top-3 tokens: 20 clusters, Total/Min/Max: 4063287/100/2149959 Logs. Last cluster logs: 398
--- Finished 2nd Level Clustering by top-3 tokens: 14 clusters, Total/Min/Max: 299591/104/281319 Logs. Last cluster logs: 343
--- Finished 2nd Level Clustering by top-3 tokens: 13 clusters, Total/Min/Max: 411359/175/396911 Logs. Last cluster logs: 406
--- Finished 2nd Level Clustering by top-3 tokens: 19 clusters, Total/Min/Max: 1356544/119/412149 Logs. Last cluster logs: 349
--- Finished 2nd Level Clustering by top-3 tokens: 6 clusters, Total/Min/Max: 2378050/94/2149959 Logs. Last cluster logs: 94
--- Finished 2nd Level Clustering by top-3 tokens: 11 clusters, Total/Min/Max: 17906/149/11698 Logs. Last cluster logs: 309
--- Finished 2nd Level Clustering by top-3 tokens: 6 clusters, Total/Min/Max: 3903/97/2299 Logs. Last cluster logs: 97
--- Finished 2nd Level Clustering by top-3 tokens: 8 clusters, Total/Min/Max: 6362/49/2228 Logs. Last cluster logs: 49
--- Finished 2nd Level Clustering by top-3 tokens: 4 clusters, Total/Min/Max: 477164/246/475836 Logs. Last cluster logs: 246
--- Finished 2nd Level Clustering by top-3 tokens: 5 clusters, Total/Min/Max: 2650820/142/2625700 Logs. Last cluster logs: 2158
--- Finished 2nd Level Clustering by top-3 tokens: 5 clusters, Total/Min/Max: 3555397/87/2146621 Logs. Last cluster logs: 87
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 207/80/127 Logs. Last cluster logs: 80
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 33/33/33 Logs. Last cluster logs: 33
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 635/132/503 Logs. Last cluster logs: 132
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 5070/107/4963 Logs. Last cluster logs: 107
--- Finished 2nd Level Clustering by top-3 tokens: 3 clusters, Total/Min/Max: 685/23/378 Logs. Last cluster logs: 23
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 116/6/110 Logs. Last cluster logs: 6
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 4/4/4 Logs. Last cluster logs: 4
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 12/12/12 Logs. Last cluster logs: 12
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 189/189/189 Logs. Last cluster logs: 189
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 107/4/103 Logs. Last cluster logs: 4
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 36/36/36 Logs. Last cluster logs: 36
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 3/3/3 Logs. Last cluster logs: 3
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 2/2/2 Logs. Last cluster logs: 2
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 4/4/4 Logs. Last cluster logs: 4
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1979/1979/1979 Logs. Last cluster logs: 1979
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 2/2/2 Logs. Last cluster logs: 2
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 2561/2561/2561 Logs. Last cluster logs: 2561
Clustering (min_cluster_size=100) by length and 1st 3 tokens: 239 clusters
Clustering results: [2378, 2378, 2359, 1828, 1828, 204, 204, 146, 1664, 128, 412107, 256, 2750, 142, 2561, 2561, 2561, 330, 333, 347, 208, 6176, 156, 184, 142, 156, 142, 142, 142, 142, 178, 114, 188, 114, 132, 106, 116, 116, 116, 174, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 117, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 117, 116, 116, 116, 116, 116, 116, 116, 117, 116, 116, 116, 116, 117, 122, 102, 138, 117, 130, 103, 138, 103, 103, 103, 139, 103, 103, 134, 111, 9166, 777, 110, 380270, 154, 131, 422, 2289, 2359, 2149959, 1823, 717, 108, 107, 113, 115, 380, 100, 100, 138, 1895245, 101, 2682, 2268, 2353, 1932, 398, 9926, 2353, 281319, 1886, 1907, 142, 218, 190, 293, 104, 353, 353, 204, 343, 2378, 2353, 2000, 2554, 2561, 336, 175, 324, 396911, 291, 870, 200, 406, 2606, 4859, 2289, 281073, 2623, 2561, 693, 207, 714, 119, 353, 198, 412149, 412107, 3504, 2682, 227317, 141, 349, 2149959, 383, 171, 126, 227317, 94, 202, 202, 462, 2610, 865, 149, 277, 11698, 150, 982, 309, 218, 685, 2299, 440, 164, 97, 763, 845, 229, 2228, 466, 244, 1538, 49, 475836, 471, 611, 246, 2625700, 142, 408, 22412, 2158, 1105614, 282226, 2146621, 20849, 87, 127, 80, 33, 503, 132, 4963, 107, 284, 378, 23, 110, 6, 4, 12, 189, 103, 4, 1, 1, 36, 1, 3, 2, 1, 4, 1979, 2, 1, 2561]
Iteration 0
Sample 3 from current logs bucket: ID: 200, Len: 13, Bucket Size: 2625700, Total Buckets: 239
Sampling from 286817 logs, Sim Level: 5, MaxSim to anchor: 0.6667. Anchor: `Times: total = 4458, boot = 536, init = 83, finish = 3839`, MaxSim Log: `Times: total = 536, boot = -82, init = 83, finish = 535`.
	============  Query  ====================
	Log[1]: `Times: total = 4458, boot = 536, init = 83, finish = 3839`
	Log[2]: `Times: total = 950, boot = -81, init = 83, finish = 948`
	Log[3]: `Times: total = 165, boot = -77, init = 83, finish = 159`
	============ Response ====================
LogTemplate[1]: `Times: total = {total}, boot = {boot}, init = {init}, finish = {finish}`
LogTemplate[2]: `Times: total = {total}, boot = {boot}, init = {init}, finish = {finish}`
LogTemplate[3]: `Times: total = {total}, boot = {boot}, init = {init}, finish = {finish}`
	============ PostProcess ====================
	Post Template: `Times: total = <*> boot = <*> init = <*> finish = <*>`
	Post Template: `Times: total = <*> boot = <*> init = <*> finish = <*>`
	Post Template: `Times: total = <*> boot = <*> init = <*> finish = <*>`
	============ Aggregate ====================
	Aggregated Template:  Times: total = <*> boot = <*> init = <*> finish = <*>
[UpdateBucket] Logs: This iter found: 2625700, total: 2625700/16075117, remain: 13449417. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 2650820 -> 25120, remain buckets: 238
Update Success: Time for one update logs: 51.93512201309204, template `Times: total = <*> boot = <*> init = <*> finish = <*>`
========================================================================================


Iteration 1
Sample 3 from current logs bucket: ID: 101, Len: 4, Bucket Size: 2149959, Total Buckets: 239
Sampling from 641355 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Got assigned task 0`, MaxSim Log: `Got assigned task 1`.
	============  Query  ====================
	Log[1]: `Got assigned task 0`
	Log[2]: `Got assigned task 723046`
	Log[3]: `Got assigned task 590140`
	============ Response ====================
LogTemplate[1]: `Got assigned task {task_id}`  
LogTemplate[2]: `Got assigned task {task_id}`  
LogTemplate[3]: `Got assigned task {task_id}`  
	============ PostProcess ====================
	Post Template: `Got assigned task <*>`
	Post Template: `Got assigned task <*>`
	Post Template: `Got assigned task <*>`
	============ Aggregate ====================
	Aggregated Template:  Got assigned task <*>
[UpdateBucket] Logs: This iter found: 2149959, total: 4775659/16075117, remain: 11299458. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 4063287 -> 1913328, remain buckets: 237
Update Success: Time for one update logs: 34.320773124694824, template `Got assigned task <*>`
========================================================================================


Iteration 2
Sample 3 from current logs bucket: ID: 165, Len: 8, Bucket Size: 2149959, Total Buckets: 239
Sampling from 1738958 logs, Sim Level: 5, MaxSim to anchor: 0.8750. Anchor: `Running task 0.0 in stage 0.0 (TID 0)`, MaxSim Log: `Running task 6.0 in stage 0.0 (TID 0)`.
	============  Query  ====================
	Log[1]: `Running task 0.0 in stage 0.0 (TID 0)`
	Log[2]: `Running task 9.0 in stage 208.0 (TID 8337)`
	Log[3]: `Running task 30.0 in stage 318.0 (TID 13436)`
	============ Response ====================
LogTemplate[1]: `Running task {task_id} in stage {stage_id} (TID {tid})`
	============ PostProcess ====================
	Post Template: `Running task <*> in stage <*> (TID <*>)`
	Post Template: `Running task <*> in stage <*> (TID <*>)`
	Post Template: `Running task <*> in stage <*> (TID <*>)`
	============ Aggregate ====================
	Aggregated Template:  Running task <*> in stage <*> (TID <*>)
[UpdateBucket] Logs: This iter found: 2149959, total: 6925618/16075117, remain: 9149499. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 2378050 -> 228091, remain buckets: 236
Update Success: Time for one update logs: 37.30880093574524, template `Running task <*> in stage <*> (TID <*>)`
========================================================================================


Iteration 3
Sample 3 from current logs bucket: ID: 207, Len: 14, Bucket Size: 2146621, Total Buckets: 239
Sampling from 1911526 logs, Sim Level: 7, MaxSim to anchor: 0.8667. Anchor: `Finished task 1.0 in stage 0.0 (TID 1). 14372091 bytes result sent to driver`, MaxSim Log: `Finished task 1.0 in stage 0.0 (TID 1). 2668 bytes result sent to driver`.
	============  Query  ====================
	Log[1]: `Finished task 1.0 in stage 0.0 (TID 1). 14372091 bytes result sent to driver`
	Log[2]: `Finished task 10.0 in stage 692.0 (TID 28450). 2364 bytes result sent to driver`
	Log[3]: `Finished task 21.0 in stage 208.0 (TID 8581). 2241 bytes result sent to driver`
	============ Response ====================
LogTemplate[1]: `Finished task {task_id} in stage {stage_id} (TID {task_instance_id}). {bytes} bytes result sent to driver`
	============ PostProcess ====================
	Post Template: `Finished task <*> in stage <*> (TID <*>). <*> bytes result sent to driver`
	Post Template: `Finished task <*> in stage <*> (TID <*>). <*> bytes result sent to driver`
	Post Template: `Finished task <*> in stage <*> (TID <*>). <*> bytes result sent to driver`
	============ Aggregate ====================
	Aggregated Template:  Finished task <*> in stage <*> (TID <*>). <*> bytes result sent to driver
[UpdateBucket] Logs: This iter found: 2146621, total: 9072239/16075117, remain: 7002878. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 3555397 -> 1408776, remain buckets: 235
Update Success: Time for one update logs: 48.274831771850586, template `Finished task <*> in stage <*> (TID <*>). <*> bytes result sent to driver`
========================================================================================


Iteration 4
Sample 3 from current logs bucket: ID: 112, Len: 4, Bucket Size: 1895245, Total Buckets: 239
Sampling from 246285 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Found block rdd_2_9 locally`, MaxSim Log: `Found block rdd_2_5 locally`.
	============  Query  ====================
	Log[1]: `Found block rdd_2_9 locally`
	Log[2]: `Found block rdd_754_20 locally`
	Log[3]: `Found block rdd_10691_24 locally`
	============ Response ====================
LogTemplate[1]: `Found block rdd_<*> locally`
LogTemplate[2]: `Found block rdd_<*> locally`
LogTemplate[3]: `Found block rdd_<*> locally`
	============ PostProcess ====================
	Post Template: `Found block <*> locally`
	Post Template: `Found block <*> locally`
	Post Template: `Found block <*> locally`
	============ Aggregate ====================
	Aggregated Template:  Found block <*> locally
[UpdateBucket] Logs: This iter found: 1895245, total: 10967484/16075117, remain: 5107633. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 1913328 -> 18083, remain buckets: 234
Update Success: Time for one update logs: 27.269602060317993, template `Found block <*> locally`
========================================================================================


Iteration 5
Sample 3 from current logs bucket: ID: 205, Len: 14, Bucket Size: 1105614, Total Buckets: 239
Sampling from 750759 logs, Sim Level: 9, MaxSim to anchor: 0.9286. Anchor: `Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)`, MaxSim Log: `Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 193.2 KB)`.
	============  Query  ====================
	Log[1]: `Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 3.7 KB)`
	Log[2]: `Block rdd_3045_17 stored as bytes in memory (estimated size 354.0 B, free 9.0 MB)`
	Log[3]: `Block broadcast_6_piece210 stored as bytes in memory (estimated size 4.0 MB, free 4.0 GB)`
	============ Response ====================
LogTemplate[1]: `Block {block_name} stored as bytes in memory (estimated size {size}, free {free_space})`  
LogTemplate[2]: `Block {block_name} stored as bytes in memory (estimated size {size}, free {free_space})`  
LogTemplate[3]: `Block {block_name} stored as bytes in memory (estimated size {size}, free {free_space})`  
	============ PostProcess ====================
	Post Template: `Block <*> stored as bytes in memory (estimated size <*> free <*>)`
	Post Template: `Block <*> stored as bytes in memory (estimated size <*> free <*>)`
	Post Template: `Block <*> stored as bytes in memory (estimated size <*> free <*>)`
	============ Aggregate ====================
	Aggregated Template:  Block <*> stored as bytes in memory (estimated size <*> free <*>)
[UpdateBucket] Logs: This iter found: 1105614, total: 12073098/16075117, remain: 4002019. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 1408776 -> 303162, remain buckets: 233
Update Success: Time for one update logs: 26.847688913345337, template `Block <*> stored as bytes in memory (estimated size <*> free <*>)`
========================================================================================


Iteration 6
Sample 3 from current logs bucket: ID: 196, Len: 12, Bucket Size: 475836, Total Buckets: 239
Sampling from 475793 logs, Sim Level: 7, MaxSim to anchor: 0.8462. Anchor: `Added broadcast_0_piece0 in memory on 10.10.34.23:48030 (size: 21.4 KB, free: 26.4 GB)`, MaxSim Log: `Added broadcast_0_piece0 in memory on 10.10.34.31:54234 (size: 21.4 KB, free: 26.4 GB)`.
	============  Query  ====================
	Log[1]: `Added broadcast_0_piece0 in memory on 10.10.34.23:48030 (size: 21.4 KB, free: 26.4 GB)`
	Log[2]: `Added broadcast_101_piece0 in memory on mesos-slave-09:47971 (size: 2.2 KB, free: 2.6 GB)`
	Log[3]: `Added broadcast_93_piece0 in memory on mesos-slave-18:49085 (size: 5.6 KB, free: 27.8 GB)`
	============ Response ====================
LogTemplate[1]: `Added broadcast_{*}_piece0 in memory on {ip_or_url}:{*} (size: {*}, free: {*})`  
LogTemplate[2]: `Added broadcast_{*}_piece0 in memory on {ip_or_url}:{*} (size: {*}, free: {*})`  
LogTemplate[3]: `Added broadcast_{*}_piece0 in memory on {ip_or_url}:{*} (size: {*}, free: {*})`  
	============ PostProcess ====================
	Post Template: `Added <*> in memory on <*> (size: <*> free: <*>)`
	Post Template: `Added <*> in memory on <*> (size: <*> free: <*>)`
	Post Template: `Added <*> in memory on <*> (size: <*> free: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Added <*> in memory on <*> (size: <*> free: <*>)
[UpdateBucket] Logs: This iter found: 437630, total: 12510728/16075117, remain: 3564389. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 477164 -> 39534, remain buckets: 233
Update Success: Time for one update logs: 8.659637928009033, template `Added <*> in memory on <*> (size: <*> free: <*>)`
========================================================================================


Iteration 7
Sample 3 from current logs bucket: ID: 158, Len: 7, Bucket Size: 412149, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `File Output Committer Algorithm version is 1`
	============ Response ====================
LogTemplate[1]: `File Output Committer Algorithm version is {version}`
	============ PostProcess ====================
	Post Template: `File Output Committer Algorithm version is <*>`
	============ Aggregate ====================
	Aggregated Template:  File Output Committer Algorithm version is <*>
[UpdateBucket] Logs: This iter found: 412149, total: 12922877/16075117, remain: 3152240. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 1356544 -> 944395, remain buckets: 232
Update Success: Time for one update logs: 8.467563152313232, template `File Output Committer Algorithm version is <*>`
========================================================================================


Iteration 8
Sample 3 from current logs bucket: ID: 10, Len: 2, Bucket Size: 412107, Total Buckets: 239
Sampling from 412106 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `attempt_201706101524_0006_m_000009_128: Committed`, MaxSim Log: `attempt_201706101524_0006_m_000001_120: Committed`.
	============  Query  ====================
	Log[1]: `attempt_201706101524_0006_m_000009_128: Committed`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_m_{task_id}_{value}: Committed`
	============ PostProcess ====================
	Post Template: `<*>: Committed`
	============ Aggregate ====================
	Aggregated Template:  <*>: Committed
[UpdateBucket] Logs: This iter found: 412107, total: 13334984/16075117, remain: 2740133. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 425480 -> 13373, remain buckets: 231
Update Success: Time for one update logs: 5.681410074234009, template `<*>: Committed`
========================================================================================


Iteration 9
Sample 3 from current logs bucket: ID: 159, Len: 7, Bucket Size: 412107, Total Buckets: 239
Sampling from 412106 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`, MaxSim Log: `Saved output of task 'attempt_201706101524_0006_m_000003_122' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000003`.
	============  Query  ====================
	Log[1]: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`
	Log[2]: `Saved output of task 'attempt_201706082013_8988_m_000003_359562' to hdfs://10.10.34.11:9000/pjhe/test/124/_temporary/0/task_201706082013_8988_m_000003`
	Log[3]: `Saved output of task 'attempt_201706091043_0432_m_000017_17337' to hdfs://10.10.34.11:9000/pjhe/test/41/_temporary/0/task_201706091043_0432_m_000017`
	============ Response ====================
LogTemplate[1]: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
LogTemplate[2]: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
LogTemplate[3]: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
	============ PostProcess ====================
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`
	============ Aggregate ====================
	Aggregated Template:  Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>
[UpdateBucket] Logs: This iter found: 0, total: 13334984/16075117, remain: 2740133. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 944395 -> 944395, remain buckets: 231
Update failed: Template can not match logs `Saved output of task '<task_id>' to hdfs://<ip_address>:<port>/pjhe/test/<number>/_temporary/0/task_<task_id>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 159, Len: 7, Bucket Size: 412107, Total Buckets: 239
Sampling from 412106 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`, MaxSim Log: `Saved output of task 'attempt_201706101524_0006_m_000003_122' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000003`.
	============  Query  ====================
	Log[1]: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`
	Log[2]: `Saved output of task 'attempt_201706091556_1740_m_000004_77564' to hdfs://10.10.34.11:9000/pjhe/test/6/_temporary/0/task_201706091556_1740_m_000004`
	Log[3]: `Saved output of task 'attempt_201706091731_3761_m_001653_163189' to hdfs://10.10.34.11:9000/pjhe/test/18/_temporary/0/task_201706091731_3761_m_001653`
	============ Response ====================
LogTemplate[1]: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num1>/_temporary/0/task_<task_id>`
LogTemplate[2]: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num2>/_temporary/0/task_<task_id>`
LogTemplate[3]: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num3>/_temporary/0/task_<task_id>`
	============ PostProcess ====================
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num1>/_temporary/0/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num2>/_temporary/0/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num3>/_temporary/0/task_<task_id>`
	============ Aggregate ====================
	Aggregated Template:  Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num1>/_temporary/0/task_<task_id>
[UpdateBucket] Logs: This iter found: 0, total: 13334984/16075117, remain: 2740133. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 944395 -> 944395, remain buckets: 231
Update failed: Template can not match logs `Saved output of task '<task_id>' to hdfs://<ip_address>:9000/pjhe/test/<num1>/_temporary/0/task_<task_id>`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 159, Len: 7, Bucket Size: 412107, Total Buckets: 239
Sampling from 412106 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`, MaxSim Log: `Saved output of task 'attempt_201706101524_0006_m_000003_122' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000003`.
	============  Query  ====================
	Log[1]: `Saved output of task 'attempt_201706101524_0006_m_000001_120' to hdfs://10.10.34.11:9000/pjhe/test/1/_temporary/0/task_201706101524_0006_m_000001`
	Log[2]: `Saved output of task 'attempt_201706081746_2150_m_000029_86025' to hdfs://10.10.34.11:9000/pjhe/test/11/_temporary/0/task_201706081746_2150_m_000029`
	Log[3]: `Saved output of task 'attempt_201706082218_22545_m_000015_901853' to hdfs://10.10.34.11:9000/pjhe/test/571/_temporary/0/task_201706082218_22545_m_000015`
	============ Response ====================
LogTemplate[1]: `Saved output of task '{task_id}' to {hdfs_path}`
LogTemplate[2]: `Saved output of task '{task_id}' to {hdfs_path}`
LogTemplate[3]: `Saved output of task '{task_id}' to {hdfs_path}`
	============ PostProcess ====================
	Post Template: `Saved output of task <*> to <*>`
	Post Template: `Saved output of task <*> to <*>`
	Post Template: `Saved output of task <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  Saved output of task <*> to <*>
[UpdateBucket] Logs: This iter found: 412107, total: 13747091/16075117, remain: 2328026. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 944395 -> 532288, remain buckets: 230
Update Success: Time for one update logs: 8.10312819480896, template `Saved output of task <*> to <*>`
========================================================================================


Iteration 10
Sample 3 from current logs bucket: ID: 141, Len: 6, Bucket Size: 396911, Total Buckets: 239
Sampling from 246287 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Partition rdd_2_3 not found, computing it`, MaxSim Log: `Partition rdd_2_5 not found, computing it`.
	============  Query  ====================
	Log[1]: `Partition rdd_2_3 not found, computing it`
	Log[2]: `Partition rdd_21667_24 not found, computing it`
	Log[3]: `Partition rdd_3154_6 not found, computing it`
	============ Response ====================
LogTemplate[1]: `Partition {rdd_id} not found, computing it`  
LogTemplate[2]: `Partition {rdd_id} not found, computing it`  
LogTemplate[3]: `Partition {rdd_id} not found, computing it`  
	============ PostProcess ====================
	Post Template: `Partition <*> not found, computing it`
	Post Template: `Partition <*> not found, computing it`
	Post Template: `Partition <*> not found, computing it`
	============ Aggregate ====================
	Aggregated Template:  Partition <*> not found, computing it
[UpdateBucket] Logs: This iter found: 396911, total: 14144002/16075117, remain: 1931115. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 411359 -> 14448, remain buckets: 229
Update Success: Time for one update logs: 6.180389881134033, template `Partition <*> not found, computing it`
========================================================================================


Iteration 11
Sample 3 from current logs bucket: ID: 95, Len: 3, Bucket Size: 380270, Total Buckets: 239
Sampling from 7324 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Removing RDD 456`, MaxSim Log: `Removing RDD 237`.
	============  Query  ====================
	Log[1]: `Removing RDD 456`
	Log[2]: `Removing RDD 10401`
	Log[3]: `Removing RDD 12556`
	============ Response ====================
LogTemplate[1]: `Removing RDD {<*>}`
	============ PostProcess ====================
	Post Template: `Removing RDD <*>`
	Post Template: `Removing RDD <*>`
	Post Template: `Removing RDD <*>`
	============ Aggregate ====================
	Aggregated Template:  Removing RDD <*>
[UpdateBucket] Logs: This iter found: 390212, total: 14534214/16075117, remain: 1540903. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 417604 -> 27392, remain buckets: 198
Update Success: Time for one update logs: 5.424633741378784, template `Removing RDD <*>`
========================================================================================


Iteration 12
Sample 3 from current logs bucket: ID: 206, Len: 14, Bucket Size: 282226, Total Buckets: 239
Sampling from 151005 logs, Sim Level: 8, MaxSim to anchor: 0.8667. Anchor: `Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 9.7 KB)`, MaxSim Log: `Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 189.6 KB)`.
	============  Query  ====================
	Log[1]: `Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 9.7 KB)`
	Log[2]: `Block broadcast_12236 stored as values in memory (estimated size 9.5 KB, free 9.1 MB)`
	Log[3]: `Block broadcast_0 stored as values in memory (estimated size 440.0 B, free 440.0 B)`
	============ Response ====================
LogTemplate[1]: `Block broadcast_{value} stored as values in memory (estimated size {size}, free {free})`
	============ PostProcess ====================
	Post Template: `Block <*> stored as values in memory (estimated size <*> free <*>)`
	Post Template: `Block <*> stored as values in memory (estimated size <*> free <*>)`
	Post Template: `Block <*> stored as values in memory (estimated size <*> free <*>)`
	============ Aggregate ====================
	Aggregated Template:  Block <*> stored as values in memory (estimated size <*> free <*>)
[UpdateBucket] Logs: This iter found: 282226, total: 14816440/16075117, remain: 1258677. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 303162 -> 20936, remain buckets: 197
[TemplateDB] Try Merge: `Block <*> stored as values in memory (estimated size <*> free <*>)` | `Block <*> stored as bytes in memory (estimated size <*> free <*>)`
[TemplateDB] Reject Merge, Remain Template: `Block <*> stored as values in memory (estimated size <*> free <*>)`
Update Success: Time for one update logs: 5.566468000411987, template `Block <*> stored as values in memory (estimated size <*> free <*>)`
========================================================================================


Iteration 13
Sample 3 from current logs bucket: ID: 121, Len: 5, Bucket Size: 281319, Total Buckets: 239
Sampling from 22657 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Started reading broadcast variable 1`, MaxSim Log: `Started reading broadcast variable 0`.
	============  Query  ====================
	Log[1]: `Started reading broadcast variable 1`
	Log[2]: `Started reading broadcast variable 7808`
	Log[3]: `Started reading broadcast variable 3634`
	============ Response ====================
LogTemplate[1]: `Started reading broadcast variable {var}`  
LogTemplate[2]: `Started reading broadcast variable {var}`  
LogTemplate[3]: `Started reading broadcast variable {var}`  
	============ PostProcess ====================
	Post Template: `Started reading broadcast variable <*>`
	Post Template: `Started reading broadcast variable <*>`
	Post Template: `Started reading broadcast variable <*>`
	============ Aggregate ====================
	Aggregated Template:  Started reading broadcast variable <*>
[UpdateBucket] Logs: This iter found: 281319, total: 15097759/16075117, remain: 977358. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 299591 -> 18272, remain buckets: 196
Update Success: Time for one update logs: 4.246117115020752, template `Started reading broadcast variable <*>`
========================================================================================


Iteration 14
Sample 3 from current logs bucket: ID: 149, Len: 7, Bucket Size: 281073, Total Buckets: 239
Sampling from 103379 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `Reading broadcast variable 1 took 120 ms`, MaxSim Log: `Reading broadcast variable 1 took 160 ms`.
	============  Query  ====================
	Log[1]: `Reading broadcast variable 1 took 120 ms`
	Log[2]: `Reading broadcast variable 400 took 3 ms`
	Log[3]: `Reading broadcast variable 1707 took 5 ms`
	============ Response ====================
LogTemplate[1]: `Reading broadcast variable {var} took {time} ms`
LogTemplate[2]: `Reading broadcast variable {var} took {time} ms`
LogTemplate[3]: `Reading broadcast variable {var} took {time} ms`
	============ PostProcess ====================
	Post Template: `Reading broadcast variable <*> took <*> ms`
	Post Template: `Reading broadcast variable <*> took <*> ms`
	Post Template: `Reading broadcast variable <*> took <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Reading broadcast variable <*> took <*> ms
[UpdateBucket] Logs: This iter found: 281073, total: 15378832/16075117, remain: 696285. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 532288 -> 251215, remain buckets: 195
Update Success: Time for one update logs: 5.160774230957031, template `Reading broadcast variable <*> took <*> ms`
========================================================================================


Iteration 15
Sample 3 from current logs bucket: ID: 162, Len: 7, Bucket Size: 227317, Total Buckets: 239
Sampling from 1012 logs, Sim Level: 4, MaxSim to anchor: 0.8571. Anchor: `Started 0 remote fetches in 7 ms`, MaxSim Log: `Started 7 remote fetches in 7 ms`.
	============  Query  ====================
	Log[1]: `Started 0 remote fetches in 7 ms`
	Log[2]: `Started 4 remote fetches in 30 ms`
	Log[3]: `Started 3 remote fetches in 10 ms`
	============ Response ====================
LogTemplate[1]: `Started {number} remote fetches in {time} ms`
LogTemplate[2]: `Started {number} remote fetches in {time} ms`
LogTemplate[3]: `Started {number} remote fetches in {time} ms`
	============ PostProcess ====================
	Post Template: `Started <*> remote fetches in <*> ms`
	Post Template: `Started <*> remote fetches in <*> ms`
	Post Template: `Started <*> remote fetches in <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Started <*> remote fetches in <*> ms
[UpdateBucket] Logs: This iter found: 227317, total: 15606149/16075117, remain: 468968. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 251215 -> 23898, remain buckets: 194
Update Success: Time for one update logs: 3.693793773651123, template `Started <*> remote fetches in <*> ms`
========================================================================================


Iteration 16
Sample 3 from current logs bucket: ID: 169, Len: 8, Bucket Size: 227317, Total Buckets: 239
Sampling from 296 logs, Sim Level: 3, MaxSim to anchor: 0.8571. Anchor: `Getting 2 non-empty blocks out of 2 blocks`, MaxSim Log: `Getting 2 non-empty blocks out of 13 blocks`.
	============  Query  ====================
	Log[1]: `Getting 2 non-empty blocks out of 2 blocks`
	Log[2]: `Getting 226 non-empty blocks out of 240 blocks`
	Log[3]: `Getting 315 non-empty blocks out of 396 blocks`
	============ Response ====================
LogTemplate[1]: `Getting {number} non-empty blocks out of {number} blocks`
LogTemplate[2]: `Getting {number} non-empty blocks out of {number} blocks`
LogTemplate[3]: `Getting {number} non-empty blocks out of {number} blocks`
	============ PostProcess ====================
	Post Template: `Getting <*> non-empty blocks out of <*> blocks`
	Post Template: `Getting <*> non-empty blocks out of <*> blocks`
	Post Template: `Getting <*> non-empty blocks out of <*> blocks`
	============ Aggregate ====================
	Aggregated Template:  Getting <*> non-empty blocks out of <*> blocks
[UpdateBucket] Logs: This iter found: 227317, total: 15833466/16075117, remain: 241651. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 228091 -> 774, remain buckets: 193
Update Success: Time for one update logs: 3.803982734680176, template `Getting <*> non-empty blocks out of <*> blocks`
========================================================================================


Iteration 17
Sample 3 from current logs bucket: ID: 196, Len: 12, Bucket Size: 38206, Total Buckets: 239
Sampling from 38205 logs, Sim Level: 6, MaxSim to anchor: 0.8462. Anchor: `Removed broadcast_1_piece0 on 10.10.34.16:42124 in memory (size: 3.7 KB, free: 36.4 GB)`, MaxSim Log: `Removed broadcast_1_piece0 on 10.10.34.16:58162 in memory (size: 3.7 KB, free: 36.4 GB)`.
	============  Query  ====================
	Log[1]: `Removed broadcast_1_piece0 on 10.10.34.16:42124 in memory (size: 3.7 KB, free: 36.4 GB)`
	Log[2]: `Removed broadcast_153_piece0 on mesos-slave-19:51361 in memory (size: 2.2 KB, free: 2.6 GB)`
	Log[3]: `Removed broadcast_56_piece0 on mesos-slave-25:38626 in memory (size: 4.1 KB, free: 27.8 GB)`
	============ Response ====================
LogTemplate[1]: `Removed broadcast_{broadcast_id}_piece0 on {server}:{port} in memory (size: {size}, free: {free_space})`  
LogTemplate[2]: `Removed broadcast_{broadcast_id}_piece0 on {server}:{port} in memory (size: {size}, free: {free_space})`  
LogTemplate[3]: `Removed broadcast_{broadcast_id}_piece0 on {server}:{port} in memory (size: {size}, free: {free_space})`  
	============ PostProcess ====================
	Post Template: `Removed <*> on <*> in memory (size: <*> free: <*>)`
	Post Template: `Removed <*> on <*> in memory (size: <*> free: <*>)`
	Post Template: `Removed <*> on <*> in memory (size: <*> free: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Removed <*> on <*> in memory (size: <*> free: <*>)
[UpdateBucket] Logs: This iter found: 38206, total: 15871672/16075117, remain: 203445. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 39534 -> 1328, remain buckets: 192
Update Success: Time for one update logs: 0.7738091945648193, template `Removed <*> on <*> in memory (size: <*> free: <*>)`
========================================================================================


Iteration 18
Sample 3 from current logs bucket: ID: 203, Len: 13, Bucket Size: 22412, Total Buckets: 239
Sampling from 22224 logs, Sim Level: 9, MaxSim to anchor: 0.8462. Anchor: `Starting task 0.0 in stage 0.0 (TID 0, mesos-master-1, partition 0,NODE_LOCAL, 2159 bytes)`, MaxSim Log: `Starting task 0.0 in stage 0.0 (TID 0, mesos-slave-27, partition 0,NODE_LOCAL, 2159 bytes)`.
	============  Query  ====================
	Log[1]: `Starting task 0.0 in stage 0.0 (TID 0, mesos-master-1, partition 0,NODE_LOCAL, 2159 bytes)`
	Log[2]: `Starting task 14.0 in stage 14.0 (TID 584, mesos-master-1, partition 14,PROCESS_LOCAL, 1850809 bytes)`
	Log[3]: `Starting task 1.0 in stage 1.0 (TID 3, mesos-master-1, partition 1,PROCESS_LOCAL, 19689129 bytes)`
	============ Response ====================
LogTemplate[1]: `Starting task {task_id} in stage {stage} (TID {tid}, mesos-master-1, partition {partition},{locality}, {bytes} bytes)`
	============ PostProcess ====================
	Post Template: `Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)`
	Post Template: `Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)`
	Post Template: `Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)`
	============ Aggregate ====================
	Aggregated Template:  Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)
[UpdateBucket] Logs: This iter found: 2931, total: 15874603/16075117, remain: 200514. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 25120 -> 22189, remain buckets: 192
Update Success: Time for one update logs: 0.6106641292572021, template `Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)`
========================================================================================


Iteration 19
Sample 3 from current logs bucket: ID: 208, Len: 14, Bucket Size: 20849, Total Buckets: 239
Sampling from 20848 logs, Sim Level: 12, MaxSim to anchor: 0.8571. Anchor: `Finished task 1.0 in stage 0.0 (TID 1) in 5931 ms on mesos-master-1 (1/2)`, MaxSim Log: `Finished task 1.0 in stage 0.0 (TID 1) in 5700 ms on mesos-master-1 (1/2)`.
	============  Query  ====================
	Log[1]: `Finished task 1.0 in stage 0.0 (TID 1) in 5931 ms on mesos-master-1 (1/2)`
	Log[2]: `Finished task 0.0 in stage 1.0 (TID 2) in 1743 ms on mesos-slave-13 (2/3)`
	Log[3]: `Finished task 2.0 in stage 1.0 (TID 4) in 973 ms on mesos-master-1 (3/40)`
	============ Response ====================
LogTemplate[1]: `Finished task {task_id} in stage {stage_id} (TID {tid}) in {duration} ms on {executor} ({progress})`  
LogTemplate[2]: `Finished task {task_id} in stage {stage_id} (TID {tid}) in {duration} ms on {executor} ({progress})`  
LogTemplate[3]: `Finished task {task_id} in stage {stage_id} (TID {tid}) in {duration} ms on {executor} ({progress})`  
	============ PostProcess ====================
	Post Template: `Finished task <*> in stage <*> (TID <*>) in <*> ms on <*> (<*>)`
	Post Template: `Finished task <*> in stage <*> (TID <*>) in <*> ms on <*> (<*>)`
	Post Template: `Finished task <*> in stage <*> (TID <*>) in <*> ms on <*> (<*>)`
	============ Aggregate ====================
	Aggregated Template:  Finished task <*> in stage <*> (TID <*>) in <*> ms on <*> (<*>)
[UpdateBucket] Logs: This iter found: 20709, total: 15895312/16075117, remain: 179805. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 20936 -> 227, remain buckets: 192
Update Success: Time for one update logs: 0.48454809188842773, template `Finished task <*> in stage <*> (TID <*>) in <*> ms on <*> (<*>)`
========================================================================================


Iteration 20
Sample 3 from current logs bucket: ID: 203, Len: 13, Bucket Size: 19745, Total Buckets: 239
Sampling from 19589 logs, Sim Level: 9, MaxSim to anchor: 0.8462. Anchor: `Starting task 0.0 in stage 0.0 (TID 0, mesos-slave-20, partition 0,RACK_LOCAL, 2159 bytes)`, MaxSim Log: `Starting task 0.0 in stage 0.0 (TID 0, mesos-slave-18, partition 0,RACK_LOCAL, 2159 bytes)`.
	============  Query  ====================
	Log[1]: `Starting task 0.0 in stage 0.0 (TID 0, mesos-slave-20, partition 0,RACK_LOCAL, 2159 bytes)`
	Log[2]: `Starting task 1.0 in stage 1.0 (TID 3, mesos-slave-20, partition 1,PROCESS_LOCAL, 1242986 bytes)`
	Log[3]: `Starting task 2.0 in stage 2.0 (TID 8, mesos-slave-20, partition 2,PROCESS_LOCAL, 14758160 bytes)`
	============ Response ====================
LogTemplate[1]: `Starting task {task_id} in stage {stage_id} (TID {tid}, {node}, partition {partition_id},{locality}, {bytes} bytes)`
	============ PostProcess ====================
	Post Template: `Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)`
	Post Template: `Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)`
	Post Template: `Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)`
	============ Aggregate ====================
	Aggregated Template:  Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)
[UpdateBucket] Logs: This iter found: 21299, total: 15916611/16075117, remain: 158506. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 22189 -> 890, remain buckets: 191
Update Success: Time for one update logs: 0.4747161865234375, template `Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)`
========================================================================================


Iteration 21
Sample 3 from current logs bucket: ID: 178, Len: 9, Bucket Size: 11698, Total Buckets: 239
Sampling from 126 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Don't have map outputs for shuffle 0, fetching them`, MaxSim Log: `Don't have map outputs for shuffle 3, fetching them`.
	============  Query  ====================
	Log[1]: `Don't have map outputs for shuffle 0, fetching them`
	Log[2]: `Don't have map outputs for shuffle 13, fetching them`
	Log[3]: `Don't have map outputs for shuffle 51, fetching them`
	============ Response ====================
LogTemplate[1]: `Don't have map outputs for shuffle {shuffle_id}, fetching them`
	============ PostProcess ====================
	Post Template: `Don't have map outputs for shuffle <*> fetching them`
	Post Template: `Don't have map outputs for shuffle <*> fetching them`
	Post Template: `Don't have map outputs for shuffle <*> fetching them`
	============ Aggregate ====================
	Aggregated Template:  Don't have map outputs for shuffle <*> fetching them
[UpdateBucket] Logs: This iter found: 11698, total: 15928309/16075117, remain: 146808. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 17906 -> 6208, remain buckets: 190
Update Success: Time for one update logs: 0.24123287200927734, template `Don't have map outputs for shuffle <*> fetching them`
========================================================================================


Iteration 22
Sample 3 from current logs bucket: ID: 119, Len: 5, Bucket Size: 9926, Total Buckets: 239
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Changing view acls to: yarn,curi`, MaxSim Log: `Changing modify acls to: yarn,curi`.
	============  Query  ====================
	Log[1]: `Changing view acls to: yarn,curi`
	Log[2]: `Changing view acls to: yarn,yxsu`
	Log[3]: `Changing modify acls to: yarn,curi`
	============ Response ====================
LogTemplate[1]: `Changing view acls to: yarn,{user}`
LogTemplate[2]: `Changing view acls to: yarn,{user}`
LogTemplate[3]: `Changing modify acls to: yarn,{user}`
	============ PostProcess ====================
	Post Template: `Changing view acls to: yarn,<*>`
	Post Template: `Changing view acls to: yarn,<*>`
	Post Template: `Changing modify acls to: yarn,<*>`
	============ Aggregate ====================
	Aggregated Template:  Changing view acls to: yarn,<*>
[UpdateBucket] Logs: This iter found: 4963, total: 15933272/16075117, remain: 141845. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 18272 -> 13309, remain buckets: 190
Update Success: Time for one update logs: 0.19501304626464844, template `Changing view acls to: yarn,<*>`
========================================================================================


Iteration 23
Sample 3 from current logs bucket: ID: 92, Len: 3, Bucket Size: 9166, Total Buckets: 239
Sampling from 2593 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:0+6292942`, MaxSim Log: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:6292942+6292942`.
	============  Query  ====================
	Log[1]: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:0+6292942`
	Log[2]: `Input split: Paths:/yxsu/dataset/ImageNet/ILSVRC2012_img_test/ILSVRC2012_test_00068234.JPEG:0+120820,/yxsu/dataset/ImageNet/ILSVRC2012_img_test/ILSVRC2012_test_00068243.JPEG:0+167078`
	Log[3]: `Input split: Paths:/yxsu/dataset/ImageNet/ILSVRC2012_img_test/ILSVRC2012_test_00004651.JPEG:0+90898,/yxsu/dataset/ImageNet/ILSVRC2012_img_test/ILSVRC2012_test_00004657.JPEG:0+151959`
	============ Response ====================
LogTemplate[1]: `Input split: hdfs://{ip_or_url}/user/{user}/{file}:{offset}+{length}`
LogTemplate[2]: `Input split: Paths:{directory}/{file}:{offset}+{length},{directory}/{file}:{offset}+{length}`
LogTemplate[3]: `Input split: Paths:{directory}/{file}:{offset}+{length},{directory}/{file}:{offset}+{length}`
	============ PostProcess ====================
	Post Template: `Input split: hdfs://<*>/user/<*>`
	Post Template: `Input split: Paths:<*>`
	Post Template: `Input split: Paths:<*>`
	============ Aggregate ====================
	Aggregated Template:  Input split: Paths:<*>
[UpdateBucket] Logs: This iter found: 2261, total: 15935533/16075117, remain: 139584. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 27392 -> 25131, remain buckets: 190
Update Success: Time for one update logs: 0.2835981845855713, template `Input split: Paths:<*>`
========================================================================================


Iteration 24
Sample 3 from current logs bucket: ID: 92, Len: 3, Bucket Size: 6905, Total Buckets: 239
Sampling from 332 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:0+6292942`, MaxSim Log: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:6292942+6292942`.
	============  Query  ====================
	Log[1]: `Input split: hdfs://10.10.34.11:9000/user/niuxy/com-amazon.ungraph.txt:0+6292942`
	Log[2]: `Input split: hdfs://10.10.34.11:9000/pjhe/logs/2kBGL.log:32604+8151`
	Log[3]: `Input split: hdfs://10.10.34.11:9000/pjhe/logs/2kBGL.log:97812+8151`
	============ Response ====================
LogTemplate[1]: `Input split: hdfs://{ip_or_url}/<*>/<*>:<*>+<*>`
LogTemplate[2]: `Input split: hdfs://{ip_or_url}/<*>/<*>:<*>+<*>`
LogTemplate[3]: `Input split: hdfs://{ip_or_url}/<*>/<*>:<*>+<*>`
	============ PostProcess ====================
	Post Template: `Input split: hdfs://<*>`
	Post Template: `Input split: hdfs://<*>`
	Post Template: `Input split: hdfs://<*>`
	============ Aggregate ====================
	Aggregated Template:  Input split: hdfs://<*>
[UpdateBucket] Logs: This iter found: 11606, total: 15947139/16075117, remain: 127978. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 25131 -> 13525, remain buckets: 149
[TemplateDB] Try Merge: `Input split: hdfs://<*>` | `Input split: Paths:<*>`
	Post Template: `Input split: <*>`
[TemplateDB] Merged: -> `Input split: <*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 13867/13867, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]
[UpdateBucket] Logs: This iter found: 0, total: 15947139/16075117, remain: 127978. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 13525 -> 13525, remain buckets: 149
[TemplateDB] Update Indexes: 13867 -> 13867 for `Input split: <*>`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Input split: <*>`
Update Success: Time for one update logs: 0.5546097755432129, template `Input split: hdfs://<*>`
========================================================================================


Iteration 25
Sample 3 from current logs bucket: ID: 119, Len: 5, Bucket Size: 4963, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Changing modify acls to: yarn,curi`, MaxSim Log: `Changing modify acls to: yarn,yxsu`.
	============  Query  ====================
	Log[1]: `Changing modify acls to: yarn,curi`
	Log[2]: `Changing modify acls to: yarn,yxsu`
	============ Response ====================
LogTemplate[1]: `Changing modify acls to: yarn,{user}`
LogTemplate[2]: `Changing modify acls to: yarn,{user}`
	============ PostProcess ====================
	Post Template: `Changing modify acls to: yarn,<*>`
	Post Template: `Changing modify acls to: yarn,<*>`
	============ Aggregate ====================
	Aggregated Template:  Changing modify acls to: yarn,<*>
[UpdateBucket] Logs: This iter found: 4963, total: 15952102/16075117, remain: 123015. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 13309 -> 8346, remain buckets: 148
[TemplateDB] Try Merge: `Changing modify acls to: yarn,<*>` | `Changing view acls to: yarn,<*>`
[TemplateDB] Reject Merge, Remain Template: `Changing modify acls to: yarn,<*>`
Update Success: Time for one update logs: 0.12861084938049316, template `Changing modify acls to: yarn,<*>`
========================================================================================


Iteration 26
Sample 3 from current logs bucket: ID: 215, Len: 18, Bucket Size: 4963, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7333. Anchor: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, curi); users with modify permissions: Set(yarn, curi)`, MaxSim Log: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, yxsu); users with modify permissions: Set(yarn, yxsu)`.
	============  Query  ====================
	Log[1]: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, curi); users with modify permissions: Set(yarn, curi)`
	Log[2]: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, yxsu); users with modify permissions: Set(yarn, yxsu)`
	============ Response ====================
LogTemplate[1]: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, {user1}); users with modify permissions: Set(yarn, {user1})`
LogTemplate[2]: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, {user1}); users with modify permissions: Set(yarn, {user1})`
	============ PostProcess ====================
	Post Template: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, <*>); users with modify permissions: Set(yarn, <*>)`
	Post Template: `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, <*>); users with modify permissions: Set(yarn, <*>)`
	============ Aggregate ====================
	Aggregated Template:  SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, <*>); users with modify permissions: Set(yarn, <*>)
[UpdateBucket] Logs: This iter found: 4963, total: 15957065/16075117, remain: 118052. 
[UpdateBucket] Buckets: Checked 2 ([215, 216]), Parent Bucket size: 5070 -> 107, remain buckets: 147
Update Success: Time for one update logs: 0.13562226295471191, template `SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, <*>); users with modify permissions: Set(yarn, <*>)`
========================================================================================


Iteration 27
Sample 3 from current logs bucket: ID: 147, Len: 7, Bucket Size: 4859, Total Buckets: 239
Sampling from 4676 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Successfully started service 'sparkExecutorActorSystem' on port 40424.`, MaxSim Log: `Successfully started service 'sparkExecutorActorSystem' on port 49572.`.
	============  Query  ====================
	Log[1]: `Successfully started service 'sparkExecutorActorSystem' on port 40424.`
	Log[2]: `Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47333.`
	Log[3]: `Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42937.`
	============ Response ====================
LogTemplate[1]: `Successfully started service '<service_name>' on port <port>.`
	============ PostProcess ====================
	Post Template: `Successfully started service '<service_name>' on port <port>.`
	Post Template: `Successfully started service '<service_name>' on port <port>.`
	Post Template: `Successfully started service '<service_name>' on port <port>.`
	============ Aggregate ====================
	Aggregated Template:  Successfully started service '<service_name>' on port <port>.
[UpdateBucket] Logs: This iter found: 0, total: 15957065/16075117, remain: 118052. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 23898 -> 23898, remain buckets: 147
Update failed: Template can not match logs `Successfully started service '<service_name>' on port <port>.`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 147, Len: 7, Bucket Size: 4859, Total Buckets: 239
Sampling from 4676 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Successfully started service 'sparkExecutorActorSystem' on port 40424.`, MaxSim Log: `Successfully started service 'sparkExecutorActorSystem' on port 49572.`.
	============  Query  ====================
	Log[1]: `Successfully started service 'sparkExecutorActorSystem' on port 40424.`
	Log[2]: `Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59755.`
	Log[3]: `Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43120.`
	============ Response ====================
LogTemplate[1]: `Successfully started service '{service_name}' on port {port}.`

LogTemplate[2]: `Successfully started service '{service_name}' on port {port}.`

LogTemplate[3]: `Successfully started service '{service_name}' on port {port}.`
	============ PostProcess ====================
	Post Template: `Successfully started service <*> on port <*>.`
	Post Template: `Successfully started service <*> on port <*>.`
	Post Template: `Successfully started service <*> on port <*>.`
	============ Aggregate ====================
	Aggregated Template:  Successfully started service <*> on port <*>.
[UpdateBucket] Logs: This iter found: 4859, total: 15961924/16075117, remain: 113193. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 23898 -> 19039, remain buckets: 146
Update Success: Time for one update logs: 0.15607190132141113, template `Successfully started service <*> on port <*>.`
========================================================================================


Iteration 28
Sample 3 from current logs bucket: ID: 160, Len: 7, Bucket Size: 3504, Total Buckets: 239
Sampling from 175 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Updating epoch to 1 and clearing cache`, MaxSim Log: `Updating epoch to 2 and clearing cache`.
	============  Query  ====================
	Log[1]: `Updating epoch to 1 and clearing cache`
	Log[2]: `Updating epoch to 162 and clearing cache`
	Log[3]: `Updating epoch to 152 and clearing cache`
	============ Response ====================
LogTemplate[1]: `Updating epoch to {epoch} and clearing cache`  
LogTemplate[2]: `Updating epoch to {epoch} and clearing cache`  
LogTemplate[3]: `Updating epoch to {epoch} and clearing cache`  
	============ PostProcess ====================
	Post Template: `Updating epoch to <*> and clearing cache`
	Post Template: `Updating epoch to <*> and clearing cache`
	Post Template: `Updating epoch to <*> and clearing cache`
	============ Aggregate ====================
	Aggregated Template:  Updating epoch to <*> and clearing cache
[UpdateBucket] Logs: This iter found: 3504, total: 15965428/16075117, remain: 109689. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 19039 -> 15535, remain buckets: 145
Update Success: Time for one update logs: 0.12179207801818848, template `Updating epoch to <*> and clearing cache`
========================================================================================


Iteration 29
Sample 3 from current logs bucket: ID: 12, Len: 3, Bucket Size: 2750, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Shutdown hook called`
	============ Response ====================
LogTemplate[1]: `Shutdown hook called`
	============ PostProcess ====================
	Post Template: `Shutdown hook called`
	============ Aggregate ====================
	Aggregated Template:  Shutdown hook called
[UpdateBucket] Logs: This iter found: 2750, total: 15968178/16075117, remain: 106939. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 13525 -> 10775, remain buckets: 144
Update Success: Time for one update logs: 0.09338927268981934, template `Shutdown hook called`
========================================================================================


Iteration 30
Sample 1 from current logs bucket: ID: 114, Len: 4, Bucket Size: 2682, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Got the output locations`
	============ Response ====================
LogTemplate[1]: `Got the output locations`
	============ PostProcess ====================
	Post Template: `Got the output locations`
	============ Aggregate ====================
	Aggregated Template:  Got the output locations
[UpdateBucket] Logs: This iter found: 2682, total: 15970860/16075117, remain: 104257. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 18083 -> 15401, remain buckets: 143
Update Success: Time for one update logs: 0.07238578796386719, template `Got the output locations`
========================================================================================


Iteration 31
Sample 1 from current logs bucket: ID: 161, Len: 7, Bucket Size: 2682, Total Buckets: 239
Sampling from 38 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.10.34.11:43537)`, MaxSim Log: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.10.34.25:36782)`.
	============  Query  ====================
	Log[1]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.10.34.11:43537)`
	Log[2]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.10.34.11:51535)`
	Log[3]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@10.10.34.36:44803)`
	============ Response ====================
LogTemplate[1]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@{ip}:43537)`
LogTemplate[2]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@{ip}:51535)`
LogTemplate[3]: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@{ip}:44803)`
	============ PostProcess ====================
	Post Template: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)`
	Post Template: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)`
	Post Template: `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)`
	============ Aggregate ====================
	Aggregated Template:  Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)
[UpdateBucket] Logs: This iter found: 2682, total: 15973542/16075117, remain: 101575. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 15535 -> 12853, remain buckets: 142
Update Success: Time for one update logs: 0.10798382759094238, template `Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)`
========================================================================================


Iteration 32
Sample 3 from current logs bucket: ID: 150, Len: 7, Bucket Size: 2623, Total Buckets: 239
Sampling from 7 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Container request (host: Any, capability: <memory:22528, vCores:8>)`, MaxSim Log: `Container request (host: Any, capability: <memory:22528, vCores:1>)`.
	============  Query  ====================
	Log[1]: `Container request (host: Any, capability: <memory:22528, vCores:8>)`
	Log[2]: `Container request (host: Any, capability: <memory:28160, vCores:6>)`
	Log[3]: `Container request (host: Any, capability: <memory:6758, vCores:5>)`
	============ Response ====================
LogTemplate[1]: `Container request (host: Any, capability: <memory:{memory}, vCores:{vCores}>)`
	============ PostProcess ====================
	Post Template: `Container request (host: Any, capability: <memory:<*>, vCores:<*>)`
	Post Template: `Container request (host: Any, capability: <memory:<*>, vCores:<*>)`
	Post Template: `Container request (host: Any, capability: <memory:<*>, vCores:<*>)`
	============ Aggregate ====================
	Aggregated Template:  Container request (host: Any, capability: <memory:<*>, vCores:<*>)
[UpdateBucket] Logs: This iter found: 2623, total: 15976165/16075117, remain: 98952. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 12853 -> 10230, remain buckets: 141
Update Success: Time for one update logs: 0.10264801979064941, template `Container request (host: Any, capability: <memory:<*>, vCores:<*>)`
========================================================================================


Iteration 33
Sample 3 from current logs bucket: ID: 174, Len: 9, Bucket Size: 2610, Total Buckets: 239
Sampling from 157 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Found inactive connection to mesos-slave-20/10.10.34.30:33900, creating a new one.`, MaxSim Log: `Found inactive connection to mesos-master-1/10.10.34.11:60970, creating a new one.`.
	============  Query  ====================
	Log[1]: `Found inactive connection to mesos-slave-20/10.10.34.30:33900, creating a new one.`
	Log[2]: `Found inactive connection to mesos-slave-21/10.10.34.31:51927, creating a new one.`
	Log[3]: `Found inactive connection to mesos-slave-26/10.10.34.36:39635, creating a new one.`
	============ Response ====================
LogTemplate[1]: `Found inactive connection to mesos-slave-{slave_id}/{ip_or_url}, creating a new one.`
	============ PostProcess ====================
	Post Template: `Found inactive connection to mesos-slave-<*>, creating a new one.`
	Post Template: `Found inactive connection to mesos-slave-<*>, creating a new one.`
	Post Template: `Found inactive connection to mesos-slave-<*>, creating a new one.`
	============ Aggregate ====================
	Aggregated Template:  Found inactive connection to mesos-slave-<*>, creating a new one.
[UpdateBucket] Logs: This iter found: 2157, total: 15978322/16075117, remain: 96795. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 6208 -> 4051, remain buckets: 141
Update Success: Time for one update logs: 0.09004902839660645, template `Found inactive connection to mesos-slave-<*>, creating a new one.`
========================================================================================


Iteration 34
Sample 3 from current logs bucket: ID: 146, Len: 7, Bucket Size: 2606, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Registered signal handlers for [TERM, HUP, INT]`
	============ Response ====================
LogTemplate[1]: `Registered signal handlers for [TERM, HUP, INT]`
	============ PostProcess ====================
	Post Template: `Registered signal handlers for [TERM, HUP, INT]`
	============ Aggregate ====================
	Aggregated Template:  Registered signal handlers for [TERM, HUP, INT]
[UpdateBucket] Logs: This iter found: 2606, total: 15980928/16075117, remain: 94189. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 10230 -> 7624, remain buckets: 140
Update Success: Time for one update logs: 0.06298303604125977, template `Registered signal handlers for [TERM, HUP, INT]`
========================================================================================


Iteration 35
Sample 3 from current logs bucket: ID: 14, Len: 3, Bucket Size: 2561, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Starting Executor Container`
	============ Response ====================
LogTemplate[1]: `Starting Executor Container`
	============ PostProcess ====================
	Post Template: `Starting Executor Container`
	============ Aggregate ====================
	Aggregated Template:  Starting Executor Container
[UpdateBucket] Logs: This iter found: 2561, total: 15983489/16075117, remain: 91628. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 10775 -> 8214, remain buckets: 139
Update Success: Time for one update logs: 0.08276081085205078, template `Starting Executor Container`
========================================================================================


Iteration 36
Sample 1 from current logs bucket: ID: 15, Len: 3, Bucket Size: 2561, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Setting up ContainerLaunchContext`
	============ Response ====================
LogTemplate[1]: `Setting up ContainerLaunchContext`
	============ PostProcess ====================
	Post Template: `Setting up ContainerLaunchContext`
	============ Aggregate ====================
	Aggregated Template:  Setting up ContainerLaunchContext
[UpdateBucket] Logs: This iter found: 2561, total: 15986050/16075117, remain: 89067. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 8214 -> 5653, remain buckets: 138
Update Success: Time for one update logs: 0.06750297546386719, template `Setting up ContainerLaunchContext`
========================================================================================


Iteration 37
Sample 1 from current logs bucket: ID: 16, Len: 3, Bucket Size: 2561, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Preparing Local resources`
	============ Response ====================
LogTemplate[1]: `Preparing Local resources`
	============ PostProcess ====================
	Post Template: `Preparing Local resources`
	============ Aggregate ====================
	Aggregated Template:  Preparing Local resources
[UpdateBucket] Logs: This iter found: 2561, total: 15988611/16075117, remain: 86506. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 5653 -> 3092, remain buckets: 137
Update Success: Time for one update logs: 0.06048393249511719, template `Preparing Local resources`
========================================================================================


Iteration 38
Sample 1 from current logs bucket: ID: 137, Len: 6, Bucket Size: 2561, Total Buckets: 239
Sampling from 1954 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.23:47891, executorHostname: mesos-slave-19`, MaxSim Log: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.23:47891, executorHostname: mesos-slave-28`.
	============  Query  ====================
	Log[1]: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.23:47891, executorHostname: mesos-slave-19`
	Log[2]: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.11:32921, executorHostname: mesos-master-2`
	Log[3]: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@10.10.34.11:39185, executorHostname: mesos-slave-20`
	============ Response ====================
LogTemplate[1]: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@{ip_address}:{port}, executorHostname: {hostname}`
	============ PostProcess ====================
	Post Template: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>`
	Post Template: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>`
	Post Template: `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>`
	============ Aggregate ====================
	Aggregated Template:  Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>
[UpdateBucket] Logs: This iter found: 2561, total: 15991172/16075117, remain: 83945. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 14448 -> 11887, remain buckets: 136
Update Success: Time for one update logs: 0.10596299171447754, template `Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>`
========================================================================================


Iteration 39
Sample 3 from current logs bucket: ID: 151, Len: 7, Bucket Size: 2561, Total Buckets: 239
Sampling from 2560 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Launching container container_1485248649253_0020_02_000002 for on host mesos-slave-19`, MaxSim Log: `Launching container container_1485248649253_0018_01_000003 for on host mesos-slave-19`.
	============  Query  ====================
	Log[1]: `Launching container container_1485248649253_0020_02_000002 for on host mesos-slave-19`
	Log[2]: `Launching container container_1485248649253_0004_01_000002 for on host mesos-slave-05`
	Log[3]: `Launching container container_1485248649253_0130_01_000006 for on host mesos-slave-27`
	============ Response ====================
LogTemplate[1]: `Launching container container_<*> for on host mesos-slave-<*>`
LogTemplate[2]: `Launching container container_<*> for on host mesos-slave-<*>`
LogTemplate[3]: `Launching container container_<*> for on host mesos-slave-<*>`
	============ PostProcess ====================
	Post Template: `Launching container <*> for on host mesos-slave-<*>`
	Post Template: `Launching container <*> for on host mesos-slave-<*>`
	Post Template: `Launching container <*> for on host mesos-slave-<*>`
	============ Aggregate ====================
	Aggregated Template:  Launching container <*> for on host mesos-slave-<*>
[UpdateBucket] Logs: This iter found: 2245, total: 15993417/16075117, remain: 81700. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 7624 -> 5379, remain buckets: 136
Update Success: Time for one update logs: 0.09464716911315918, template `Launching container <*> for on host mesos-slave-<*>`
========================================================================================


Iteration 40
Sample 3 from current logs bucket: ID: 238, Len: 66, Bucket Size: 2561, Total Buckets: 239
Sampling from 115 logs, Sim Level: 1, MaxSim to anchor: 0.6923. Anchor: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/spark-assembly-1.6.0-hadoop2.2.0.jar" } size: 109525492 timestamp: 1489498812773 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/pyspark.zip" } size: 355358 timestamp: 1489498812856 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/py4j-0.9-src.zip" } size: 44846 timestamp: 1489498812874 type: FILE visibility: PRIVATE)`, MaxSim Log: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0018/spark-assembly-1.6.0-hadoop2.2.0.jar" } size: 109525492 timestamp: 1489498440252 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0018/pyspark.zip" } size: 355358 timestamp: 1489498440353 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0018/py4j-0.9-src.zip" } size: 44846 timestamp: 1489498440372 type: FILE visibility: PRIVATE)`.
	============  Query  ====================
	Log[1]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/spark-assembly-1.6.0-hadoop2.2.0.jar" } size: 109525492 timestamp: 1489498812773 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/pyspark.zip" } size: 355358 timestamp: 1489498812856 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0020/py4j-0.9-src.zip" } size: 44846 timestamp: 1489498812874 type: FILE visibility: PRIVATE)`
	Log[2]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0159/spark-assembly-1.6.0-hadoop2.2.0.jar" } size: 109525492 timestamp: 1497078835931 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0159/pyspark.zip" } size: 355358 timestamp: 1497078836001 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0159/py4j-0.9-src.zip" } size: 44846 timestamp: 1497078836021 type: FILE visibility: PRIVATE)`
	Log[3]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0174/spark-assembly-1.6.0-hadoop2.2.0.jar" } size: 109525492 timestamp: 1501137161217 type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0174/pyspark.zip" } size: 355358 timestamp: 1501137161295 type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "10.10.34.11" port: 9000 file: "/user/curi/.sparkStaging/application_1485248649253_0174/py4j-0.9-src.zip" } size: 44846 timestamp: 1501137161411 type: FILE visibility: PRIVATE)`
	============ Response ====================
LogTemplate[1]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 109525492 timestamp: {timestamp} type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 355358 timestamp: {timestamp} type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 44846 timestamp: {timestamp} type: FILE visibility: PRIVATE)`

LogTemplate[2]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 109525492 timestamp: {timestamp} type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 355358 timestamp: {timestamp} type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 44846 timestamp: {timestamp} type: FILE visibility: PRIVATE)`

LogTemplate[3]: `Prepared Local resources Map(__spark__.jar -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 109525492 timestamp: {timestamp} type: FILE visibility: PRIVATE, pyspark.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 355358 timestamp: {timestamp} type: FILE visibility: PRIVATE, py4j-0.9-src.zip -> resource { scheme: "hdfs" host: "{ip}" port: 9000 file: "{file}" } size: 44846 timestamp: {timestamp} type: FILE visibility: PRIVATE)`
	============ PostProcess ====================
	Post Template: `Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)`
	Post Template: `Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)`
	Post Template: `Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)`
	============ Aggregate ====================
	Aggregated Template:  Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)
[UpdateBucket] Logs: This iter found: 2561, total: 15995978/16075117, remain: 79139. 
[UpdateBucket] Buckets: Checked 1 ([238]), Parent Bucket size: 2561 -> 0, remain buckets: 135
Update Success: Time for one update logs: 0.16246604919433594, template `Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)`
========================================================================================


Iteration 41
Sample 3 from current logs bucket: ID: 136, Len: 6, Bucket Size: 2554, Total Buckets: 239
Sampling from 119 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Received new token for : mesos-slave-19:35680`, MaxSim Log: `Received new token for : mesos-slave-28:39598`.
	============  Query  ====================
	Log[1]: `Received new token for : mesos-slave-19:35680`
	Log[2]: `Received new token for : mesos-slave-29:38147`
	Log[3]: `Received new token for : mesos-slave-23:58316`
	============ Response ====================
LogTemplate[1]: `Received new token for : {hostname}:{port}`
LogTemplate[2]: `Received new token for : {hostname}:{port}`
LogTemplate[3]: `Received new token for : {hostname}:{port}`
	============ PostProcess ====================
	Post Template: `Received new token for : <*>`
	Post Template: `Received new token for : <*>`
	Post Template: `Received new token for : <*>`
	============ Aggregate ====================
	Aggregated Template:  Received new token for : <*>
[UpdateBucket] Logs: This iter found: 2554, total: 15998532/16075117, remain: 76585. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 11887 -> 9333, remain buckets: 134
Update Success: Time for one update logs: 0.0938560962677002, template `Received new token for : <*>`
========================================================================================


Iteration 42
Sample 3 from current logs bucket: ID: 0, Len: 2, Bucket Size: 2378, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Slf4jLogger started`
	============ Response ====================
LogTemplate[1]: `Slf4jLogger started`
	============ PostProcess ====================
	Post Template: `Slf4jLogger started`
	============ Aggregate ====================
	Aggregated Template:  Slf4jLogger started
[UpdateBucket] Logs: This iter found: 2378, total: 16000910/16075117, remain: 74207. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 13373 -> 10995, remain buckets: 133
Update Success: Time for one update logs: 0.05894875526428223, template `Slf4jLogger started`
========================================================================================


Iteration 43
Sample 3 from current logs bucket: ID: 1, Len: 2, Bucket Size: 2378, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Starting remoting`
	============ Response ====================
LogTemplate[1]: `Starting remoting`
	============ PostProcess ====================
	Post Template: `Starting remoting`
	============ Aggregate ====================
	Aggregated Template:  Starting remoting
[UpdateBucket] Logs: This iter found: 2378, total: 16003288/16075117, remain: 71829. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 10995 -> 8617, remain buckets: 132
Update Success: Time for one update logs: 0.0557401180267334, template `Starting remoting`
========================================================================================


Iteration 44
Sample 1 from current logs bucket: ID: 133, Len: 6, Bucket Size: 2378, Total Buckets: 239
Sampling from 2372 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@mesos-master-1:40424]`, MaxSim Log: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@mesos-slave-18:49572]`.
	============  Query  ====================
	Log[1]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@mesos-master-1:40424]`
	Log[2]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@mesos-master-1:36373]`
	Log[3]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@mesos-slave-14:53880]`
	============ Response ====================
LogTemplate[1]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@{hostname}:{port}]`
	============ PostProcess ====================
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]`
	============ Aggregate ====================
	Aggregated Template:  Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]
[UpdateBucket] Logs: This iter found: 2272, total: 16005560/16075117, remain: 69557. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 9333 -> 7061, remain buckets: 132
Update Success: Time for one update logs: 0.08965873718261719, template `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]`
========================================================================================


Iteration 45
Sample 3 from current logs bucket: ID: 2, Len: 2, Bucket Size: 2359, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Registered BlockManager`
	============ Response ====================
LogTemplate[1]: `Registered BlockManager`
	============ PostProcess ====================
	Post Template: `Registered BlockManager`
	============ Aggregate ====================
	Aggregated Template:  Registered BlockManager
[UpdateBucket] Logs: This iter found: 2359, total: 16007919/16075117, remain: 67198. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 8617 -> 6258, remain buckets: 131
Update Success: Time for one update logs: 0.050776004791259766, template `Registered BlockManager`
========================================================================================


Iteration 46
Sample 1 from current logs bucket: ID: 100, Len: 4, Bucket Size: 2359, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Trying to register BlockManager`
	============ Response ====================
LogTemplate[1]: `Trying to register BlockManager`
	============ PostProcess ====================
	Post Template: `Trying to register BlockManager`
	============ Aggregate ====================
	Aggregated Template:  Trying to register BlockManager
[UpdateBucket] Logs: This iter found: 2359, total: 16010278/16075117, remain: 64839. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 15401 -> 13042, remain buckets: 130
Update Success: Time for one update logs: 0.07315182685852051, template `Trying to register BlockManager`
========================================================================================


Iteration 47
Sample 1 from current logs bucket: ID: 116, Len: 4, Bucket Size: 2353, Total Buckets: 239
Sampling from 2263 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Server created on 48869`, MaxSim Log: `Server created on 43488`.
	============  Query  ====================
	Log[1]: `Server created on 48869`
	Log[2]: `Server created on 44677`
	Log[3]: `Server created on 60885`
	============ Response ====================
LogTemplate[1]: `Server created on {port}`
LogTemplate[2]: `Server created on {port}`
LogTemplate[3]: `Server created on {port}`
	============ PostProcess ====================
	Post Template: `Server created on <*>`
	Post Template: `Server created on <*>`
	Post Template: `Server created on <*>`
	============ Aggregate ====================
	Aggregated Template:  Server created on <*>
[UpdateBucket] Logs: This iter found: 2353, total: 16012631/16075117, remain: 62486. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 13042 -> 10689, remain buckets: 129
Update Success: Time for one update logs: 0.0928640365600586, template `Server created on <*>`
========================================================================================


Iteration 48
Sample 3 from current logs bucket: ID: 120, Len: 5, Bucket Size: 2353, Total Buckets: 239
Sampling from 2352 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/blockmgr-416b8a6f-4ed7-49bb-b2f3-71d51930d48d`, MaxSim Log: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/blockmgr-87d182fa-5de1-4948-b453-baeb6f07c2c0`.
	============  Query  ====================
	Log[1]: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/blockmgr-416b8a6f-4ed7-49bb-b2f3-71d51930d48d`
	Log[2]: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0179/blockmgr-374f57ab-7657-4682-a6a0-9eff3c3f7cb0`
	Log[3]: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0072/blockmgr-ad553ad0-5432-432e-8721-ed722a30028f`
	============ Response ====================
LogTemplate[1]: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_{app_id}/blockmgr-{block_id}`
	============ PostProcess ====================
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	============ Aggregate ====================
	Aggregated Template:  Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>
[UpdateBucket] Logs: This iter found: 2332, total: 16014963/16075117, remain: 60154. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 8346 -> 6014, remain buckets: 129
Update Success: Time for one update logs: 0.09494924545288086, template `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
========================================================================================


Iteration 49
Sample 3 from current logs bucket: ID: 134, Len: 6, Bucket Size: 2353, Total Buckets: 239
Sampling from 12 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `MemoryStore started with capacity 14.2 GB`, MaxSim Log: `MemoryStore started with capacity 26.4 GB`.
	============  Query  ====================
	Log[1]: `MemoryStore started with capacity 14.2 GB`
	Log[2]: `MemoryStore started with capacity 19.8 GB`
	Log[3]: `MemoryStore started with capacity 530.3 MB`
	============ Response ====================
LogTemplate[1]: `MemoryStore started with capacity {capacity}`  
LogTemplate[2]: `MemoryStore started with capacity {capacity}`  
LogTemplate[3]: `MemoryStore started with capacity {capacity}`  
	============ PostProcess ====================
	Post Template: `MemoryStore started with capacity <*>`
	Post Template: `MemoryStore started with capacity <*>`
	Post Template: `MemoryStore started with capacity <*>`
	============ Aggregate ====================
	Aggregated Template:  MemoryStore started with capacity <*>
[UpdateBucket] Logs: This iter found: 2353, total: 16017316/16075117, remain: 57801. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 7061 -> 4708, remain buckets: 128
Update Success: Time for one update logs: 0.07989501953125, template `MemoryStore started with capacity <*>`
========================================================================================


Iteration 50
Sample 3 from current logs bucket: ID: 184, Len: 10, Bucket Size: 2299, Total Buckets: 239
Sampling from 8 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms`, MaxSim Log: `Retrying fetch (2/3) for 1 outstanding blocks after 5000 ms`.
	============  Query  ====================
	Log[1]: `Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms`
	Log[2]: `Retrying fetch (2/3) for 9 outstanding blocks after 5000 ms`
	Log[3]: `Retrying fetch (3/3) for 2 outstanding blocks after 5000 ms`
	============ Response ====================
LogTemplate[1]: `Retrying fetch (<*>) for <*> outstanding blocks after 5000 ms`
	============ PostProcess ====================
	Post Template: `Retrying fetch (<*>) for <*> outstanding blocks after <*> ms`
	Post Template: `Retrying fetch (<*>) for <*> outstanding blocks after <*> ms`
	Post Template: `Retrying fetch (<*>) for <*> outstanding blocks after <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Retrying fetch (<*>) for <*> outstanding blocks after <*> ms
[UpdateBucket] Logs: This iter found: 2299, total: 16019615/16075117, remain: 55502. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 3903 -> 1604, remain buckets: 127
Update Success: Time for one update logs: 0.07459402084350586, template `Retrying fetch (<*>) for <*> outstanding blocks after <*> ms`
========================================================================================


Iteration 51
Sample 3 from current logs bucket: ID: 99, Len: 4, Bucket Size: 2289, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Successfully registered with driver`
	============ Response ====================
LogTemplate[1]: `Successfully registered with driver`
	============ PostProcess ====================
	Post Template: `Successfully registered with driver`
	============ Aggregate ====================
	Aggregated Template:  Successfully registered with driver
[UpdateBucket] Logs: This iter found: 2289, total: 16021904/16075117, remain: 53213. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 10689 -> 8400, remain buckets: 126
Update Success: Time for one update logs: 0.06209206581115723, template `Successfully registered with driver`
========================================================================================


Iteration 52
Sample 1 from current logs bucket: ID: 148, Len: 7, Bucket Size: 2289, Total Buckets: 239
Sampling from 823 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Starting executor ID 6 on host mesos-master-1`, MaxSim Log: `Starting executor ID 6 on host mesos-slave-07`.
	============  Query  ====================
	Log[1]: `Starting executor ID 6 on host mesos-master-1`
	Log[2]: `Starting executor ID 56 on host mesos-slave-22`
	Log[3]: `Starting executor ID 3 on host mesos-slave-23`
	============ Response ====================
LogTemplate[1]: `Starting executor ID {executor_id} on host {host_name}`
LogTemplate[2]: `Starting executor ID {executor_id} on host {host_name}`
LogTemplate[3]: `Starting executor ID {executor_id} on host {host_name}`
	============ PostProcess ====================
	Post Template: `Starting executor ID <*> on host <*>`
	Post Template: `Starting executor ID <*> on host <*>`
	Post Template: `Starting executor ID <*> on host <*>`
	============ Aggregate ====================
	Aggregated Template:  Starting executor ID <*> on host <*>
[UpdateBucket] Logs: This iter found: 2289, total: 16024193/16075117, remain: 50924. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 5379 -> 3090, remain buckets: 125
Update Success: Time for one update logs: 0.08013391494750977, template `Starting executor ID <*> on host <*>`
========================================================================================


Iteration 53
Sample 3 from current logs bucket: ID: 115, Len: 4, Bucket Size: 2268, Total Buckets: 239
Sampling from 154 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Connecting to driver: spark://CoarseGrainedScheduler@10.10.34.23:47891`, MaxSim Log: `Connecting to driver: spark://CoarseGrainedScheduler@10.10.34.11:50050`.
	============  Query  ====================
	Log[1]: `Connecting to driver: spark://CoarseGrainedScheduler@10.10.34.23:47891`
	Log[2]: `Connecting to driver: spark://CoarseGrainedScheduler@10.10.34.16:37380`
	Log[3]: `Connecting to driver: spark://CoarseGrainedScheduler@10.10.34.11:53494`
	============ Response ====================
LogTemplate[1]: `Connecting to driver: spark://CoarseGrainedScheduler@{ip_or_url}:{port}`
	============ PostProcess ====================
	Post Template: `Connecting to driver: spark://CoarseGrainedScheduler@<*>`
	Post Template: `Connecting to driver: spark://CoarseGrainedScheduler@<*>`
	Post Template: `Connecting to driver: spark://CoarseGrainedScheduler@<*>`
	============ Aggregate ====================
	Aggregated Template:  Connecting to driver: spark://CoarseGrainedScheduler@<*>
[UpdateBucket] Logs: This iter found: 2268, total: 16026461/16075117, remain: 48656. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 8400 -> 6132, remain buckets: 124
Update Success: Time for one update logs: 0.08509683609008789, template `Connecting to driver: spark://CoarseGrainedScheduler@<*>`
========================================================================================


Iteration 54
Sample 3 from current logs bucket: ID: 191, Len: 11, Bucket Size: 2228, Total Buckets: 239
Sampling from 8 logs, Sim Level: 3, MaxSim to anchor: 0.9091. Anchor: `Exception while beginning fetch of 1 outstanding blocks (after 1 retries)`, MaxSim Log: `Exception while beginning fetch of 1 outstanding blocks (after 2 retries)`.
	============  Query  ====================
	Log[1]: `Exception while beginning fetch of 1 outstanding blocks (after 1 retries)`
	Log[2]: `Exception while beginning fetch of 2 outstanding blocks (after 2 retries)`
	Log[3]: `Exception while beginning fetch of 9 outstanding blocks (after 3 retries)`
	============ Response ====================
LogTemplate[1]: `Exception while beginning fetch of {number} outstanding blocks (after {number} retries)`
	============ PostProcess ====================
	Post Template: `Exception while beginning fetch of <*> outstanding blocks (after <*> retries)`
	Post Template: `Exception while beginning fetch of <*> outstanding blocks (after <*> retries)`
	Post Template: `Exception while beginning fetch of <*> outstanding blocks (after <*> retries)`
	============ Aggregate ====================
	Aggregated Template:  Exception while beginning fetch of <*> outstanding blocks (after <*> retries)
[UpdateBucket] Logs: This iter found: 2228, total: 16028689/16075117, remain: 46428. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 6362 -> 4134, remain buckets: 123
Update Success: Time for one update logs: 0.07403898239135742, template `Exception while beginning fetch of <*> outstanding blocks (after <*> retries)`
========================================================================================


Iteration 55
Sample 3 from current logs bucket: ID: 135, Len: 6, Bucket Size: 2000, Total Buckets: 239
Sampling from 4 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `mapred.tip.id is deprecated. Instead, use mapreduce.task.id`, MaxSim Log: `mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id`.
	============  Query  ====================
	Log[1]: `mapred.tip.id is deprecated. Instead, use mapreduce.task.id`
	Log[2]: `mapred.job.id is deprecated. Instead, use mapreduce.job.id`
	Log[3]: `mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id`
	============ Response ====================
LogTemplate[1]: `mapred.<{placeholder}> is deprecated. Instead, use mapreduce.<{placeholder}>`

LogTemplate[2]: `mapred.<{placeholder}> is deprecated. Instead, use mapreduce.<{placeholder}>`

LogTemplate[3]: `mapred.<{placeholder}> is deprecated. Instead, use mapreduce.<{placeholder}>`
	============ PostProcess ====================
	Post Template: `mapred.<*> is deprecated. Instead, use mapreduce.<*>`
	Post Template: `mapred.<*> is deprecated. Instead, use mapreduce.<*>`
	Post Template: `mapred.<*> is deprecated. Instead, use mapreduce.<*>`
	============ Aggregate ====================
	Aggregated Template:  mapred.<*> is deprecated. Instead, use mapreduce.<*>
[UpdateBucket] Logs: This iter found: 2000, total: 16030689/16075117, remain: 44428. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 4708 -> 2708, remain buckets: 122
Update Success: Time for one update logs: 0.10852622985839844, template `mapred.<*> is deprecated. Instead, use mapreduce.<*>`
========================================================================================


Iteration 56
Sample 3 from current logs bucket: ID: 235, Len: 40, Bucket Size: 1979, Total Buckets: 239
Sampling from 1978 logs, Sim Level: 12, MaxSim to anchor: 0.9189. Anchor: `Lost task 7.2 in stage 1.0 (TID 53, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`, MaxSim Log: `Lost task 1.0 in stage 1.0 (TID 3, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`.
	============  Query  ====================
	Log[1]: `Lost task 7.2 in stage 1.0 (TID 53, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[2]: `Lost task 52.0 in stage 11.1 (TID 1003, mesos-slave-13): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 31.3 GB of 28 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[3]: `Lost task 17.0 in stage 3.0 (TID 68, mesos-slave-25): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 28.4 GB of 22 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-slave-{slave_id}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {memory_limit} physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[2]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-slave-{slave_id}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {memory_limit} physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[3]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-slave-{slave_id}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {memory_limit} physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.
[UpdateBucket] Logs: This iter found: 389, total: 16031078/16075117, remain: 44039. 
[UpdateBucket] Buckets: Checked 1 ([235]), Parent Bucket size: 1979 -> 1590, remain buckets: 122
Update Success: Time for one update logs: 0.09870791435241699, template `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
========================================================================================


Iteration 57
Sample 3 from current logs bucket: ID: 117, Len: 4, Bucket Size: 1932, Total Buckets: 239
Sampling from 111 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Opening proxy : mesos-slave-18:56143`, MaxSim Log: `Opening proxy : mesos-slave-28:39598`.
	============  Query  ====================
	Log[1]: `Opening proxy : mesos-slave-18:56143`
	Log[2]: `Opening proxy : mesos-slave-29:49983`
	Log[3]: `Opening proxy : mesos-slave-10:36903`
	============ Response ====================
LogTemplate[1]: `Opening proxy : {proxy_name}:{port}`  
LogTemplate[2]: `Opening proxy : {proxy_name}:{port}`  
LogTemplate[3]: `Opening proxy : {proxy_name}:{port}`  
	============ PostProcess ====================
	Post Template: `Opening proxy : <*>`
	Post Template: `Opening proxy : <*>`
	Post Template: `Opening proxy : <*>`
	============ Aggregate ====================
	Aggregated Template:  Opening proxy : <*>
[UpdateBucket] Logs: This iter found: 2561, total: 16033639/16075117, remain: 41478. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 6132 -> 3571, remain buckets: 115
Update Success: Time for one update logs: 0.08013367652893066, template `Opening proxy : <*>`
========================================================================================


Iteration 58
Sample 3 from current logs bucket: ID: 123, Len: 5, Bucket Size: 1907, Total Buckets: 239
Sampling from 154 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Driver 10.10.34.23:47891 disassociated! Shutting down.`, MaxSim Log: `Driver 10.10.34.11:50050 disassociated! Shutting down.`.
	============  Query  ====================
	Log[1]: `Driver 10.10.34.23:47891 disassociated! Shutting down.`
	Log[2]: `Driver 10.10.34.15:53495 disassociated! Shutting down.`
	Log[3]: `Driver 10.10.34.11:50076 disassociated! Shutting down.`
	============ Response ====================
LogTemplate[1]: `Driver {ip_or_url} disassociated! Shutting down.`
	============ PostProcess ====================
	Post Template: `Driver <*> disassociated! Shutting down.`
	Post Template: `Driver <*> disassociated! Shutting down.`
	Post Template: `Driver <*> disassociated! Shutting down.`
	============ Aggregate ====================
	Aggregated Template:  Driver <*> disassociated! Shutting down.
[UpdateBucket] Logs: This iter found: 1907, total: 16035546/16075117, remain: 39571. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 6014 -> 4107, remain buckets: 114
Update Success: Time for one update logs: 0.07349491119384766, template `Driver <*> disassociated! Shutting down.`
========================================================================================


Iteration 59
Sample 3 from current logs bucket: ID: 122, Len: 5, Bucket Size: 1886, Total Buckets: 239
Sampling from 153 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `An unknown (mesos-slave-13:47891) driver disconnected.`, MaxSim Log: `An unknown (mesos-master-1:50050) driver disconnected.`.
	============  Query  ====================
	Log[1]: `An unknown (mesos-slave-13:47891) driver disconnected.`
	Log[2]: `An unknown (mesos-slave-14:48530) driver disconnected.`
	Log[3]: `An unknown (mesos-master-1:59844) driver disconnected.`
	============ Response ====================
LogTemplate[1]: `An unknown {node} driver disconnected.`  
LogTemplate[2]: `An unknown {node} driver disconnected.`  
LogTemplate[3]: `An unknown {node} driver disconnected.`  
	============ PostProcess ====================
	Post Template: `An unknown <*> driver disconnected.`
	Post Template: `An unknown <*> driver disconnected.`
	Post Template: `An unknown <*> driver disconnected.`
	============ Aggregate ====================
	Aggregated Template:  An unknown <*> driver disconnected.
[UpdateBucket] Logs: This iter found: 1886, total: 16037432/16075117, remain: 37685. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 4107 -> 2221, remain buckets: 113
Update Success: Time for one update logs: 0.06695818901062012, template `An unknown <*> driver disconnected.`
========================================================================================


Iteration 60
Sample 3 from current logs bucket: ID: 3, Len: 2, Bucket Size: 1828, Total Buckets: 239
	============  Query  ====================
	Log[1]: `MemoryStore cleared`
	============ Response ====================
LogTemplate[1]: `MemoryStore cleared`
	============ PostProcess ====================
	Post Template: `MemoryStore cleared`
	============ Aggregate ====================
	Aggregated Template:  MemoryStore cleared
[UpdateBucket] Logs: This iter found: 1828, total: 16039260/16075117, remain: 35857. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 6258 -> 4430, remain buckets: 112
Update Success: Time for one update logs: 0.04128217697143555, template `MemoryStore cleared`
========================================================================================


Iteration 61
Sample 1 from current logs bucket: ID: 4, Len: 2, Bucket Size: 1828, Total Buckets: 239
	============  Query  ====================
	Log[1]: `BlockManager stopped`
	============ Response ====================
LogTemplate[1]: `BlockManager stopped`
	============ PostProcess ====================
	Post Template: `BlockManager stopped`
	============ Aggregate ====================
	Aggregated Template:  BlockManager stopped
[UpdateBucket] Logs: This iter found: 1828, total: 16041088/16075117, remain: 34029. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 4430 -> 2602, remain buckets: 111
Update Success: Time for one update logs: 0.03790998458862305, template `BlockManager stopped`
========================================================================================


Iteration 62
Sample 1 from current logs bucket: ID: 102, Len: 4, Bucket Size: 1823, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Driver commanded a shutdown`
	============ Response ====================
LogTemplate[1]: `Driver commanded a shutdown`
	============ PostProcess ====================
	Post Template: `Driver commanded a shutdown`
	============ Aggregate ====================
	Aggregated Template:  Driver commanded a shutdown
[UpdateBucket] Logs: This iter found: 1823, total: 16042911/16075117, remain: 32206. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 3571 -> 1748, remain buckets: 110
Update Success: Time for one update logs: 0.03270721435546875, template `Driver commanded a shutdown`
========================================================================================


Iteration 63
Sample 1 from current logs bucket: ID: 8, Len: 2, Bucket Size: 1664, Total Buckets: 239
Sampling from 25 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `stopped o.s.j.s.ServletContextHandler{/metrics/json,null}`, MaxSim Log: `stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}`.
	============  Query  ====================
	Log[1]: `stopped o.s.j.s.ServletContextHandler{/metrics/json,null}`
	============ Response ====================
LogTemplate[1]: `stopped o.s.j.s.ServletContextHandler{/metrics/json,null}`
	============ PostProcess ====================
	Post Template: `stopped o.s.j.s.<*>`
	============ Aggregate ====================
	Aggregated Template:  stopped o.s.j.s.<*>
[UpdateBucket] Logs: This iter found: 1600, total: 16044511/16075117, remain: 30606. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 2602 -> 1002, remain buckets: 110
Update Success: Time for one update logs: 0.042263031005859375, template `stopped o.s.j.s.<*>`
========================================================================================


Iteration 64
Sample 3 from current logs bucket: ID: 235, Len: 40, Bucket Size: 1590, Total Buckets: 239
Sampling from 1589 logs, Sim Level: 12, MaxSim to anchor: 0.9189. Anchor: `Lost task 7.2 in stage 1.0 (TID 53, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`, MaxSim Log: `Lost task 1.0 in stage 1.0 (TID 3, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`.
	============  Query  ====================
	Log[1]: `Lost task 7.2 in stage 1.0 (TID 53, mesos-slave-27): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[2]: `Lost task 45.0 in stage 11.3 (TID 1407, mesos-master-2): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 28.1 GB of 28 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[3]: `Lost task 3.0 in stage 3.0 (TID 54, mesos-master-1): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 22.1 GB of 22 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {total_memory} {memory_type} memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[2]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {total_memory} {memory_type} memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[3]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. {memory_used} of {total_memory} {memory_type} memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.
[UpdateBucket] Logs: This iter found: 1590, total: 16046101/16075117, remain: 29016. 
[UpdateBucket] Buckets: Checked 1 ([235]), Parent Bucket size: 1590 -> 0, remain buckets: 109
Update Success: Time for one update logs: 0.08252906799316406, template `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
========================================================================================


Iteration 65
Sample 3 from current logs bucket: ID: 194, Len: 11, Bucket Size: 1538, Total Buckets: 239
Sampling from 1366 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Asked to send map output locations for shuffle 0 to mesos-slave-19:44974`, MaxSim Log: `Asked to send map output locations for shuffle 0 to mesos-slave-31:55220`.
	============  Query  ====================
	Log[1]: `Asked to send map output locations for shuffle 0 to mesos-slave-19:44974`
	Log[2]: `Asked to send map output locations for shuffle 28 to mesos-slave-26:60793`
	Log[3]: `Asked to send map output locations for shuffle 38 to mesos-slave-21:33490`
	============ Response ====================
LogTemplate[1]: `Asked to send map output locations for shuffle {shuffle_id} to {server}:{port}`
LogTemplate[2]: `Asked to send map output locations for shuffle {shuffle_id} to {server}:{port}`
LogTemplate[3]: `Asked to send map output locations for shuffle {shuffle_id} to {server}:{port}`
	============ PostProcess ====================
	Post Template: `Asked to send map output locations for shuffle <*> to <*>`
	Post Template: `Asked to send map output locations for shuffle <*> to <*>`
	Post Template: `Asked to send map output locations for shuffle <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  Asked to send map output locations for shuffle <*> to <*>
[UpdateBucket] Logs: This iter found: 1538, total: 16047639/16075117, remain: 27478. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 4134 -> 2596, remain buckets: 108
Update Success: Time for one update logs: 0.06598281860351562, template `Asked to send map output locations for shuffle <*> to <*>`
========================================================================================


Iteration 66
Sample 3 from current logs bucket: ID: 180, Len: 9, Bucket Size: 982, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Failed to connect to driver at 10.10.34.11:49939, retrying ...`
	============ Response ====================
LogTemplate[1]: `Failed to connect to driver at {ip_or_url}, retrying ...`
	============ PostProcess ====================
	Post Template: `Failed to connect to driver at <*> retrying ...`
	============ Aggregate ====================
	Aggregated Template:  Failed to connect to driver at <*> retrying ...
[UpdateBucket] Logs: This iter found: 982, total: 16048621/16075117, remain: 26496. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 4051 -> 3069, remain buckets: 107
Update Success: Time for one update logs: 0.05677676200866699, template `Failed to connect to driver at <*> retrying ...`
========================================================================================


Iteration 67
Sample 3 from current logs bucket: ID: 143, Len: 6, Bucket Size: 870, Total Buckets: 239
Sampling from 33 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Failed to get block(s) from mesos-master-1:45950`, MaxSim Log: `Failed to get block(s) from mesos-master-2:36967`.
	============  Query  ====================
	Log[1]: `Failed to get block(s) from mesos-master-1:45950`
	Log[2]: `Failed to get block(s) from mesos-slave-07:58702`
	Log[3]: `Failed to get block(s) from mesos-slave-22:39839`
	============ Response ====================
LogTemplate[1]: `Failed to get block(s) from {hostname}:{port}`
	============ PostProcess ====================
	Post Template: `Failed to get block(s) from <*>`
	Post Template: `Failed to get block(s) from <*>`
	Post Template: `Failed to get block(s) from <*>`
	============ Aggregate ====================
	Aggregated Template:  Failed to get block(s) from <*>
[UpdateBucket] Logs: This iter found: 870, total: 16049491/16075117, remain: 25626. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 2708 -> 1838, remain buckets: 106
Update Success: Time for one update logs: 0.04256415367126465, template `Failed to get block(s) from <*>`
========================================================================================


Iteration 68
Sample 3 from current logs bucket: ID: 175, Len: 9, Bucket Size: 865, Total Buckets: 239
Sampling from 819 logs, Sim Level: 7, MaxSim to anchor: 0.7000. Anchor: `Executor killed task 46.0 in stage 1.0 (TID 48)`, MaxSim Log: `Executor killed task 1.0 in stage 1.0 (TID 3)`.
	============  Query  ====================
	Log[1]: `Executor killed task 46.0 in stage 1.0 (TID 48)`
	Log[2]: `Executor killed task 0.1 in stage 2.0 (TID 113)`
	Log[3]: `Executor killed task 22.0 in stage 108.0 (TID 4706)`
	============ Response ====================
LogTemplate[1]: `Executor killed task {task_id} in stage {stage_id} (TID {tid})`
LogTemplate[2]: `Executor killed task {task_id} in stage {stage_id} (TID {tid})`
LogTemplate[3]: `Executor killed task {task_id} in stage {stage_id} (TID {tid})`
	============ PostProcess ====================
	Post Template: `Executor killed task <*> in stage <*> (TID <*>)`
	Post Template: `Executor killed task <*> in stage <*> (TID <*>)`
	Post Template: `Executor killed task <*> in stage <*> (TID <*>)`
	============ Aggregate ====================
	Aggregated Template:  Executor killed task <*> in stage <*> (TID <*>)
[UpdateBucket] Logs: This iter found: 510, total: 16050001/16075117, remain: 25116. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 3069 -> 2559, remain buckets: 106
Update Success: Time for one update logs: 0.03490185737609863, template `Executor killed task <*> in stage <*> (TID <*>)`
========================================================================================


Iteration 69
Sample 3 from current logs bucket: ID: 189, Len: 11, Bucket Size: 845, Total Buckets: 239
Sampling from 83 logs, Sim Level: 3, MaxSim to anchor: 0.9091. Anchor: `Received 4 containers from YARN, launching executors on 4 of them.`, MaxSim Log: `Received 12 containers from YARN, launching executors on 4 of them.`.
	============  Query  ====================
	Log[1]: `Received 4 containers from YARN, launching executors on 4 of them.`
	Log[2]: `Received 17 containers from YARN, launching executors on 0 of them.`
	Log[3]: `Received 11 containers from YARN, launching executors on 8 of them.`
	============ Response ====================
LogTemplate[1]: `Received {number} containers from YARN, launching executors on {number} of them.`
	============ PostProcess ====================
	Post Template: `Received <*> containers from YARN, launching executors on <*> of them.`
	Post Template: `Received <*> containers from YARN, launching executors on <*> of them.`
	Post Template: `Received <*> containers from YARN, launching executors on <*> of them.`
	============ Aggregate ====================
	Aggregated Template:  Received <*> containers from YARN, launching executors on <*> of them.
[UpdateBucket] Logs: This iter found: 845, total: 16050846/16075117, remain: 24271. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 2596 -> 1751, remain buckets: 105
Update Success: Time for one update logs: 0.04675912857055664, template `Received <*> containers from YARN, launching executors on <*> of them.`
========================================================================================


Iteration 70
Sample 3 from current logs bucket: ID: 93, Len: 3, Bucket Size: 777, Total Buckets: 239
Sampling from 776 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/spark-d820458f-e3bb-471c-af2c-6395418161b0/pyspark-11c108f1-169b-4205-983c-752295e704c0`, MaxSim Log: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/spark-d820458f-e3bb-471c-af2c-6395418161b0`.
	============  Query  ====================
	Log[1]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/spark-d820458f-e3bb-471c-af2c-6395418161b0/pyspark-11c108f1-169b-4205-983c-752295e704c0`
	Log[2]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0060/spark-c1813f84-7d58-454e-89d3-3c787b644921/pyspark-1082e59f-e55b-449f-a467-79daf1472c46`
	Log[3]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0068/spark-5c7c0821-46cd-4f6d-9d69-2d8f5392fd0d`
	============ Response ====================
LogTemplate[1]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_{app_id}/spark-{uuid}/pyspark-{uuid}`
	============ PostProcess ====================
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>`
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>`
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>`
	============ Aggregate ====================
	Aggregated Template:  Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>
[UpdateBucket] Logs: This iter found: 64, total: 16050910/16075117, remain: 24207. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 3092 -> 3028, remain buckets: 105
Update Success: Time for one update logs: 0.08507299423217773, template `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>`
========================================================================================


Iteration 71
Sample 3 from current logs bucket: ID: 188, Len: 11, Bucket Size: 763, Total Buckets: 239
Sampling from 756 logs, Sim Level: 3, MaxSim to anchor: 0.5714. Anchor: `Registering block manager 10.10.34.23:48030 with 26.4 GB RAM, BlockManagerId(driver, 10.10.34.23, 48030)`, MaxSim Log: `Registering block manager 10.10.34.31:54234 with 26.4 GB RAM, BlockManagerId(driver, 10.10.34.31, 54234)`.
	============  Query  ====================
	Log[1]: `Registering block manager 10.10.34.23:48030 with 26.4 GB RAM, BlockManagerId(driver, 10.10.34.23, 48030)`
	Log[2]: `Registering block manager 10.10.34.23:50850 with 36.4 GB RAM, BlockManagerId(driver, 10.10.34.23, 50850)`
	Log[3]: `Registering block manager 10.10.34.24:57861 with 26.4 GB RAM, BlockManagerId(driver, 10.10.34.24, 57861)`
	============ Response ====================
LogTemplate[1]: `Registering block manager {ip_or_url} with {memory} RAM, BlockManagerId(driver, {ip_or_url}, {port})`  
LogTemplate[2]: `Registering block manager {ip_or_url} with {memory} RAM, BlockManagerId(driver, {ip_or_url}, {port})`  
LogTemplate[3]: `Registering block manager {ip_or_url} with {memory} RAM, BlockManagerId(driver, {ip_or_url}, {port})`  
	============ PostProcess ====================
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)`
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)`
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)`
	============ Aggregate ====================
	Aggregated Template:  Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)
[UpdateBucket] Logs: This iter found: 64, total: 16050974/16075117, remain: 24143. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 1751 -> 1687, remain buckets: 105
Update Success: Time for one update logs: 0.03932499885559082, template `Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)`
========================================================================================


Iteration 72
Sample 3 from current logs bucket: ID: 103, Len: 4, Bucket Size: 717, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Shutting down remote daemon.`
	============ Response ====================
LogTemplate[1]: `Shutting down remote daemon.`
	============ PostProcess ====================
	Post Template: `Shutting down remote daemon.`
	============ Aggregate ====================
	Aggregated Template:  Shutting down remote daemon.
[UpdateBucket] Logs: This iter found: 717, total: 16051691/16075117, remain: 23426. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 1748 -> 1031, remain buckets: 104
Update Success: Time for one update logs: 0.029386043548583984, template `Shutting down remote daemon.`
========================================================================================


Iteration 73
Sample 3 from current logs bucket: ID: 154, Len: 7, Bucket Size: 714, Total Buckets: 239
Sampling from 539 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Adding task set 0.0 with 2 tasks`, MaxSim Log: `Adding task set 0.0 with 13 tasks`.
	============  Query  ====================
	Log[1]: `Adding task set 0.0 with 2 tasks`
	Log[2]: `Adding task set 9.3 with 74 tasks`
	Log[3]: `Adding task set 35.0 with 48 tasks`
	============ Response ====================
LogTemplate[1]: `Adding task set {number} with {number} tasks`
LogTemplate[2]: `Adding task set {number} with {number} tasks`
LogTemplate[3]: `Adding task set {number} with {number} tasks`
	============ PostProcess ====================
	Post Template: `Adding task set <*> with <*> tasks`
	Post Template: `Adding task set <*> with <*> tasks`
	Post Template: `Adding task set <*> with <*> tasks`
	============ Aggregate ====================
	Aggregated Template:  Adding task set <*> with <*> tasks
[UpdateBucket] Logs: This iter found: 714, total: 16052405/16075117, remain: 22712. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 3090 -> 2376, remain buckets: 103
Update Success: Time for one update logs: 0.05139613151550293, template `Adding task set <*> with <*> tasks`
========================================================================================


Iteration 74
Sample 3 from current logs bucket: ID: 93, Len: 3, Bucket Size: 713, Total Buckets: 239
Sampling from 712 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/spark-d820458f-e3bb-471c-af2c-6395418161b0`, MaxSim Log: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0018/spark-8fdc99b9-ae2d-4f0f-b65f-c38887339139`.
	============  Query  ====================
	Log[1]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0020/spark-d820458f-e3bb-471c-af2c-6395418161b0`
	Log[2]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0036/spark-071ab875-81fb-4697-9ac4-7294a998dbb7`
	Log[3]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_1460011102909_0176/spark-f67381da-e65e-4751-ad13-75ac4d707fcc`
	============ Response ====================
LogTemplate[1]: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-{uuid}`
	============ PostProcess ====================
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
	============ Aggregate ====================
	Aggregated Template:  Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>
[UpdateBucket] Logs: This iter found: 713, total: 16053118/16075117, remain: 21999. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 3028 -> 2315, remain buckets: 102
[TemplateDB] Try Merge: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>` | `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>/pyspark-<*>`
	Post Template: `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
[TemplateDB] Merged: -> `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 777/777, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]
Update Success: Time for one update logs: 0.12313604354858398, template `Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>`
========================================================================================


Iteration 75
Sample 3 from current logs bucket: ID: 188, Len: 11, Bucket Size: 699, Total Buckets: 239
Sampling from 692 logs, Sim Level: 4, MaxSim to anchor: 0.6923. Anchor: `Registering block manager mesos-master-1:48869 with 14.2 GB RAM, BlockManagerId(6, mesos-master-1, 48869)`, MaxSim Log: `Registering block manager mesos-master-1:45291 with 14.2 GB RAM, BlockManagerId(6, mesos-master-1, 45291)`.
	============  Query  ====================
	Log[1]: `Registering block manager mesos-master-1:48869 with 14.2 GB RAM, BlockManagerId(6, mesos-master-1, 48869)`
	Log[2]: `Registering block manager mesos-master-1:53100 with 14.2 GB RAM, BlockManagerId(1, mesos-master-1, 53100)`
	Log[3]: `Registering block manager mesos-slave-23:44528 with 14.2 GB RAM, BlockManagerId(6, mesos-slave-23, 44528)`
	============ Response ====================
LogTemplate[1]: `Registering block manager {node_name}:{port} with {memory} RAM, BlockManagerId(<*>, {node_name}, {port})`
	============ PostProcess ====================
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
	============ Aggregate ====================
	Aggregated Template:  Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)
[UpdateBucket] Logs: This iter found: 699, total: 16053817/16075117, remain: 21300. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 1687 -> 988, remain buckets: 101
[TemplateDB] Try Merge: `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)` | `Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)`
	Post Template: `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
[TemplateDB] Merged: -> `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 763/763, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
Update Success: Time for one update logs: 0.061300039291381836, template `Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)`
========================================================================================


Iteration 76
Sample 3 from current logs bucket: ID: 152, Len: 7, Bucket Size: 693, Total Buckets: 239
Sampling from 692 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Registered executor NettyRpcEndpointRef(null) (mesos-slave-19:57937) with ID 1`, MaxSim Log: `Registered executor NettyRpcEndpointRef(null) (mesos-slave-22:34702) with ID 1`.
	============  Query  ====================
	Log[1]: `Registered executor NettyRpcEndpointRef(null) (mesos-slave-19:57937) with ID 1`
	Log[2]: `Registered executor NettyRpcEndpointRef(null) (mesos-slave-22:51367) with ID 3`
	Log[3]: `Registered executor NettyRpcEndpointRef(null) (mesos-slave-14:36310) with ID 21`
	============ Response ====================
LogTemplate[1]: `Registered executor NettyRpcEndpointRef(null) ({executor_host}:{executor_port}) with ID {executor_id}`
	============ PostProcess ====================
	Post Template: `Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>`
	Post Template: `Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>`
	Post Template: `Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>`
	============ Aggregate ====================
	Aggregated Template:  Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>
[UpdateBucket] Logs: This iter found: 693, total: 16054510/16075117, remain: 20607. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 2376 -> 1683, remain buckets: 100
Update Success: Time for one update logs: 0.04533720016479492, template `Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>`
========================================================================================


Iteration 77
Sample 3 from current logs bucket: ID: 183, Len: 10, Bucket Size: 685, Total Buckets: 239
Sampling from 277 logs, Sim Level: 1, MaxSim to anchor: 0.8182. Anchor: `Removed TaskSet 0.0, whose tasks have all completed, from pool`, MaxSim Log: `Removed TaskSet 1.0, whose tasks have all completed, from pool`.
	============  Query  ====================
	Log[1]: `Removed TaskSet 0.0, whose tasks have all completed, from pool`
	Log[2]: `Removed TaskSet 221.0, whose tasks have all completed, from pool`
	Log[3]: `Removed TaskSet 201.0, whose tasks have all completed, from pool`
	============ Response ====================
LogTemplate[1]: `Removed TaskSet {task_id}, whose tasks have all completed, from pool`
LogTemplate[2]: `Removed TaskSet {task_id}, whose tasks have all completed, from pool`
LogTemplate[3]: `Removed TaskSet {task_id}, whose tasks have all completed, from pool`
	============ PostProcess ====================
	Post Template: `Removed TaskSet <*> whose tasks have all completed, from pool`
	Post Template: `Removed TaskSet <*> whose tasks have all completed, from pool`
	Post Template: `Removed TaskSet <*> whose tasks have all completed, from pool`
	============ Aggregate ====================
	Aggregated Template:  Removed TaskSet <*> whose tasks have all completed, from pool
[UpdateBucket] Logs: This iter found: 685, total: 16055195/16075117, remain: 19922. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 1604 -> 919, remain buckets: 99
Update Success: Time for one update logs: 0.03304910659790039, template `Removed TaskSet <*> whose tasks have all completed, from pool`
========================================================================================


Iteration 78
Sample 3 from current logs bucket: ID: 198, Len: 12, Bucket Size: 611, Total Buckets: 239
Sampling from 575 logs, Sim Level: 8, MaxSim to anchor: 0.7692. Anchor: `Executor is trying to kill task 28.0 in stage 1.0 (TID 30)`, MaxSim Log: `Executor is trying to kill task 1.0 in stage 1.0 (TID 3)`.
	============  Query  ====================
	Log[1]: `Executor is trying to kill task 28.0 in stage 1.0 (TID 30)`
	Log[2]: `Executor is trying to kill task 18.0 in stage 108.0 (TID 4702)`
	Log[3]: `Executor is trying to kill task 45.2 in stage 3.0 (TID 176)`
	============ Response ====================
LogTemplate[1]: `Executor is trying to kill task {task_id} in stage {stage_id} (TID {tid})`
	============ PostProcess ====================
	Post Template: `Executor is trying to kill task <*> in stage <*> (TID <*>)`
	Post Template: `Executor is trying to kill task <*> in stage <*> (TID <*>)`
	Post Template: `Executor is trying to kill task <*> in stage <*> (TID <*>)`
	============ Aggregate ====================
	Aggregated Template:  Executor is trying to kill task <*> in stage <*> (TID <*>)
[UpdateBucket] Logs: This iter found: 565, total: 16055760/16075117, remain: 19357. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 1328 -> 763, remain buckets: 99
Update Success: Time for one update logs: 0.03209495544433594, template `Executor is trying to kill task <*> in stage <*> (TID <*>)`
========================================================================================


Iteration 79
Sample 3 from current logs bucket: ID: 213, Len: 17, Bucket Size: 503, Total Buckets: 239
Sampling from 30 logs, Sim Level: 6, MaxSim to anchor: 0.8824. Anchor: `Will request 6 executor containers, each with 8 cores and 22528 MB memory including 2048 MB overhead`, MaxSim Log: `Will request 1 executor containers, each with 8 cores and 22528 MB memory including 2048 MB overhead`.
	============  Query  ====================
	Log[1]: `Will request 6 executor containers, each with 8 cores and 22528 MB memory including 2048 MB overhead`
	Log[2]: `Will request 64 executor containers, each with 5 cores and 28160 MB memory including 2560 MB overhead`
	Log[3]: `Will request 1 executor containers, each with 1 cores and 1408 MB memory including 384 MB overhead`
	============ Response ====================
LogTemplate[1]: `Will request {num_executors} executor containers, each with {num_cores} cores and {memory} MB memory including {overhead} MB overhead`
LogTemplate[2]: `Will request {num_executors} executor containers, each with {num_cores} cores and {memory} MB memory including {overhead} MB overhead`
LogTemplate[3]: `Will request {num_executors} executor containers, each with {num_cores} cores and {memory} MB memory including {overhead} MB overhead`
	============ PostProcess ====================
	Post Template: `Will request <*> executor containers, each with <*> cores and <*> MB memory including <*> MB overhead`
	Post Template: `Will request <*> executor containers, each with <*> cores and <*> MB memory including <*> MB overhead`
	Post Template: `Will request <*> executor containers, each with <*> cores and <*> MB memory including <*> MB overhead`
	============ Aggregate ====================
	Aggregated Template:  Will request <*> executor containers, each with <*> cores and <*> MB memory including <*> MB overhead
[UpdateBucket] Logs: This iter found: 503, total: 16056263/16075117, remain: 18854. 
[UpdateBucket] Buckets: Checked 2 ([213, 214]), Parent Bucket size: 635 -> 132, remain buckets: 98
Update Success: Time for one update logs: 0.03125286102294922, template `Will request <*> executor containers, each with <*> cores and <*> MB memory including <*> MB overhead`
========================================================================================


Iteration 80
Sample 3 from current logs bucket: ID: 197, Len: 12, Bucket Size: 471, Total Buckets: 239
Sampling from 368 logs, Sim Level: 6, MaxSim to anchor: 0.8333. Anchor: `Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:225)`, MaxSim Log: `Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:221)`.
	============  Query  ====================
	Log[1]: `Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:225)`
	Log[2]: `Submitting 40 missing tasks from ResultStage 40 (PythonRDD[82] at collect at pnmf.py:279)`
	Log[3]: `Submitting 3 missing tasks from ResultStage 3 (PythonRDD[9] at collect at pnmf4.py:376)`
	============ Response ====================
LogTemplate[1]: `Submitting {task_count} missing tasks from ResultStage {stage_number} ({rdd_name} at collect at {file_path}:{line_number})`
	============ PostProcess ====================
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)`
	============ Aggregate ====================
	Aggregated Template:  Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)
[UpdateBucket] Logs: This iter found: 227, total: 16056490/16075117, remain: 18627. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 763 -> 536, remain buckets: 98
Update Success: Time for one update logs: 0.02962779998779297, template `Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)`
========================================================================================


Iteration 81
Sample 3 from current logs bucket: ID: 192, Len: 11, Bucket Size: 466, Total Buckets: 239
Sampling from 465 logs, Sim Level: 3, MaxSim to anchor: 0.8333. Anchor: `Completed container container_1485248649253_0037_01_000002 on host: mesos-slave-16 (state: COMPLETE, exit status: -100)`, MaxSim Log: `Completed container container_1485248649253_0126_01_000003 on host: mesos-slave-16 (state: COMPLETE, exit status: -100)`.
	============  Query  ====================
	Log[1]: `Completed container container_1485248649253_0037_01_000002 on host: mesos-slave-16 (state: COMPLETE, exit status: -100)`
	Log[2]: `Completed container container_1485248649253_0060_01_000016 on host: mesos-master-1 (state: COMPLETE, exit status: -104)`
	Log[3]: `Completed container container_1485248649253_0171_01_000052 on host: mesos-slave-10 (state: COMPLETE, exit status: 1)`
	============ Response ====================
LogTemplate[1]: `Completed container {container_id} on host: {host} (state: {state}, exit status: {exit_status})`
LogTemplate[2]: `Completed container {container_id} on host: {host} (state: {state}, exit status: {exit_status})`
LogTemplate[3]: `Completed container {container_id} on host: {host} (state: {state}, exit status: {exit_status})`
	============ PostProcess ====================
	Post Template: `Completed container <*> on host: <*> (state: <*> exit status: <*>)`
	Post Template: `Completed container <*> on host: <*> (state: <*> exit status: <*>)`
	Post Template: `Completed container <*> on host: <*> (state: <*> exit status: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Completed container <*> on host: <*> (state: <*> exit status: <*>)
[UpdateBucket] Logs: This iter found: 466, total: 16056956/16075117, remain: 18161. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 988 -> 522, remain buckets: 97
Update Success: Time for one update logs: 0.0244140625, template `Completed container <*> on host: <*> (state: <*> exit status: <*>)`
========================================================================================


Iteration 82
Sample 3 from current logs bucket: ID: 173, Len: 9, Bucket Size: 462, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Remote daemon shut down; proceeding with flushing remote transports.`
	============ Response ====================
LogTemplate[1]: `Remote daemon shut down; proceeding with flushing remote transports.`
	============ PostProcess ====================
	Post Template: `Remote daemon shut down; proceeding with flushing remote transports.`
	============ Aggregate ====================
	Aggregated Template:  Remote daemon shut down; proceeding with flushing remote transports.
[UpdateBucket] Logs: This iter found: 462, total: 16057418/16075117, remain: 17699. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 2559 -> 2097, remain buckets: 96
Update Success: Time for one update logs: 0.022745132446289062, template `Remote daemon shut down; proceeding with flushing remote transports.`
========================================================================================


Iteration 83
Sample 3 from current logs bucket: ID: 174, Len: 9, Bucket Size: 453, Total Buckets: 239
Sampling from 26 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Found inactive connection to mesos-master-1/10.10.34.11:60970, creating a new one.`, MaxSim Log: `Found inactive connection to mesos-master-2/10.10.34.12:36003, creating a new one.`.
	============  Query  ====================
	Log[1]: `Found inactive connection to mesos-master-1/10.10.34.11:60970, creating a new one.`
	Log[2]: `Found inactive connection to mesos-master-3/10.10.34.13:52453, creating a new one.`
	Log[3]: `Found inactive connection to mesos-master-2/10.10.34.12:49207, creating a new one.`
	============ Response ====================
LogTemplate[1]: `Found inactive connection to mesos-master-{master_id}/{ip_or_url}, creating a new one.`
	============ PostProcess ====================
	Post Template: `Found inactive connection to mesos-master-<*>, creating a new one.`
	Post Template: `Found inactive connection to mesos-master-<*>, creating a new one.`
	Post Template: `Found inactive connection to mesos-master-<*>, creating a new one.`
	============ Aggregate ====================
	Aggregated Template:  Found inactive connection to mesos-master-<*>, creating a new one.
[UpdateBucket] Logs: This iter found: 453, total: 16057871/16075117, remain: 17246. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 2097 -> 1644, remain buckets: 95
[TemplateDB] Try Merge: `Found inactive connection to mesos-master-<*>, creating a new one.` | `Found inactive connection to mesos-slave-<*>, creating a new one.`
	Post Template: `Found inactive connection to mesos-<*>, creating a new one.`
[TemplateDB] Merged: -> `Found inactive connection to mesos-<*>, creating a new one.`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2610/2610, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
[UpdateBucket] Logs: This iter found: 0, total: 16057871/16075117, remain: 17246. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 1644 -> 1644, remain buckets: 95
[TemplateDB] Update Indexes: 2610 -> 2610 for `Found inactive connection to mesos-<*>, creating a new one.`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Found inactive connection to mesos-<*>, creating a new one.`
Update Success: Time for one update logs: 0.09816503524780273, template `Found inactive connection to mesos-master-<*>, creating a new one.`
========================================================================================


Iteration 84
Sample 3 from current logs bucket: ID: 185, Len: 10, Bucket Size: 440, Total Buckets: 239
Sampling from 190 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Size of output statuses for shuffle 0 is 342 bytes`, MaxSim Log: `Size of output statuses for shuffle 0 is 567 bytes`.
	============  Query  ====================
	Log[1]: `Size of output statuses for shuffle 0 is 342 bytes`
	Log[2]: `Size of output statuses for shuffle 11 is 590 bytes`
	Log[3]: `Size of output statuses for shuffle 3 is 1413 bytes`
	============ Response ====================
LogTemplate[1]: `Size of output statuses for shuffle {shuffle_id} is {size} bytes`
LogTemplate[2]: `Size of output statuses for shuffle {shuffle_id} is {size} bytes`
LogTemplate[3]: `Size of output statuses for shuffle {shuffle_id} is {size} bytes`
	============ PostProcess ====================
	Post Template: `Size of output statuses for shuffle <*> is <*> bytes`
	Post Template: `Size of output statuses for shuffle <*> is <*> bytes`
	Post Template: `Size of output statuses for shuffle <*> is <*> bytes`
	============ Aggregate ====================
	Aggregated Template:  Size of output statuses for shuffle <*> is <*> bytes
[UpdateBucket] Logs: This iter found: 440, total: 16058311/16075117, remain: 16806. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 919 -> 479, remain buckets: 94
Update Success: Time for one update logs: 0.025194883346557617, template `Size of output statuses for shuffle <*> is <*> bytes`
========================================================================================


Iteration 85
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 422, Total Buckets: 239
Sampling from 94 logs failed
	============  Query  ====================
	Log[1]: `Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter`
	============ Response ====================
LogTemplate[1]: `Adding filter: {api}`
	============ PostProcess ====================
	Post Template: `Adding filter: <*>`
	============ Aggregate ====================
	Aggregated Template:  Adding filter: <*>
[UpdateBucket] Logs: This iter found: 64, total: 16058375/16075117, remain: 16742. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 2315 -> 2251, remain buckets: 94
Update Success: Time for one update logs: 0.06743693351745605, template `Adding filter: <*>`
========================================================================================


Iteration 86
Sample 3 from current logs bucket: ID: 202, Len: 13, Bucket Size: 408, Total Buckets: 239
Sampling from 274 logs, Sim Level: 3, MaxSim to anchor: 0.8462. Anchor: `Submitting ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:225), which has no missing parents`, MaxSim Log: `Submitting ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:221), which has no missing parents`.
	============  Query  ====================
	Log[1]: `Submitting ResultStage 0 (PythonRDD[2] at collect at pnmf4.py:225), which has no missing parents`
	Log[2]: `Submitting ResultStage 44 (MapPartitionsRDD[90] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents`
	Log[3]: `Submitting ResultStage 4 (PythonRDD[10] at RDD at PythonRDD.scala:43), which has no missing parents`
	============ Response ====================
LogTemplate[1]: `Submitting ResultStage {stage_num} ({rdd_type}[{rdd_num}] at {location}), which has no missing parents`
LogTemplate[2]: `Submitting ResultStage {stage_num} ({rdd_type}[{rdd_num}] at {location}), which has no missing parents`
LogTemplate[3]: `Submitting ResultStage {stage_num} ({rdd_type}[{rdd_num}] at {location}), which has no missing parents`
	============ PostProcess ====================
	Post Template: `Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents`
	Post Template: `Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents`
	Post Template: `Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents`
	============ Aggregate ====================
	Aggregated Template:  Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents
[UpdateBucket] Logs: This iter found: 471, total: 16058846/16075117, remain: 16271. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 890 -> 419, remain buckets: 93
Update Success: Time for one update logs: 0.0336461067199707, template `Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents`
========================================================================================


Iteration 87
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 406, Total Buckets: 239
Sampling from 126 logs failed
	============  Query  ====================
	Log[1]: `Waiting for spark context initialization ...`
	============ Response ====================
LogTemplate[1]: `Waiting for spark context initialization ...`
	============ PostProcess ====================
	Post Template: `Waiting for spark context initialization ...`
	============ Aggregate ====================
	Aggregated Template:  Waiting for spark context initialization ...
[UpdateBucket] Logs: This iter found: 65, total: 16058911/16075117, remain: 16206. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 1838 -> 1773, remain buckets: 93
Update Success: Time for one update logs: 0.027881860733032227, template `Waiting for spark context initialization ...`
========================================================================================


Iteration 88
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 398, Total Buckets: 239
Sampling from 223 logs failed
	============  Query  ====================
	Log[1]: `Running Spark version 1.6.0`
	============ Response ====================
LogTemplate[1]: `Running Spark version {version}`
	============ PostProcess ====================
	Post Template: `Running Spark version <*>`
	============ Aggregate ====================
	Aggregated Template:  Running Spark version <*>
[UpdateBucket] Logs: This iter found: 64, total: 16058975/16075117, remain: 16142. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 1031 -> 967, remain buckets: 93
Update Success: Time for one update logs: 0.02779102325439453, template `Running Spark version <*>`
========================================================================================


Iteration 89
Sample 3 from current logs bucket: ID: 166, Len: 8, Bucket Size: 383, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Exception while beginning fetch of 1 outstanding blocks`, MaxSim Log: `Exception while beginning fetch of 2 outstanding blocks`.
	============  Query  ====================
	Log[1]: `Exception while beginning fetch of 1 outstanding blocks`
	Log[2]: `Exception while beginning fetch of 9 outstanding blocks`
	Log[3]: `Exception while beginning fetch of 2 outstanding blocks`
	============ Response ====================
LogTemplate[1]: `Exception while beginning fetch of {number} outstanding blocks`
	============ PostProcess ====================
	Post Template: `Exception while beginning fetch of <*> outstanding blocks`
	Post Template: `Exception while beginning fetch of <*> outstanding blocks`
	Post Template: `Exception while beginning fetch of <*> outstanding blocks`
	============ Aggregate ====================
	Aggregated Template:  Exception while beginning fetch of <*> outstanding blocks
[UpdateBucket] Logs: This iter found: 383, total: 16059358/16075117, remain: 15759. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 774 -> 391, remain buckets: 92
Update Success: Time for one update logs: 0.02990889549255371, template `Exception while beginning fetch of <*> outstanding blocks`
========================================================================================


Iteration 90
Sample 3 from current logs bucket: ID: 108, Len: 4, Bucket Size: 380, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `RECEIVED SIGNAL 15: SIGTERM`
	============ Response ====================
LogTemplate[1]: `RECEIVED SIGNAL <*>: SIGTERM`
	============ PostProcess ====================
	Post Template: `RECEIVED SIGNAL <*>: SIGTERM`
	============ Aggregate ====================
	Aggregated Template:  RECEIVED SIGNAL <*>: SIGTERM
[UpdateBucket] Logs: This iter found: 380, total: 16059738/16075117, remain: 15379. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 967 -> 587, remain buckets: 91
Update Success: Time for one update logs: 0.03774905204772949, template `RECEIVED SIGNAL <*>: SIGTERM`
========================================================================================


Iteration 91
Sample 3 from current logs bucket: ID: 218, Len: 19, Bucket Size: 378, Total Buckets: 239
Sampling from 35 logs, Sim Level: 2, MaxSim to anchor: 0.9412. Anchor: `Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`, MaxSim Log: `Container killed by YARN for exceeding memory limits. 46.2 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`.
	============  Query  ====================
	Log[1]: `Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[2]: `Container killed by YARN for exceeding memory limits. 46.5 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[3]: `Container killed by YARN for exceeding memory limits. 52.0 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Response ====================
LogTemplate[1]: `Container killed by YARN for exceeding memory limits. {memory_used} GB of {total_memory} GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ PostProcess ====================
	Post Template: `Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Aggregate ====================
	Aggregated Template:  Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.
[UpdateBucket] Logs: This iter found: 378, total: 16060116/16075117, remain: 15001. 
[UpdateBucket] Buckets: Checked 3 ([217, 218, 219]), Parent Bucket size: 685 -> 307, remain buckets: 90
Update Success: Time for one update logs: 0.030763626098632812, template `Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
========================================================================================


Iteration 92
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 358, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Successfully stopped SparkContext`
	============ Response ====================
LogTemplate[1]: `Successfully stopped SparkContext`
	============ PostProcess ====================
	Post Template: `Successfully stopped SparkContext`
	============ Aggregate ====================
	Aggregated Template:  Successfully stopped SparkContext
[UpdateBucket] Logs: This iter found: 64, total: 16060180/16075117, remain: 14937. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 2251 -> 2187, remain buckets: 90
Update Success: Time for one update logs: 0.06168508529663086, template `Successfully stopped SparkContext`
========================================================================================


Iteration 93
Sample 1 from current logs bucket: ID: 175, Len: 9, Bucket Size: 355, Total Buckets: 239
Sampling from 336 logs, Sim Level: 3, MaxSim to anchor: 0.6000. Anchor: `Exception in task 2.0 in stage 1.0 (TID 4)`, MaxSim Log: `Exception in task 8.0 in stage 1.0 (TID 10)`.
	============  Query  ====================
	Log[1]: `Exception in task 2.0 in stage 1.0 (TID 4)`
	Log[2]: `Exception in task 17.0 in stage 1.0 (TID 19)`
	Log[3]: `Exception in task 25.0 in stage 25.0 (TID 1075)`
	============ Response ====================
LogTemplate[1]: `Exception in task {task_id} in stage {stage_id} (TID {tid})`
	============ PostProcess ====================
	Post Template: `Exception in task <*> in stage <*> (TID <*>)`
	Post Template: `Exception in task <*> in stage <*> (TID <*>)`
	Post Template: `Exception in task <*> in stage <*> (TID <*>)`
	============ Aggregate ====================
	Aggregated Template:  Exception in task <*> in stage <*> (TID <*>)
[UpdateBucket] Logs: This iter found: 355, total: 16060535/16075117, remain: 14582. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 1644 -> 1289, remain buckets: 89
Update Success: Time for one update logs: 0.035392045974731445, template `Exception in task <*> in stage <*> (TID <*>)`
========================================================================================


Iteration 94
Sample 3 from current logs bucket: ID: 129, Len: 5, Bucket Size: 353, Total Buckets: 239
Sampling from 178 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Executor lost: 6 (epoch 0)`, MaxSim Log: `Executor lost: 2 (epoch 0)`.
	============  Query  ====================
	Log[1]: `Executor lost: 6 (epoch 0)`
	Log[2]: `Executor lost: 2 (epoch 0)`
	Log[3]: `Executor lost: 6 (epoch 2)`
	============ Response ====================
LogTemplate[1]: `Executor lost: {executor} (epoch {epoch})`
	============ PostProcess ====================
	Post Template: `Executor lost: <*> (epoch <*>)`
	Post Template: `Executor lost: <*> (epoch <*>)`
	Post Template: `Executor lost: <*> (epoch <*>)`
	============ Aggregate ====================
	Aggregated Template:  Executor lost: <*> (epoch <*>)
[UpdateBucket] Logs: This iter found: 353, total: 16060888/16075117, remain: 14229. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 2221 -> 1868, remain buckets: 88
Update Success: Time for one update logs: 0.03928399085998535, template `Executor lost: <*> (epoch <*>)`
========================================================================================


Iteration 95
Sample 3 from current logs bucket: ID: 130, Len: 5, Bucket Size: 353, Total Buckets: 239
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Removed 6 successfully in removeExecutor`, MaxSim Log: `Removed 2 successfully in removeExecutor`.
	============  Query  ====================
	Log[1]: `Removed 6 successfully in removeExecutor`
	Log[2]: `Removed 3 successfully in removeExecutor`
	Log[3]: `Removed 1 successfully in removeExecutor`
	============ Response ====================
LogTemplate[1]: `Removed {number} successfully in removeExecutor`
LogTemplate[2]: `Removed {number} successfully in removeExecutor`
LogTemplate[3]: `Removed {number} successfully in removeExecutor`
	============ PostProcess ====================
	Post Template: `Removed <*> successfully in removeExecutor`
	Post Template: `Removed <*> successfully in removeExecutor`
	Post Template: `Removed <*> successfully in removeExecutor`
	============ Aggregate ====================
	Aggregated Template:  Removed <*> successfully in removeExecutor
[UpdateBucket] Logs: This iter found: 353, total: 16061241/16075117, remain: 13876. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 1868 -> 1515, remain buckets: 87
Update Success: Time for one update logs: 0.03931093215942383, template `Removed <*> successfully in removeExecutor`
========================================================================================


Iteration 96
Sample 3 from current logs bucket: ID: 156, Len: 7, Bucket Size: 353, Total Buckets: 239
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Trying to remove executor 6 from BlockManagerMaster.`, MaxSim Log: `Trying to remove executor 2 from BlockManagerMaster.`.
	============  Query  ====================
	Log[1]: `Trying to remove executor 6 from BlockManagerMaster.`
	Log[2]: `Trying to remove executor 5 from BlockManagerMaster.`
	Log[3]: `Trying to remove executor 1 from BlockManagerMaster.`
	============ Response ====================
LogTemplate[1]: `Trying to remove executor {executor_id} from BlockManagerMaster.`
	============ PostProcess ====================
	Post Template: `Trying to remove executor <*> from BlockManagerMaster.`
	Post Template: `Trying to remove executor <*> from BlockManagerMaster.`
	Post Template: `Trying to remove executor <*> from BlockManagerMaster.`
	============ Aggregate ====================
	Aggregated Template:  Trying to remove executor <*> from BlockManagerMaster.
[UpdateBucket] Logs: This iter found: 353, total: 16061594/16075117, remain: 13523. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 1683 -> 1330, remain buckets: 86
Update Success: Time for one update logs: 0.039399147033691406, template `Trying to remove executor <*> from BlockManagerMaster.`
========================================================================================


Iteration 97
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 349, Total Buckets: 239
Sampling from 15 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2`, MaxSim Log: `Created broadcast 5 from textFile at NativeMethodAccessorImpl.java:-2`.
	============  Query  ====================
	Log[1]: `Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2`
	Log[2]: `Created broadcast 5 from textFile at NativeMethodAccessorImpl.java:-2`
	============ Response ====================
LogTemplate[1]: `Created broadcast {number} from textFile at NativeMethodAccessorImpl.java:-2`
LogTemplate[2]: `Created broadcast {number} from textFile at NativeMethodAccessorImpl.java:-2`
	============ PostProcess ====================
	Post Template: `Created broadcast <*> from textFile at NativeMethodAccessorImpl.java:-<*>`
	Post Template: `Created broadcast <*> from textFile at NativeMethodAccessorImpl.java:-<*>`
	============ Aggregate ====================
	Aggregated Template:  Created broadcast <*> from textFile at NativeMethodAccessorImpl.java:-<*>
[UpdateBucket] Logs: This iter found: 64, total: 16061658/16075117, remain: 13459. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 1330 -> 1266, remain buckets: 86
Update Success: Time for one update logs: 0.031549930572509766, template `Created broadcast <*> from textFile at NativeMethodAccessorImpl.java:-<*>`
========================================================================================


Iteration 98
Sample 3 from current logs bucket: ID: 19, Len: 3, Bucket Size: 347, Total Buckets: 239
Sampling from 98 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Cleaned accumulator 2`, MaxSim Log: `Cleaned accumulator 4`.
	============  Query  ====================
	Log[1]: `Cleaned accumulator 2`
	Log[2]: `Cleaned accumulator 37`
	Log[3]: `Cleaned accumulator 6`
	============ Response ====================
LogTemplate[1]: `Cleaned accumulator {accumulator}`  
LogTemplate[2]: `Cleaned accumulator {accumulator}`  
LogTemplate[3]: `Cleaned accumulator {accumulator}`  
	============ PostProcess ====================
	Post Template: `Cleaned accumulator <*>`
	Post Template: `Cleaned accumulator <*>`
	Post Template: `Cleaned accumulator <*>`
	============ Aggregate ====================
	Aggregated Template:  Cleaned accumulator <*>
[UpdateBucket] Logs: This iter found: 478, total: 16062136/16075117, remain: 12981. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 2187 -> 1709, remain buckets: 84
Update Success: Time for one update logs: 0.0740518569946289, template `Cleaned accumulator <*>`
========================================================================================


Iteration 99
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 343, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Waiting for spark context initialization`
	============ Response ====================
LogTemplate[1]: `Waiting for spark context initialization`
	============ PostProcess ====================
	Post Template: `Waiting for spark context initialization`
	============ Aggregate ====================
	Aggregated Template:  Waiting for spark context initialization
[UpdateBucket] Logs: This iter found: 64, total: 16062200/16075117, remain: 12917. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 1515 -> 1451, remain buckets: 84
Update Success: Time for one update logs: 0.021335840225219727, template `Waiting for spark context initialization`
========================================================================================


Iteration 100
Sample 1 from current logs bucket: ID: 145, Len: 6, Bucket Size: 341, Total Buckets: 239
Sampling from 107 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Stopped Spark web UI at http://10.10.34.23:33134`, MaxSim Log: `Stopped Spark web UI at http://10.10.34.31:51961`.
	============  Query  ====================
	Log[1]: `Stopped Spark web UI at http://10.10.34.23:33134`
	Log[2]: `Stopped Spark web UI at http://10.10.34.36:48724`
	Log[3]: `Stopped Spark web UI at http://10.10.34.17:51244`
	============ Response ====================
LogTemplate[1]: `Stopped Spark web UI at http://{ip_or_url}:{port}`  
LogTemplate[2]: `Stopped Spark web UI at http://{ip_or_url}:{port}`  
LogTemplate[3]: `Stopped Spark web UI at http://{ip_or_url}:{port}`  
	============ PostProcess ====================
	Post Template: `Stopped Spark web UI at http://<*>`
	Post Template: `Stopped Spark web UI at http://<*>`
	Post Template: `Stopped Spark web UI at http://<*>`
	============ Aggregate ====================
	Aggregated Template:  Stopped Spark web UI at http://<*>
[UpdateBucket] Logs: This iter found: 64, total: 16062264/16075117, remain: 12853. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 1773 -> 1709, remain buckets: 84
Update Success: Time for one update logs: 0.030005931854248047, template `Stopped Spark web UI at http://<*>`
========================================================================================


Iteration 101
Sample 3 from current logs bucket: ID: 138, Len: 6, Bucket Size: 336, Total Buckets: 239
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Asked to remove non-existent executor 1`, MaxSim Log: `Asked to remove non-existent executor 6`.
	============  Query  ====================
	Log[1]: `Asked to remove non-existent executor 1`
	Log[2]: `Asked to remove non-existent executor 13`
	Log[3]: `Asked to remove non-existent executor 10`
	============ Response ====================
LogTemplate[1]: `Asked to remove non-existent executor {executor_id}`  
LogTemplate[2]: `Asked to remove non-existent executor {executor_id}`  
LogTemplate[3]: `Asked to remove non-existent executor {executor_id}`  
	============ PostProcess ====================
	Post Template: `Asked to remove non-existent executor <*>`
	Post Template: `Asked to remove non-existent executor <*>`
	Post Template: `Asked to remove non-existent executor <*>`
	============ Aggregate ====================
	Aggregated Template:  Asked to remove non-existent executor <*>
[UpdateBucket] Logs: This iter found: 336, total: 16062600/16075117, remain: 12517. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 1709 -> 1373, remain buckets: 83
Update Success: Time for one update logs: 0.031494855880737305, template `Asked to remove non-existent executor <*>`
========================================================================================


Iteration 102
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 334, Total Buckets: 239
Sampling from 63 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Started SparkUI at http://10.10.34.23:33134`, MaxSim Log: `Started SparkUI at http://10.10.34.31:51961`.
	============  Query  ====================
	Log[1]: `Started SparkUI at http://10.10.34.23:33134`
	Log[2]: `Started SparkUI at http://10.10.34.24:47193`
	Log[3]: `Started SparkUI at http://10.10.34.38:32805`
	============ Response ====================
LogTemplate[1]: `Started SparkUI at http://{ip_or_url}:{port}`
	============ PostProcess ====================
	Post Template: `Started SparkUI at http://<*>`
	Post Template: `Started SparkUI at http://<*>`
	Post Template: `Started SparkUI at http://<*>`
	============ Aggregate ====================
	Aggregated Template:  Started SparkUI at http://<*>
[UpdateBucket] Logs: This iter found: 64, total: 16062664/16075117, remain: 12453. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 587 -> 523, remain buckets: 83
Update Success: Time for one update logs: 0.025588035583496094, template `Started SparkUI at http://<*>`
========================================================================================


Iteration 103
Sample 3 from current logs bucket: ID: 18, Len: 3, Bucket Size: 333, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Remoting shut down.`
	============ Response ====================
LogTemplate[1]: `Remoting shut down.`
	============ PostProcess ====================
	Post Template: `Remoting shut down.`
	============ Aggregate ====================
	Aggregated Template:  Remoting shut down.
[UpdateBucket] Logs: This iter found: 333, total: 16062997/16075117, remain: 12120. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 1709 -> 1376, remain buckets: 82
Update Success: Time for one update logs: 0.06212973594665527, template `Remoting shut down.`
========================================================================================


Iteration 104
Sample 3 from current logs bucket: ID: 17, Len: 3, Bucket Size: 330, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Missing parents: List()`
	============ Response ====================
LogTemplate[1]: `Missing parents: List()`
	============ PostProcess ====================
	Post Template: `Missing parents: List()`
	============ Aggregate ====================
	Aggregated Template:  Missing parents: List()
[UpdateBucket] Logs: This iter found: 330, total: 16063327/16075117, remain: 11790. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 1376 -> 1046, remain buckets: 81
Update Success: Time for one update logs: 0.05321002006530762, template `Missing parents: List()`
========================================================================================


Iteration 105
Sample 3 from current logs bucket: ID: 140, Len: 6, Bucket Size: 324, Total Buckets: 239
Sampling from 317 logs, Sim Level: 2, MaxSim to anchor: 0.5000. Anchor: `Removing block manager BlockManagerId(6, mesos-slave-27, 54380)`, MaxSim Log: `Removing block manager BlockManagerId(6, mesos-slave-19, 47674)`.
	============  Query  ====================
	Log[1]: `Removing block manager BlockManagerId(6, mesos-slave-27, 54380)`
	Log[2]: `Removing block manager BlockManagerId(10, mesos-slave-27, 59217)`
	Log[3]: `Removing block manager BlockManagerId(1, mesos-slave-27, 37801)`
	============ Response ====================
LogTemplate[1]: `Removing block manager BlockManagerId(<*>, mesos-slave-27, <*>)`
	============ PostProcess ====================
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)`
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)`
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)`
	============ Aggregate ====================
	Aggregated Template:  Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)
[UpdateBucket] Logs: This iter found: 285, total: 16063612/16075117, remain: 11505. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 1373 -> 1088, remain buckets: 81
Update Success: Time for one update logs: 0.03930211067199707, template `Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)`
========================================================================================


Iteration 106
Sample 3 from current logs bucket: ID: 151, Len: 7, Bucket Size: 316, Total Buckets: 239
Sampling from 315 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Launching container container_1485248649253_0020_02_000007 for on host mesos-master-1`, MaxSim Log: `Launching container container_1485248649253_0037_02_000012 for on host mesos-master-1`.
	============  Query  ====================
	Log[1]: `Launching container container_1485248649253_0020_02_000007 for on host mesos-master-1`
	Log[2]: `Launching container container_1485248649253_0131_01_000032 for on host mesos-master-3`
	Log[3]: `Launching container container_1485248649253_0139_01_000010 for on host mesos-master-2`
	============ Response ====================
LogTemplate[1]: `Launching container container_<*> for on host mesos-master-<*>`
LogTemplate[2]: `Launching container container_<*> for on host mesos-master-<*>`
LogTemplate[3]: `Launching container container_<*> for on host mesos-master-<*>`
	============ PostProcess ====================
	Post Template: `Launching container <*> for on host mesos-master-<*>`
	Post Template: `Launching container <*> for on host mesos-master-<*>`
	Post Template: `Launching container <*> for on host mesos-master-<*>`
	============ Aggregate ====================
	Aggregated Template:  Launching container <*> for on host mesos-master-<*>
[UpdateBucket] Logs: This iter found: 316, total: 16063928/16075117, remain: 11189. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 1266 -> 950, remain buckets: 80
[TemplateDB] Try Merge: `Launching container <*> for on host mesos-master-<*>` | `Launching container <*> for on host mesos-slave-<*>`
	Post Template: `Launching container <*> for on host mesos-<*>`
[TemplateDB] Merged: -> `Launching container <*> for on host mesos-<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2561/2561, in child Bucket [146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]
[UpdateBucket] Logs: This iter found: 0, total: 16063928/16075117, remain: 11189. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 950 -> 950, remain buckets: 80
[TemplateDB] Update Indexes: 2561 -> 2561 for `Launching container <*> for on host mesos-<*>`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Launching container <*> for on host mesos-<*>`
Update Success: Time for one update logs: 0.1065208911895752, template `Launching container <*> for on host mesos-master-<*>`
========================================================================================


Iteration 107
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 309, Total Buckets: 239
Sampling from 146 logs, Sim Level: 7, MaxSim to anchor: 0.8000. Anchor: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:332) failed in 76.251 s`, MaxSim Log: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:332) failed in 303.435 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:332) failed in 76.251 s`
	Log[2]: `ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) failed in 266.276 s`
	Log[3]: `ShuffleMapStage 3 (reduceByKey at pnmf4.py:357) failed in 253.608 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:{line_num}) failed in {duration} s`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s
[UpdateBucket] Logs: This iter found: 25, total: 16063953/16075117, remain: 11164. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 1289 -> 1264, remain buckets: 80
Update Success: Time for one update logs: 0.032550811767578125, template `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s`
========================================================================================


Iteration 108
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 294, Total Buckets: 239
Sampling from 4 logs, Sim Level: 2, MaxSim to anchor: 0.5000. Anchor: `Cancelling stage 1`, MaxSim Log: `Cancelling stage 3`.
	============  Query  ====================
	Log[1]: `Cancelling stage 1`
	Log[2]: `Cancelling stage 3`
	Log[3]: `Cancelling stage 108`
	============ Response ====================
LogTemplate[1]: `Cancelling stage {stage_number}`
LogTemplate[2]: `Cancelling stage {stage_number}`
LogTemplate[3]: `Cancelling stage {stage_number}`
	============ PostProcess ====================
	Post Template: `Cancelling stage <*>`
	Post Template: `Cancelling stage <*>`
	Post Template: `Cancelling stage <*>`
	============ Aggregate ====================
	Aggregated Template:  Cancelling stage <*>
[UpdateBucket] Logs: This iter found: 26, total: 16063979/16075117, remain: 11138. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 1046 -> 1020, remain buckets: 80
Update Success: Time for one update logs: 0.06627511978149414, template `Cancelling stage <*>`
========================================================================================


Iteration 109
Sample 3 from current logs bucket: ID: 127, Len: 5, Bucket Size: 293, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Failed while starting block fetches`
	============ Response ====================
LogTemplate[1]: `Failed while starting block fetches`
	============ PostProcess ====================
	Post Template: `Failed while starting block fetches`
	============ Aggregate ====================
	Aggregated Template:  Failed while starting block fetches
[UpdateBucket] Logs: This iter found: 293, total: 16064272/16075117, remain: 10845. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 1451 -> 1158, remain buckets: 79
Update Success: Time for one update logs: 0.025612831115722656, template `Failed while starting block fetches`
========================================================================================


Iteration 110
Sample 1 from current logs bucket: ID: 142, Len: 6, Bucket Size: 291, Total Buckets: 239
Sampling from 233 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Removing RDD 52 from persistence list`, MaxSim Log: `Removing RDD 62 from persistence list`.
	============  Query  ====================
	Log[1]: `Removing RDD 52 from persistence list`
	Log[2]: `Removing RDD 247 from persistence list`
	Log[3]: `Removing RDD 167 from persistence list`
	============ Response ====================
LogTemplate[1]: `Removing RDD {rdd_id} from persistence list`
LogTemplate[2]: `Removing RDD {rdd_id} from persistence list`
LogTemplate[3]: `Removing RDD {rdd_id} from persistence list`
	============ PostProcess ====================
	Post Template: `Removing RDD <*> from persistence list`
	Post Template: `Removing RDD <*> from persistence list`
	Post Template: `Removing RDD <*> from persistence list`
	============ Aggregate ====================
	Aggregated Template:  Removing RDD <*> from persistence list
[UpdateBucket] Logs: This iter found: 291, total: 16064563/16075117, remain: 10554. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 1088 -> 797, remain buckets: 78
Update Success: Time for one update logs: 0.028855085372924805, template `Removing RDD <*> from persistence list`
========================================================================================


Iteration 111
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 285, Total Buckets: 239
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.0769. Anchor: `Total input paths to process : 1`, MaxSim Log: `Waiting for Spark driver to be reachable.`.
	============  Query  ====================
	Log[1]: `Total input paths to process : 1`
	============ Response ====================
LogTemplate[1]: `Total input paths to process : {number}`
	============ PostProcess ====================
	Post Template: `Total input paths to process : <*>`
	============ Aggregate ====================
	Aggregated Template:  Total input paths to process : <*>
[UpdateBucket] Logs: This iter found: 64, total: 16064627/16075117, remain: 10490. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 950 -> 886, remain buckets: 78
Update Success: Time for one update logs: 0.029431819915771484, template `Total input paths to process : <*>`
========================================================================================


Iteration 112
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 284, Total Buckets: 239
Sampling from 120 logs, Sim Level: 4, MaxSim to anchor: 0.8000. Anchor: `ShuffleMapStage 11 (reduceByKey at pnmf_dblp.py:430) failed in 24.026 s`, MaxSim Log: `ShuffleMapStage 11 (reduceByKey at pnmf_dblp.py:430) failed in 49.980 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 11 (reduceByKey at pnmf_dblp.py:430) failed in 24.026 s`
	Log[2]: `ShuffleMapStage 11 (reduceByKey at pnmf_dblp.py:430) failed in 137.358 s`
	Log[3]: `ShuffleMapStage 11 (reduceByKey at pnmf_amz.py:430) failed in 174.941 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:430) failed in {time} s`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s
[UpdateBucket] Logs: This iter found: 13, total: 16064640/16075117, remain: 10477. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 1264 -> 1251, remain buckets: 78
[TemplateDB] Try Merge: `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s` | `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) failed in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
[TemplateDB] Merged: -> `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 38/38, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
Update Success: Time for one update logs: 0.023857831954956055, template `ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s`
========================================================================================


Iteration 113
Sample 3 from current logs bucket: ID: 217, Len: 19, Bucket Size: 284, Total Buckets: 239
Sampling from 174 logs, Sim Level: 3, MaxSim to anchor: 0.8889. Anchor: `Stage 1 contains a task of very large size (1181 KB). The maximum recommended task size is 100 KB.`, MaxSim Log: `Stage 2 contains a task of very large size (1181 KB). The maximum recommended task size is 100 KB.`.
	============  Query  ====================
	Log[1]: `Stage 1 contains a task of very large size (1181 KB). The maximum recommended task size is 100 KB.`
	Log[2]: `Stage 90 contains a task of very large size (1807 KB). The maximum recommended task size is 100 KB.`
	Log[3]: `Stage 11 contains a task of very large size (80425 KB). The maximum recommended task size is 100 KB.`
	============ Response ====================
LogTemplate[1]: `Stage {stage_number} contains a task of very large size ({task_size} KB). The maximum recommended task size is 100 KB.`

LogTemplate[2]: `Stage {stage_number} contains a task of very large size ({task_size} KB). The maximum recommended task size is 100 KB.`

LogTemplate[3]: `Stage {stage_number} contains a task of very large size ({task_size} KB). The maximum recommended task size is 100 KB.`
	============ PostProcess ====================
	Post Template: `Stage <*> contains a task of very large size (<*> KB). The maximum recommended task size is <*> KB.`
	Post Template: `Stage <*> contains a task of very large size (<*> KB). The maximum recommended task size is <*> KB.`
	Post Template: `Stage <*> contains a task of very large size (<*> KB). The maximum recommended task size is <*> KB.`
	============ Aggregate ====================
	Aggregated Template:  Stage <*> contains a task of very large size (<*> KB). The maximum recommended task size is <*> KB.
[UpdateBucket] Logs: This iter found: 284, total: 16064924/16075117, remain: 10193. 
[UpdateBucket] Buckets: Checked 3 ([217, 218, 219]), Parent Bucket size: 307 -> 23, remain buckets: 77
Update Success: Time for one update logs: 0.0241849422454834, template `Stage <*> contains a task of very large size (<*> KB). The maximum recommended task size is <*> KB.`
========================================================================================


Iteration 114
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 279, Total Buckets: 239
Sampling from 24 logs failed
	============  Query  ====================
	Log[1]: `Invoking stop() from shutdown hook`
	============ Response ====================
LogTemplate[1]: `Invoking stop() from shutdown hook`
	============ PostProcess ====================
	Post Template: `Invoking stop() from shutdown hook`
	============ Aggregate ====================
	Aggregated Template:  Invoking stop() from shutdown hook
[UpdateBucket] Logs: This iter found: 64, total: 16064988/16075117, remain: 10129. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 1158 -> 1094, remain buckets: 77
Update Success: Time for one update logs: 0.013423681259155273, template `Invoking stop() from shutdown hook`
========================================================================================


Iteration 115
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 277, Total Buckets: 239
Sampling from 13 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `Asking each executor to shut down`, MaxSim Log: `Reporting 1066 blocks to the master.`.
	============  Query  ====================
	Log[1]: `Asking each executor to shut down`
	============ Response ====================
LogTemplate[1]: `Asking each executor to shut down`
	============ PostProcess ====================
	Post Template: `Asking each executor to shut down`
	============ Aggregate ====================
	Aggregated Template:  Asking each executor to shut down
[UpdateBucket] Logs: This iter found: 64, total: 16065052/16075117, remain: 10065. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 797 -> 733, remain buckets: 77
Update Success: Time for one update logs: 0.019301891326904297, template `Asking each executor to shut down`
========================================================================================


Iteration 116
Sample 3 from current logs bucket: ID: 177, Len: 9, Bucket Size: 277, Total Buckets: 239
Sampling from 276 logs, Sim Level: 2, MaxSim to anchor: 0.8000. Anchor: `org.apache.spark.SparkException: Exception while starting container container_1485248649253_0037_01_000002 on host mesos-slave-16`, MaxSim Log: `org.apache.spark.SparkException: Exception while starting container container_1485248649253_0037_02_000019 on host mesos-slave-16`.
	============  Query  ====================
	Log[1]: `org.apache.spark.SparkException: Exception while starting container container_1485248649253_0037_01_000002 on host mesos-slave-16`
	Log[2]: `org.apache.spark.SparkException: Exception while starting container container_1485248649253_0143_01_000011 on host mesos-slave-16`
	Log[3]: `org.apache.spark.SparkException: Exception while starting container container_1485248649253_0101_01_000013 on host mesos-slave-09`
	============ Response ====================
LogTemplate[1]: `org.apache.spark.SparkException: Exception while starting container container_<*> on host mesos-slave-<*>`
	============ PostProcess ====================
	Post Template: `org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>`
	Post Template: `org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>`
	Post Template: `org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>`
	============ Aggregate ====================
	Aggregated Template:  org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>
[UpdateBucket] Logs: This iter found: 277, total: 16065329/16075117, remain: 9788. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 1251 -> 974, remain buckets: 76
Update Success: Time for one update logs: 0.02940082550048828, template `org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>`
========================================================================================


Iteration 117
Sample 3 from current logs bucket: ID: 204, Len: 13, Bucket Size: 277, Total Buckets: 239
Sampling from 184 logs, Sim Level: 5, MaxSim to anchor: 0.8571. Anchor: `Failed to fetch remote block broadcast_6_piece283 from BlockManagerId(4, mesos-slave-20, 33900) (failed attempt 1)`, MaxSim Log: `Failed to fetch remote block broadcast_5_piece128 from BlockManagerId(4, mesos-slave-20, 33900) (failed attempt 1)`.
	============  Query  ====================
	Log[1]: `Failed to fetch remote block broadcast_6_piece283 from BlockManagerId(4, mesos-slave-20, 33900) (failed attempt 1)`
	Log[2]: `Failed to fetch remote block broadcast_4_piece215 from BlockManagerId(16, mesos-slave-19, 50105) (failed attempt 1)`
	Log[3]: `Failed to fetch remote block broadcast_6_piece89 from BlockManagerId(2, mesos-slave-27, 36033) (failed attempt 1)`
	============ Response ====================
LogTemplate[1]: `Failed to fetch remote block {block_name} from BlockManagerId(<*>, {block_manager}, <*>) (failed attempt <*>)`
	============ PostProcess ====================
	Post Template: `Failed to fetch remote block <*> from BlockManagerId(<*>, <*> <*>) (failed attempt <*>)`
	Post Template: `Failed to fetch remote block <*> from BlockManagerId(<*>, <*> <*>) (failed attempt <*>)`
	Post Template: `Failed to fetch remote block <*> from BlockManagerId(<*>, <*> <*>) (failed attempt <*>)`
	============ Aggregate ====================
	Aggregated Template:  Failed to fetch remote block <*> from BlockManagerId(<*>, <*> <*>) (failed attempt <*>)
[UpdateBucket] Logs: This iter found: 185, total: 16065514/16075117, remain: 9603. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 419 -> 234, remain buckets: 76
Update Success: Time for one update logs: 0.022871017456054688, template `Failed to fetch remote block <*> from BlockManagerId(<*>, <*> <*>) (failed attempt <*>)`
========================================================================================


Iteration 118
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 271, Total Buckets: 239
Sampling from 108 logs, Sim Level: 4, MaxSim to anchor: 0.8000. Anchor: `Job 1 failed: count at pnmf4.py:333, took 76.277073 s`, MaxSim Log: `Job 1 failed: count at pnmf4.py:333, took 303.460612 s`.
	============  Query  ====================
	Log[1]: `Job 1 failed: count at pnmf4.py:333, took 76.277073 s`
	Log[2]: `Job 2 failed: count at pnmf4.py:353, took 204.671906 s`
	Log[3]: `Job 3 failed: count at pnmf4.py:358, took 253.643796 s`
	============ Response ====================
LogTemplate[1]: `Job {job_num} failed: count at pnmf4.py:{line_num}, took {duration} s`
LogTemplate[2]: `Job {job_num} failed: count at pnmf4.py:{line_num}, took {duration} s`
LogTemplate[3]: `Job {job_num} failed: count at pnmf4.py:{line_num}, took {duration} s`
	============ PostProcess ====================
	Post Template: `Job <*> failed: count at pnmf4.py:<*>, took <*> s`
	Post Template: `Job <*> failed: count at pnmf4.py:<*>, took <*> s`
	Post Template: `Job <*> failed: count at pnmf4.py:<*>, took <*> s`
	============ Aggregate ====================
	Aggregated Template:  Job <*> failed: count at pnmf4.py:<*>, took <*> s
[UpdateBucket] Logs: This iter found: 11, total: 16065525/16075117, remain: 9592. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 974 -> 963, remain buckets: 76
Update Success: Time for one update logs: 0.025368928909301758, template `Job <*> failed: count at pnmf4.py:<*>, took <*> s`
========================================================================================


Iteration 119
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 270, Total Buckets: 239
Sampling from 64 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.23:47891)`, MaxSim Log: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.31:34500)`.
	============  Query  ====================
	Log[1]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.23:47891)`
	Log[2]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.24:48530)`
	Log[3]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.37:44872)`
	============ Response ====================
LogTemplate[1]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@{ip}:<*> )`
	============ PostProcess ====================
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*> )`
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*> )`
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*> )`
	============ Aggregate ====================
	Aggregated Template:  ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*> )
[UpdateBucket] Logs: This iter found: 0, total: 16065525/16075117, remain: 9592. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 523 -> 523, remain buckets: 76
Update failed: Template can not match logs `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*> )`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 270, Total Buckets: 239
Sampling from 64 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.23:47891)`, MaxSim Log: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.31:34500)`.
	============  Query  ====================
	Log[1]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.23:47891)`
	Log[2]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.38:36751)`
	Log[3]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.30:45563)`
	============ Response ====================
LogTemplate[1]: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@{ip}:47891)`
	============ PostProcess ====================
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)`
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)`
	Post Template: `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)`
	============ Aggregate ====================
	Aggregated Template:  ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)
[UpdateBucket] Logs: This iter found: 64, total: 16065589/16075117, remain: 9528. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 523 -> 459, remain buckets: 76
Update Success: Time for one update logs: 0.029705286026000977, template `ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)`
========================================================================================


Iteration 120
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 268, Total Buckets: 239
Sampling from 36 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Message RemoteProcessDisconnected(mesos-slave-11:45333) dropped.`, MaxSim Log: `Message RemoteProcessDisconnected(mesos-slave-11:45318) dropped.`.
	============  Query  ====================
	Log[1]: `Message RemoteProcessDisconnected(mesos-slave-11:45333) dropped.`
	Log[2]: `Message RemoteProcessDisconnected(mesos-slave-21:45292) dropped.`
	Log[3]: `Message RemoteProcessDisconnected(mesos-slave-10:56061) dropped.`
	============ Response ====================
LogTemplate[1]: `Message RemoteProcessDisconnected({hostname}:{port}) dropped.`
	============ PostProcess ====================
	Post Template: `Message RemoteProcessDisconnected(<*>) dropped.`
	Post Template: `Message RemoteProcessDisconnected(<*>) dropped.`
	Post Template: `Message RemoteProcessDisconnected(<*>) dropped.`
	============ Aggregate ====================
	Aggregated Template:  Message RemoteProcessDisconnected(<*>) dropped.
[UpdateBucket] Logs: This iter found: 68, total: 16065657/16075117, remain: 9460. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 1020 -> 952, remain buckets: 76
Update Success: Time for one update logs: 0.05722808837890625, template `Message RemoteProcessDisconnected(<*>) dropped.`
========================================================================================


Iteration 121
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 260, Total Buckets: 239
Sampling from 97 logs, Sim Level: 4, MaxSim to anchor: 0.8000. Anchor: `Job 4 failed: count at pnmf_dblp.py:432, took 469.055113 s`, MaxSim Log: `Job 4 failed: count at pnmf_dblp.py:432, took 411.936224 s`.
	============  Query  ====================
	Log[1]: `Job 4 failed: count at pnmf_dblp.py:432, took 469.055113 s`
	Log[2]: `Job 4 failed: count at pnmf_dblp.py:432, took 690.315495 s`
	Log[3]: `Job 3 failed: count at pnmf_dblp.py:425, took 912.227876 s`
	============ Response ====================
LogTemplate[1]: `Job {job_id} failed: count at {file}:<*> s`  
LogTemplate[2]: `Job {job_id} failed: count at {file}:<*> s`  
LogTemplate[3]: `Job {job_id} failed: count at {file}:<*> s`  
	============ PostProcess ====================
	Post Template: `Job <*> failed: count at <*> s`
	Post Template: `Job <*> failed: count at <*> s`
	Post Template: `Job <*> failed: count at <*> s`
	============ Aggregate ====================
	Aggregated Template:  Job <*> failed: count at <*> s
[UpdateBucket] Logs: This iter found: 4, total: 16065661/16075117, remain: 9456. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 963 -> 959, remain buckets: 76
Update Success: Time for one update logs: 0.028428077697753906, template `Job <*> failed: count at <*> s`
========================================================================================


Iteration 122
Sample 3 from current logs bucket: ID: 11, Len: 2, Bucket Size: 256, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Registering MapOutputTracker`
	============ Response ====================
LogTemplate[1]: `Registering MapOutputTracker`
	============ PostProcess ====================
	Post Template: `Registering MapOutputTracker`
	============ Aggregate ====================
	Aggregated Template:  Registering MapOutputTracker
[UpdateBucket] Logs: This iter found: 64, total: 16065725/16075117, remain: 9392. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 1002 -> 938, remain buckets: 76
Update Success: Time for one update logs: 0.01570296287536621, template `Registering MapOutputTracker`
========================================================================================


Iteration 123
Sample 1 from current logs bucket: ID: 181, Len: 9, Bucket Size: 256, Total Buckets: 239
Sampling from 77 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0166),/proxy/application_1485248649253_0166)`, MaxSim Log: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0001),/proxy/application_1485248649253_0001)`.
	============  Query  ====================
	Log[1]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0166),/proxy/application_1485248649253_0166)`
	Log[2]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0091),/proxy/application_1485248649253_0091)`
	Log[3]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_1485248649253_0096),/proxy/application_1485248649253_0096)`
	============ Response ====================
LogTemplate[1]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_{application_id}),/proxy/application_{application_id})`
LogTemplate[2]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_{application_id}),/proxy/application_{application_id})`
LogTemplate[3]: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-1, PROXY_URI_BASES -> http://mesos-master-1:8088/proxy/application_{application_id}),/proxy/application_{application_id})`
	============ PostProcess ====================
	Post Template: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)`
	Post Template: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)`
	Post Template: `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)`
	============ Aggregate ====================
	Aggregated Template:  Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)
[UpdateBucket] Logs: This iter found: 78, total: 16065803/16075117, remain: 9314. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 959 -> 881, remain buckets: 76
Update Success: Time for one update logs: 0.02589106559753418, template `Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)`
========================================================================================


Iteration 124
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 244, Total Buckets: 239
Sampling from 243 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(1,[Lscala.Tuple2;@299c8a57,BlockManagerId(1, mesos-master-1, 59368))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(9,[Lscala.Tuple2;@4771161c,BlockManagerId(9, mesos-slave-13, 47414))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(73,[Lscala.Tuple2;@703739b2,BlockManagerId(73, mesos-slave-08, 39817))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*>, <*>)]) in <* attempts`
LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*>, <*>)]) in <* attempts`
LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*>, <*>)]) in <* attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*>)]) in <* attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*>)]) in <* attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*>)]) in <* attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*>)]) in <* attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065803/16075117, remain: 9314. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 522 -> 522, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*>)]) in <* attempts`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 244, Total Buckets: 239
Sampling from 243 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(1,[Lscala.Tuple2;@299c8a57,BlockManagerId(1, mesos-master-1, 59368))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(2,[Lscala.Tuple2;@5ea1b8f1,BlockManagerId(2, mesos-slave-13, 55321))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(3,[Lscala.Tuple2;@5ff40a76,BlockManagerId(3, mesos-slave-19, 42990))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{placeholder},BlockManagerId(<*>, <*>, <*])] in <* attempts`
LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{placeholder},BlockManagerId(<*>, <*>, <*])] in <* attempts`
LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{placeholder},BlockManagerId(<*>, <*>, <*])] in <* attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*])] in <* attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*])] in <* attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*])] in <* attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*])] in <* attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065803/16075117, remain: 9314. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 522 -> 522, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, <*> <*])] in <* attempts`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 244, Total Buckets: 239
Sampling from 243 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(1,[Lscala.Tuple2;@299c8a57,BlockManagerId(1, mesos-master-1, 59368))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(14,[Lscala.Tuple2;@12236bdc,BlockManagerId(14, mesos-master-1, 42483))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(29,[Lscala.Tuple2;@48b53def,BlockManagerId(29, mesos-slave-19, 59688))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(65,[Lscala.Tuple2;@17b2c9aa,BlockManagerId(65, mesos-slave-22, 34767))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`

LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`

LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065803/16075117, remain: 9314. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 522 -> 522, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[<*>;@<*>],BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@12236bdc,BlockManagerId(<*>, mesos-master-<*>, <*>))] in <*> attempts`
[UpdateBucket] Logs: This iter found: 1, total: 16065804/16075117, remain: 9313. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 522 -> 521, remain buckets: 76
Update Success: Time for one update logs: 0.017040252685546875, template `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@12236bdc,BlockManagerId(<*>, mesos-master-<*>, <*>))] in <*> attempts`
========================================================================================


Iteration 125
Sample 3 from current logs bucket: ID: 197, Len: 12, Bucket Size: 244, Total Buckets: 239
Sampling from 208 logs, Sim Level: 5, MaxSim to anchor: 0.8333. Anchor: `Submitting 48 missing tasks from ResultStage 1 (PythonRDD[4] at count at pnmf4.py:353)`, MaxSim Log: `Submitting 48 missing tasks from ResultStage 1 (PythonRDD[4] at count at pnmf4.py:351)`.
	============  Query  ====================
	Log[1]: `Submitting 48 missing tasks from ResultStage 1 (PythonRDD[4] at count at pnmf4.py:353)`
	Log[2]: `Submitting 4 missing tasks from ResultStage 1 (PythonRDD[4] at count at pnmf4.py:358)`
	Log[3]: `Submitting 40 missing tasks from ResultStage 1 (PythonRDD[4] at count at pnmf4.py:356)`
	============ Response ====================
LogTemplate[1]: `Submitting {task_count} missing tasks from ResultStage {stage_num} ({rdd_type}[{rdd_num}] at count at pnmf4.py:{line_num})`
	============ PostProcess ====================
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)`
	============ Aggregate ====================
	Aggregated Template:  Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)
[UpdateBucket] Logs: This iter found: 28, total: 16065832/16075117, remain: 9285. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 536 -> 508, remain buckets: 76
Update Success: Time for one update logs: 0.02144908905029297, template `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)`
========================================================================================


Iteration 126
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 243, Total Buckets: 239
Sampling from 242 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(13,[Lscala.Tuple2;@7f2dc9f,BlockManagerId(13, mesos-slave-14, 40491))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(3,[Lscala.Tuple2;@2e4ca594,BlockManagerId(3, mesos-slave-05, 57372))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(9,[Lscala.Tuple2;@4771161c,BlockManagerId(9, mesos-slave-13, 47414))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`
LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`
LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065832/16075117, remain: 9285. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 521 -> 521, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 243, Total Buckets: 239
Sampling from 242 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(13,[Lscala.Tuple2;@7f2dc9f,BlockManagerId(13, mesos-slave-14, 40491))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(24,[Lscala.Tuple2;@7f396b32,BlockManagerId(24, mesos-slave-10, 53449))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(4,[Lscala.Tuple2;@719e9221,BlockManagerId(4, mesos-slave-13, 40185))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{api},BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`  
LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{api},BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`  
LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@{api},BlockManagerId(<*>, mesos-slave-<*>, <*])] in 1 attempts`  
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065832/16075117, remain: 9285. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 521 -> 521, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-slave-<*>, <*])] in <*> attempts`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 193, Len: 11, Bucket Size: 243, Total Buckets: 239
Sampling from 242 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`, MaxSim Log: `Error sending message [message = Heartbeat(13,[Lscala.Tuple2;@7f2dc9f,BlockManagerId(13, mesos-slave-14, 40491))] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = Heartbeat(7,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(7, mesos-slave-14, 41961))] in 1 attempts`
	Log[2]: `Error sending message [message = Heartbeat(1,[Lscala.Tuple2;@37ce3e31,BlockManagerId(1, mesos-slave-27, 53608))] in 1 attempts`
	Log[3]: `Error sending message [message = Heartbeat(62,[Lscala.Tuple2;@130eff16,BlockManagerId(62, mesos-slave-22, 46382))] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in 1 attempts`  
LogTemplate[2]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in 1 attempts`  
LogTemplate[3]: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in 1 attempts`  
	============ PostProcess ====================
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in <*> attempts
[UpdateBucket] Logs: This iter found: 0, total: 16065832/16075117, remain: 9285. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 521 -> 521, remain buckets: 76
Update failed: Template can not match logs `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>],BlockManagerId(<*>, mesos-slave-<*>)] in <*> attempts`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(<*>, mesos-slave-<*>, <*>))] in <*> attempts`
[UpdateBucket] Logs: This iter found: 1, total: 16065833/16075117, remain: 9284. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 521 -> 520, remain buckets: 76
[TemplateDB] Try Merge: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(<*>, mesos-slave-<*>, <*>))] in <*> attempts` | `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@12236bdc,BlockManagerId(<*>, mesos-master-<*>, <*>))] in <*> attempts`
	Post Template: `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
[TemplateDB] Merged: -> `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2/2, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
[UpdateBucket] Logs: This iter found: 242, total: 16066075/16075117, remain: 9042. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 520 -> 278, remain buckets: 75
[TemplateDB] Update Indexes: 2 -> 244 for `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
[TemplateBaseUpdate] Match unparsed logs 242 with new template `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts`
Update Success: Time for one update logs: 0.03237199783325195, template `Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@32a6ba4e,BlockManagerId(<*>, mesos-slave-<*>, <*>))] in <*> attempts`
========================================================================================


Iteration 127
Sample 3 from current logs bucket: ID: 190, Len: 11, Bucket Size: 229, Total Buckets: 239
Sampling from 131 logs, Sim Level: 2, MaxSim to anchor: 0.8333. Anchor: `Still have 1 requests outstanding when connection from mesos-slave-20/10.10.34.30:33900 is closed`, MaxSim Log: `Still have 1 requests outstanding when connection from mesos-master-1/10.10.34.11:60970 is closed`.
	============  Query  ====================
	Log[1]: `Still have 1 requests outstanding when connection from mesos-slave-20/10.10.34.30:33900 is closed`
	Log[2]: `Still have 4 requests outstanding when connection from mesos-slave-20/10.10.34.30:45641 is closed`
	Log[3]: `Still have 2 requests outstanding when connection from mesos-slave-18/10.10.34.28:37604 is closed`
	============ Response ====================
LogTemplate[1]: `Still have {number} requests outstanding when connection from mesos-slave-20/{ip_or_url} is closed`  
LogTemplate[2]: `Still have {number} requests outstanding when connection from mesos-slave-20/{ip_or_url} is closed`  
LogTemplate[3]: `Still have {number} requests outstanding when connection from mesos-slave-18/{ip_or_url} is closed`  
	============ PostProcess ====================
	Post Template: `Still have <*> requests outstanding when connection from mesos-slave-20/<*> is closed`
	Post Template: `Still have <*> requests outstanding when connection from mesos-slave-20/<*> is closed`
	Post Template: `Still have <*> requests outstanding when connection from mesos-slave-18/<*> is closed`
	============ Aggregate ====================
	Aggregated Template:  Still have <*> requests outstanding when connection from mesos-slave-20/<*> is closed
[UpdateBucket] Logs: This iter found: 14, total: 16066089/16075117, remain: 9028. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 278 -> 264, remain buckets: 75
Update Success: Time for one update logs: 0.015420913696289062, template `Still have <*> requests outstanding when connection from mesos-slave-20/<*> is closed`
========================================================================================


Iteration 128
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 221, Total Buckets: 239
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.0769. Anchor: `Waiting for Spark driver to be reachable.`, MaxSim Log: `Got told to re-register updating block broadcast_16_piece0`.
	============  Query  ====================
	Log[1]: `Waiting for Spark driver to be reachable.`
	============ Response ====================
LogTemplate[1]: `Waiting for Spark driver to be reachable.`
	============ PostProcess ====================
	Post Template: `Waiting for Spark driver to be reachable.`
	============ Aggregate ====================
	Aggregated Template:  Waiting for Spark driver to be reachable.
[UpdateBucket] Logs: This iter found: 82, total: 16066171/16075117, remain: 8946. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 886 -> 804, remain buckets: 75
Update Success: Time for one update logs: 0.026347875595092773, template `Waiting for Spark driver to be reachable.`
========================================================================================


Iteration 129
Sample 3 from current logs bucket: ID: 125, Len: 5, Bucket Size: 218, Total Buckets: 239
Sampling from 23 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Starting job: collect at pnmf4.py:225`, MaxSim Log: `Starting job: collect at pnmf4.py:221`.
	============  Query  ====================
	Log[1]: `Starting job: collect at pnmf4.py:225`
	Log[2]: `Starting job: collect at IPLoM.py:124`
	Log[3]: `Starting job: collect at pnmf.py:279`
	============ Response ====================
LogTemplate[1]: `Starting job: collect at {script_name}:{line_number}`
LogTemplate[2]: `Starting job: collect at {script_name}:{line_number}`
LogTemplate[3]: `Starting job: collect at {script_name}:{line_number}`
	============ PostProcess ====================
	Post Template: `Starting job: collect at <*>`
	Post Template: `Starting job: collect at <*>`
	Post Template: `Starting job: collect at <*>`
	============ Aggregate ====================
	Aggregated Template:  Starting job: collect at <*>
[UpdateBucket] Logs: This iter found: 218, total: 16066389/16075117, remain: 8728. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 1094 -> 876, remain buckets: 74
Update Success: Time for one update logs: 0.03199315071105957, template `Starting job: collect at <*>`
========================================================================================


Iteration 130
Sample 3 from current logs bucket: ID: 182, Len: 10, Bucket Size: 218, Total Buckets: 239
Sampling from 159 logs, Sim Level: 4, MaxSim to anchor: 0.8182. Anchor: `Got job 0 (collect at pnmf4.py:225) with 2 output partitions`, MaxSim Log: `Got job 0 (collect at pnmf4.py:221) with 2 output partitions`.
	============  Query  ====================
	Log[1]: `Got job 0 (collect at pnmf4.py:225) with 2 output partitions`
	Log[2]: `Got job 71 (collect at pnmf.py:279) with 40 output partitions`
	Log[3]: `Got job 3 (collect at pnmf4.py:377) with 3 output partitions`
	============ Response ====================
LogTemplate[1]: `Got job {job_id} (collect at {script}:225) with {num_partitions} output partitions`
LogTemplate[2]: `Got job {job_id} (collect at {script}:279) with {num_partitions} output partitions`
LogTemplate[3]: `Got job {job_id} (collect at {script}:377) with {num_partitions} output partitions`
	============ PostProcess ====================
	Post Template: `Got job <*> (collect at <*>) with <*> output partitions`
	Post Template: `Got job <*> (collect at <*>) with <*> output partitions`
	Post Template: `Got job <*> (collect at <*>) with <*> output partitions`
	============ Aggregate ====================
	Aggregated Template:  Got job <*> (collect at <*>) with <*> output partitions
[UpdateBucket] Logs: This iter found: 218, total: 16066607/16075117, remain: 8510. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 479 -> 261, remain buckets: 73
Update Success: Time for one update logs: 0.021245956420898438, template `Got job <*> (collect at <*>) with <*> output partitions`
========================================================================================


Iteration 131
Sample 3 from current logs bucket: ID: 197, Len: 12, Bucket Size: 216, Total Buckets: 239
Sampling from 197 logs, Sim Level: 4, MaxSim to anchor: 0.6923. Anchor: `Submitting 1 missing tasks from ResultStage 2 (PythonRDD[5] at RDD at PythonRDD.scala:43)`, MaxSim Log: `Submitting 1 missing tasks from ResultStage 4 (PythonRDD[10] at RDD at PythonRDD.scala:43)`.
	============  Query  ====================
	Log[1]: `Submitting 1 missing tasks from ResultStage 2 (PythonRDD[5] at RDD at PythonRDD.scala:43)`
	Log[2]: `Submitting 1 missing tasks from ResultStage 4 (PythonRDD[10] at RDD at PythonRDD.scala:43)`
	============ Response ====================
LogTemplate[1]: `Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)`
LogTemplate[2]: `Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)`
	============ PostProcess ====================
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)`
	============ Aggregate ====================
	Aggregated Template:  Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)
[UpdateBucket] Logs: This iter found: 10, total: 16066617/16075117, remain: 8500. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 508 -> 498, remain buckets: 73
Update Success: Time for one update logs: 0.024358034133911133, template `Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)`
========================================================================================


Iteration 132
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 215, Total Buckets: 239
Sampling from 23 logs failed
	============  Query  ====================
	Log[1]: `Starting job: runJob at PythonRDD.scala:393`
	============ Response ====================
LogTemplate[1]: `Starting job: runJob at {file}:{line}`
	============ PostProcess ====================
	Post Template: `Starting job: runJob at <*>`
	============ Aggregate ====================
	Aggregated Template:  Starting job: runJob at <*>
[UpdateBucket] Logs: This iter found: 14, total: 16066631/16075117, remain: 8486. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 876 -> 862, remain buckets: 73
[TemplateDB] Try Merge: `Starting job: runJob at <*>` | `Starting job: collect at <*>`
[TemplateDB] Reject Merge, Remain Template: `Starting job: runJob at <*>`
Update Success: Time for one update logs: 0.02464914321899414, template `Starting job: runJob at <*>`
========================================================================================


Iteration 133
Sample 3 from current logs bucket: ID: 190, Len: 11, Bucket Size: 215, Total Buckets: 239
Sampling from 121 logs, Sim Level: 2, MaxSim to anchor: 0.8333. Anchor: `Still have 1 requests outstanding when connection from mesos-master-1/10.10.34.11:60970 is closed`, MaxSim Log: `Still have 1 requests outstanding when connection from mesos-slave-21/10.10.34.31:53449 is closed`.
	============  Query  ====================
	Log[1]: `Still have 1 requests outstanding when connection from mesos-master-1/10.10.34.11:60970 is closed`
	Log[2]: `Still have 0 requests outstanding when connection from mesos-master-1/10.10.34.11:33750 is closed`
	Log[3]: `Still have 2 requests outstanding when connection from mesos-slave-18/10.10.34.28:37604 is closed`
	============ Response ====================
LogTemplate[1]: `Still have {number} requests outstanding when connection from {server}/{ip_or_url} is closed`
LogTemplate[2]: `Still have {number} requests outstanding when connection from {server}/{ip_or_url} is closed`
LogTemplate[3]: `Still have {number} requests outstanding when connection from {server}/{ip_or_url} is closed`
	============ PostProcess ====================
	Post Template: `Still have <*> requests outstanding when connection from <*> is closed`
	Post Template: `Still have <*> requests outstanding when connection from <*> is closed`
	Post Template: `Still have <*> requests outstanding when connection from <*> is closed`
	============ Aggregate ====================
	Aggregated Template:  Still have <*> requests outstanding when connection from <*> is closed
[UpdateBucket] Logs: This iter found: 215, total: 16066846/16075117, remain: 8271. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 264 -> 49, remain buckets: 72
[TemplateDB] Try Merge: `Still have <*> requests outstanding when connection from <*> is closed` | `Still have <*> requests outstanding when connection from mesos-slave-20/<*> is closed`
	Post Template: `Still have <*> requests outstanding when connection from <*> is closed`
[TemplateDB] Merged: -> `Still have <*> requests outstanding when connection from <*> is closed`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 229/229, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
Update Success: Time for one update logs: 0.03268289566040039, template `Still have <*> requests outstanding when connection from <*> is closed`
========================================================================================


Iteration 134
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 213, Total Buckets: 239
Sampling from 43 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Registering RDD 5 (reduceByKey at pnmf4.py:332)`, MaxSim Log: `Registering RDD 5 (reduceByKey at pnmf4.py:295)`.
	============  Query  ====================
	Log[1]: `Registering RDD 5 (reduceByKey at pnmf4.py:332)`
	Log[2]: `Registering RDD 7 (reduceByKey at pnmf_amz.py:389)`
	Log[3]: `Registering RDD 107 (reduceByKey at pnmf4.py:295)`
	============ Response ====================
LogTemplate[1]: `Registering RDD {number} (reduceByKey at {file}:{line})`  
LogTemplate[2]: `Registering RDD {number} (reduceByKey at {file}:{line})`  
LogTemplate[3]: `Registering RDD {number} (reduceByKey at {file}:{line})`  
	============ PostProcess ====================
	Post Template: `Registering RDD <*> (reduceByKey at <*>)`
	Post Template: `Registering RDD <*> (reduceByKey at <*>)`
	Post Template: `Registering RDD <*> (reduceByKey at <*>)`
	============ Aggregate ====================
	Aggregated Template:  Registering RDD <*> (reduceByKey at <*>)
[UpdateBucket] Logs: This iter found: 92, total: 16066938/16075117, remain: 8179. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 733 -> 641, remain buckets: 72
Update Success: Time for one update logs: 0.02241802215576172, template `Registering RDD <*> (reduceByKey at <*>)`
========================================================================================


Iteration 135
Sample 3 from current logs bucket: ID: 20, Len: 3, Bucket Size: 208, Total Buckets: 239
Sampling from 8 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Disabling executor 6.`, MaxSim Log: `Disabling executor 2.`.
	============  Query  ====================
	Log[1]: `Disabling executor 6.`
	Log[2]: `Disabling executor 4.`
	Log[3]: `Disabling executor 8.`
	============ Response ====================
LogTemplate[1]: `Disabling executor {executor_num}.`
	============ PostProcess ====================
	Post Template: `Disabling executor <*>.`
	Post Template: `Disabling executor <*>.`
	Post Template: `Disabling executor <*>.`
	============ Aggregate ====================
	Aggregated Template:  Disabling executor <*>.
[UpdateBucket] Logs: This iter found: 318, total: 16067256/16075117, remain: 7861. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 952 -> 634, remain buckets: 70
Update Success: Time for one update logs: 0.06106901168823242, template `Disabling executor <*>.`
========================================================================================


Iteration 136
Sample 3 from current logs bucket: ID: 153, Len: 7, Bucket Size: 207, Total Buckets: 239
Sampling from 144 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Final stage: ResultStage 0 (collect at pnmf4.py:225)`, MaxSim Log: `Final stage: ResultStage 0 (collect at pnmf4.py:221)`.
	============  Query  ====================
	Log[1]: `Final stage: ResultStage 0 (collect at pnmf4.py:225)`
	Log[2]: `Final stage: ResultStage 54 (collect at pnmf.py:279)`
	Log[3]: `Final stage: ResultStage 2 (collect at pnmf4.py:333)`
	============ Response ====================
LogTemplate[1]: `Final stage: ResultStage {stage_num} (collect at {file_path})`  
LogTemplate[2]: `Final stage: ResultStage {stage_num} (collect at {file_path})`  
LogTemplate[3]: `Final stage: ResultStage {stage_num} (collect at {file_path})`  
	============ PostProcess ====================
	Post Template: `Final stage: ResultStage <*> (collect at <*>)`
	Post Template: `Final stage: ResultStage <*> (collect at <*>)`
	Post Template: `Final stage: ResultStage <*> (collect at <*>)`
	============ Aggregate ====================
	Aggregated Template:  Final stage: ResultStage <*> (collect at <*>)
[UpdateBucket] Logs: This iter found: 218, total: 16067474/16075117, remain: 7643. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 804 -> 586, remain buckets: 69
Update Success: Time for one update logs: 0.02656412124633789, template `Final stage: ResultStage <*> (collect at <*>)`
========================================================================================


Iteration 137
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 206, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Unregistering ApplicationMaster with SUCCEEDED`
	============ Response ====================
LogTemplate[1]: `Unregistering ApplicationMaster with {status}`
	============ PostProcess ====================
	Post Template: `Unregistering ApplicationMaster with <*>`
	============ Aggregate ====================
	Aggregated Template:  Unregistering ApplicationMaster with <*>
[UpdateBucket] Logs: This iter found: 81, total: 16067555/16075117, remain: 7562. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 459 -> 378, remain buckets: 69
Update Success: Time for one update logs: 0.027955055236816406, template `Unregistering ApplicationMaster with <*>`
========================================================================================


Iteration 138
Sample 1 from current logs bucket: ID: 197, Len: 12, Bucket Size: 206, Total Buckets: 239
Sampling from 195 logs, Sim Level: 5, MaxSim to anchor: 0.6923. Anchor: `Submitting 13 missing tasks from ResultStage 3 (PythonRDD[11] at min at IPLoM.py:143)`, MaxSim Log: `Submitting 13 missing tasks from ResultStage 9 (PythonRDD[21] at min at IPLoM.py:143)`.
	============  Query  ====================
	Log[1]: `Submitting 13 missing tasks from ResultStage 3 (PythonRDD[11] at min at IPLoM.py:143)`
	Log[2]: `Submitting 3 missing tasks from ResultStage 3 (PythonRDD[9] at countByKey at pnmf4.py:372)`
	Log[3]: `Submitting 13 missing tasks from ResultStage 13 (PythonRDD[26] at reduce at IPLoM.py:168)`
	============ Response ====================
LogTemplate[1]: `Submitting {task_count} missing tasks from ResultStage {stage_number} ({rdd_type}[{rdd_id}] at {operation} at {file}:{line_number})`
	============ PostProcess ====================
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)`
	============ Aggregate ====================
	Aggregated Template:  Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)
[UpdateBucket] Logs: This iter found: 206, total: 16067761/16075117, remain: 7356. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 498 -> 292, remain buckets: 68
[TemplateDB] Try Merge: `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)` | `Submitting <*> missing tasks from ResultStage <*> (<*> at collect at <*>)`
	Post Template: `Submitting <*> missing tasks from ResultStage <*> (<*> at <*> at <*>)`
[TemplateDB] Merged: -> `Submitting <*> missing tasks from ResultStage <*> (<*> at <*> at <*>)`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 433/433, in child Bucket [196, 197, 198, 199]
[UpdateBucket] Logs: This iter found: 0, total: 16067761/16075117, remain: 7356. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 292 -> 292, remain buckets: 68
[TemplateDB] Update Indexes: 433 -> 433 for `Submitting <*> missing tasks from ResultStage <*> (<*> at <*> at <*>)`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Submitting <*> missing tasks from ResultStage <*> (<*> at <*> at <*>)`
Update Success: Time for one update logs: 0.029873132705688477, template `Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at <*> at <*>)`
========================================================================================


Iteration 139
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 204, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `running: Set()`
	============ Response ====================
LogTemplate[1]: `running: Set()`
	============ PostProcess ====================
	Post Template: `running: Set()`
	============ Aggregate ====================
	Aggregated Template:  running: Set()
[UpdateBucket] Logs: This iter found: 204, total: 16067965/16075117, remain: 7152. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 938 -> 734, remain buckets: 67
Update Success: Time for one update logs: 0.01740407943725586, template `running: Set()`
========================================================================================


Iteration 140
Sample 3 from current logs bucket: ID: 6, Len: 2, Bucket Size: 204, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `failed: Set()`
	============ Response ====================
LogTemplate[1]: `failed: Set()`
	============ PostProcess ====================
	Post Template: `failed: Set()`
	============ Aggregate ====================
	Aggregated Template:  failed: Set()
[UpdateBucket] Logs: This iter found: 204, total: 16068169/16075117, remain: 6948. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 734 -> 530, remain buckets: 66
[TemplateDB] Try Merge: `failed: Set()` | `running: Set()`
[TemplateDB] Reject Merge, Remain Template: `failed: Set()`
Update Success: Time for one update logs: 0.010976076126098633, template `failed: Set()`
========================================================================================


Iteration 141
Sample 3 from current logs bucket: ID: 131, Len: 5, Bucket Size: 204, Total Buckets: 239
	============  Query  ====================
	Log[1]: `looking for newly runnable stages`
	============ Response ====================
LogTemplate[1]: `looking for newly runnable stages`
	============ PostProcess ====================
	Post Template: `looking for newly runnable stages`
	============ Aggregate ====================
	Aggregated Template:  looking for newly runnable stages
[UpdateBucket] Logs: This iter found: 204, total: 16068373/16075117, remain: 6744. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 862 -> 658, remain buckets: 65
Update Success: Time for one update logs: 0.021795034408569336, template `looking for newly runnable stages`
========================================================================================


Iteration 142
Sample 1 from current logs bucket: ID: 171, Len: 9, Bucket Size: 202, Total Buckets: 239
Sampling from 201 logs, Sim Level: 2, MaxSim to anchor: 0.6364. Anchor: `ResultStage 0 (collect at pnmf4.py:225) finished in 6.049 s`, MaxSim Log: `ResultStage 0 (collect at pnmf4.py:221) finished in 8.613 s`.
	============  Query  ====================
	Log[1]: `ResultStage 0 (collect at pnmf4.py:225) finished in 6.049 s`
	Log[2]: `ResultStage 0 (collect at pnmf4.py:292) finished in 5.747 s`
	Log[3]: `ResultStage 79 (collect at pnmf.py:279) finished in 1.914 s`
	============ Response ====================
LogTemplate[1]: `ResultStage {stage_num} (collect at {file}:{line_num}) finished in {duration} s`
	============ PostProcess ====================
	Post Template: `ResultStage <*> (collect at <*>) finished in <*> s`
	Post Template: `ResultStage <*> (collect at <*>) finished in <*> s`
	Post Template: `ResultStage <*> (collect at <*>) finished in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ResultStage <*> (collect at <*>) finished in <*> s
[UpdateBucket] Logs: This iter found: 202, total: 16068575/16075117, remain: 6542. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 881 -> 679, remain buckets: 64
Update Success: Time for one update logs: 0.01825714111328125, template `ResultStage <*> (collect at <*>) finished in <*> s`
========================================================================================


Iteration 143
Sample 3 from current logs bucket: ID: 172, Len: 9, Bucket Size: 202, Total Buckets: 239
Sampling from 201 logs, Sim Level: 2, MaxSim to anchor: 0.6364. Anchor: `Job 0 finished: collect at pnmf4.py:225, took 6.458519 s`, MaxSim Log: `Job 0 finished: collect at pnmf4.py:221, took 8.836851 s`.
	============  Query  ====================
	Log[1]: `Job 0 finished: collect at pnmf4.py:225, took 6.458519 s`
	Log[2]: `Job 0 finished: collect at pnmf4.py:218, took 8.573524 s`
	Log[3]: `Job 10 finished: collect at pnmf.py:279, took 1.604490 s`
	============ Response ====================
LogTemplate[1]: `Job {job_id} finished: collect at {script_name}:{line_number}, took {duration} s`  
LogTemplate[2]: `Job {job_id} finished: collect at {script_name}:{line_number}, took {duration} s`  
LogTemplate[3]: `Job {job_id} finished: collect at {script_name}:{line_number}, took {duration} s`  
	============ PostProcess ====================
	Post Template: `Job <*> finished: collect at <*> took <*> s`
	Post Template: `Job <*> finished: collect at <*> took <*> s`
	Post Template: `Job <*> finished: collect at <*> took <*> s`
	============ Aggregate ====================
	Aggregated Template:  Job <*> finished: collect at <*> took <*> s
[UpdateBucket] Logs: This iter found: 202, total: 16068777/16075117, remain: 6340. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 679 -> 477, remain buckets: 63
Update Success: Time for one update logs: 0.026844263076782227, template `Job <*> finished: collect at <*> took <*> s`
========================================================================================


Iteration 144
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 201, Total Buckets: 239
Sampling from 22 logs failed
	============  Query  ====================
	Log[1]: `Using REPL class URI: http://10.10.18.32:65475`
	============ Response ====================
LogTemplate[1]: `Using REPL class URI: http://{ip_or_url}:{port}`
	============ PostProcess ====================
	Post Template: `Using REPL class URI: http://<*>`
	============ Aggregate ====================
	Aggregated Template:  Using REPL class URI: http://<*>
[UpdateBucket] Logs: This iter found: 21, total: 16068798/16075117, remain: 6319. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 658 -> 637, remain buckets: 63
Update Success: Time for one update logs: 0.018677949905395508, template `Using REPL class URI: http://<*>`
========================================================================================


Iteration 145
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 200, Total Buckets: 239
Sampling from 44 logs, Sim Level: 2, MaxSim to anchor: 0.5000. Anchor: `Cleaned shuffle 8`, MaxSim Log: `Cleaned shuffle 7`.
	============  Query  ====================
	Log[1]: `Cleaned shuffle 8`
	Log[2]: `Cleaned shuffle 34`
	Log[3]: `Cleaned shuffle 11`
	============ Response ====================
LogTemplate[1]: `Cleaned shuffle {num}`  
LogTemplate[2]: `Cleaned shuffle {num}`  
LogTemplate[3]: `Cleaned shuffle {num}`  
	============ PostProcess ====================
	Post Template: `Cleaned shuffle <*>`
	Post Template: `Cleaned shuffle <*>`
	Post Template: `Cleaned shuffle <*>`
	============ Aggregate ====================
	Aggregated Template:  Cleaned shuffle <*>
[UpdateBucket] Logs: This iter found: 46, total: 16068844/16075117, remain: 6273. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 634 -> 588, remain buckets: 63
[TemplateDB] Try Merge: `Cleaned shuffle <*>` | `Cleaned accumulator <*>`
[TemplateDB] Reject Merge, Remain Template: `Cleaned shuffle <*>`
Update Success: Time for one update logs: 0.05348920822143555, template `Cleaned shuffle <*>`
========================================================================================


Iteration 146
Sample 3 from current logs bucket: ID: 144, Len: 6, Bucket Size: 200, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `error=2, No such file or directory`
	============ Response ====================
LogTemplate[1]: `error=<*>, No such file or directory`
	============ PostProcess ====================
	Post Template: `error=<*>, No such file or directory`
	============ Aggregate ====================
	Aggregated Template:  error=<*>, No such file or directory
[UpdateBucket] Logs: This iter found: 200, total: 16069044/16075117, remain: 6073. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 641 -> 441, remain buckets: 62
Update Success: Time for one update logs: 0.025428056716918945, template `error=<*>, No such file or directory`
========================================================================================


Iteration 147
Sample 3 from current logs bucket: ID: 157, Len: 7, Bucket Size: 198, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Error while invoking RpcHandler#receive() for one-way message.`
	============ Response ====================
LogTemplate[1]: `Error while invoking RpcHandler#receive() for one-way message.`
	============ PostProcess ====================
	Post Template: `Error while invoking RpcHandler#receive() for one-way message.`
	============ Aggregate ====================
	Aggregated Template:  Error while invoking RpcHandler#receive() for one-way message.
[UpdateBucket] Logs: This iter found: 198, total: 16069242/16075117, remain: 5875. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 586 -> 388, remain buckets: 61
Update Success: Time for one update logs: 0.027269840240478516, template `Error while invoking RpcHandler#receive() for one-way message.`
========================================================================================


Iteration 148
Sample 3 from current logs bucket: ID: 11, Len: 2, Bucket Size: 192, Total Buckets: 239
Sampling from 63 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Started SelectChannelConnector@0.0.0.0:33134`, MaxSim Log: `Started SelectChannelConnector@0.0.0.0:51961`.
	============  Query  ====================
	Log[1]: `Started SelectChannelConnector@0.0.0.0:33134`
	============ Response ====================
LogTemplate[1]: `Started SelectChannelConnector@{ip_or_port}`
	============ PostProcess ====================
	Post Template: `Started SelectChannelConnector@<*>`
	============ Aggregate ====================
	Aggregated Template:  Started SelectChannelConnector@<*>
[UpdateBucket] Logs: This iter found: 64, total: 16069306/16075117, remain: 5811. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 530 -> 466, remain buckets: 61
Update Success: Time for one update logs: 0.01870894432067871, template `Started SelectChannelConnector@<*>`
========================================================================================


Iteration 149
Sample 3 from current logs bucket: ID: 126, Len: 5, Bucket Size: 190, Total Buckets: 239
Sampling from 126 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Exception in connection from mesos-slave-20/10.10.34.30:33900`, MaxSim Log: `Exception in connection from mesos-master-1/10.10.34.11:60970`.
	============  Query  ====================
	Log[1]: `Exception in connection from mesos-slave-20/10.10.34.30:33900`
	Log[2]: `Exception in connection from mesos-slave-10/10.10.34.20:45733`
	Log[3]: `Exception in connection from mesos-slave-25/10.10.34.35:51600`
	============ Response ====================
LogTemplate[1]: `Exception in connection from mesos-slave-{slave_id}/{ip}`
	============ PostProcess ====================
	Post Template: `Exception in connection from mesos-slave-<*>`
	Post Template: `Exception in connection from mesos-slave-<*>`
	Post Template: `Exception in connection from mesos-slave-<*>`
	============ Aggregate ====================
	Aggregated Template:  Exception in connection from mesos-slave-<*>
[UpdateBucket] Logs: This iter found: 153, total: 16069459/16075117, remain: 5658. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 637 -> 484, remain buckets: 61
Update Success: Time for one update logs: 0.024695158004760742, template `Exception in connection from mesos-slave-<*>`
========================================================================================


Iteration 150
Sample 3 from current logs bucket: ID: 224, Len: 24, Bucket Size: 189, Total Buckets: 239
Sampling from 184 logs, Sim Level: 4, MaxSim to anchor: 0.9130. Anchor: `Lost executor 6 on mesos-slave-27: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`, MaxSim Log: `Lost executor 6 on mesos-slave-11: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`.
	============  Query  ====================
	Log[1]: `Lost executor 6 on mesos-slave-27: Container killed by YARN for exceeding memory limits. 54.7 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[2]: `Lost executor 2 on mesos-slave-23: Container killed by YARN for exceeding memory limits. 57.4 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Log[3]: `Lost executor 15 on mesos-slave-11: Container killed by YARN for exceeding memory limits. 46.4 GB of 46.2 GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Response ====================
LogTemplate[1]: `Lost executor {executor_id} on {mesos_slave}: Container killed by YARN for exceeding memory limits. {memory_used} GB of {total_memory} GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[2]: `Lost executor {executor_id} on {mesos_slave}: Container killed by YARN for exceeding memory limits. {memory_used} GB of {total_memory} GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`

LogTemplate[3]: `Lost executor {executor_id} on {mesos_slave}: Container killed by YARN for exceeding memory limits. {memory_used} GB of {total_memory} GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ PostProcess ====================
	Post Template: `Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	Post Template: `Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
	============ Aggregate ====================
	Aggregated Template:  Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.
[UpdateBucket] Logs: This iter found: 189, total: 16069648/16075117, remain: 5469. 
[UpdateBucket] Buckets: Checked 1 ([224]), Parent Bucket size: 189 -> 0, remain buckets: 60
Update Success: Time for one update logs: 0.01729607582092285, template `Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.`
========================================================================================


Iteration 151
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 180, Total Buckets: 239
Sampling from 3 logs, Sim Level: 1, MaxSim to anchor: 0.4286. Anchor: `ensureFreeSpace(1097) called with curMem=0, maxMem=556038881`, MaxSim Log: `ensureFreeSpace(1776) called with curMem=1097, maxMem=556038881`.
	============  Query  ====================
	Log[1]: `ensureFreeSpace(1097) called with curMem=0, maxMem=556038881`
	============ Response ====================
LogTemplate[1]: `ensureFreeSpace(<*>) called with curMem=<*> maxMem=<*>`
	============ PostProcess ====================
	Post Template: `ensureFreeSpace(<*>) called with curMem=<*> maxMem=<*>`
	============ Aggregate ====================
	Aggregated Template:  ensureFreeSpace(<*>) called with curMem=<*> maxMem=<*>
[UpdateBucket] Logs: This iter found: 84, total: 16069732/16075117, remain: 5385. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 484 -> 400, remain buckets: 60
Update Success: Time for one update logs: 0.03316211700439453, template `ensureFreeSpace(<*>) called with curMem=<*> maxMem=<*>`
========================================================================================


Iteration 152
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 178, Total Buckets: 239
Sampling from 93 logs, Sim Level: 4, MaxSim to anchor: 0.6364. Anchor: `ShuffleMapStage 2 (aggregateByKey at IPLoM.py:140) finished in 32.076 s`, MaxSim Log: `ShuffleMapStage 8 (aggregateByKey at IPLoM.py:140) finished in 31.654 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 2 (aggregateByKey at IPLoM.py:140) finished in 32.076 s`
	Log[2]: `ShuffleMapStage 46 (aggregateByKey at IPLoM.py:140) finished in 30.693 s`
	Log[3]: `ShuffleMapStage 241 (aggregateByKey at IPLoM.py:518) finished in 29.213 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (aggregateByKey at IPLoM.py:{line_num}) finished in {duration} s`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s
[UpdateBucket] Logs: This iter found: 54, total: 16069786/16075117, remain: 5331. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 477 -> 423, remain buckets: 60
Update Success: Time for one update logs: 0.02010798454284668, template `ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s`
========================================================================================


Iteration 153
Sample 3 from current logs bucket: ID: 139, Len: 6, Bucket Size: 175, Total Buckets: 239
Sampling from 110 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Parents of final stage: List(ShuffleMapStage 1)`, MaxSim Log: `Parents of final stage: List(ShuffleMapStage 3)`.
	============  Query  ====================
	Log[1]: `Parents of final stage: List(ShuffleMapStage 1)`
	Log[2]: `Parents of final stage: List(ShuffleMapStage 255)`
	Log[3]: `Parents of final stage: List(ShuffleMapStage 29)`
	============ Response ====================
LogTemplate[1]: `Parents of final stage: List(ShuffleMapStage {stage_number})`
	============ PostProcess ====================
	Post Template: `Parents of final stage: List(ShuffleMapStage <*>)`
	Post Template: `Parents of final stage: List(ShuffleMapStage <*>)`
	Post Template: `Parents of final stage: List(ShuffleMapStage <*>)`
	============ Aggregate ====================
	Aggregated Template:  Parents of final stage: List(ShuffleMapStage <*>)
[UpdateBucket] Logs: This iter found: 175, total: 16069961/16075117, remain: 5156. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 441 -> 266, remain buckets: 59
Update Success: Time for one update logs: 0.025219202041625977, template `Parents of final stage: List(ShuffleMapStage <*>)`
========================================================================================


Iteration 154
Sample 3 from current logs bucket: ID: 167, Len: 8, Bucket Size: 171, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Incomplete task interrupted: Attempting to kill Python Worker`
	============ Response ====================
LogTemplate[1]: `Incomplete task interrupted: Attempting to kill Python Worker`
	============ PostProcess ====================
	Post Template: `Incomplete task interrupted: Attempting to kill Python Worker`
	============ Aggregate ====================
	Aggregated Template:  Incomplete task interrupted: Attempting to kill Python Worker
[UpdateBucket] Logs: This iter found: 171, total: 16070132/16075117, remain: 4985. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 391 -> 220, remain buckets: 58
Update Success: Time for one update logs: 0.01594090461730957, template `Incomplete task interrupted: Attempting to kill Python Worker`
========================================================================================


Iteration 155
Sample 3 from current logs bucket: ID: 186, Len: 10, Bucket Size: 164, Total Buckets: 239
Sampling from 154 logs, Sim Level: 5, MaxSim to anchor: 0.8182. Anchor: `ShuffleMapStage 4 is now unavailable on executor 2 (0/2, false)`, MaxSim Log: `ShuffleMapStage 4 is now unavailable on executor 3 (0/2, false)`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 4 is now unavailable on executor 2 (0/2, false)`
	Log[2]: `ShuffleMapStage 11 is now unavailable on executor 19 (25/118, false)`
	Log[3]: `ShuffleMapStage 7 is now unavailable on executor 3 (48/80, false)`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} is now unavailable on executor {executor_num} ({progress}/{total}, false)`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)`
	Post Template: `ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)`
	Post Template: `ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)
[UpdateBucket] Logs: This iter found: 164, total: 16070296/16075117, remain: 4821. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 261 -> 97, remain buckets: 57
Update Success: Time for one update logs: 0.01860499382019043, template `ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)`
========================================================================================


Iteration 156
Sample 3 from current logs bucket: ID: 198, Len: 12, Bucket Size: 157, Total Buckets: 239
Sampling from 156 logs, Sim Level: 5, MaxSim to anchor: 0.7143. Anchor: `Lost task 9.0 in stage 1.0 (TID 11, mesos-slave-13): TaskKilled (killed intentionally)`, MaxSim Log: `Lost task 39.0 in stage 1.0 (TID 41, mesos-slave-13): TaskKilled (killed intentionally)`.
	============  Query  ====================
	Log[1]: `Lost task 9.0 in stage 1.0 (TID 11, mesos-slave-13): TaskKilled (killed intentionally)`
	Log[2]: `Lost task 21.0 in stage 108.0 (TID 4705, mesos-slave-06): TaskKilled (killed intentionally)`
	Log[3]: `Lost task 25.3 in stage 2.0 (TID 181, mesos-slave-23): TaskKilled (killed intentionally)`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-slave-{slave_id}): TaskKilled (killed intentionally)`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)
[UpdateBucket] Logs: This iter found: 178, total: 16070474/16075117, remain: 4643. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 292 -> 114, remain buckets: 57
Update Success: Time for one update logs: 0.01847982406616211, template `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)`
========================================================================================


Iteration 157
Sample 3 from current logs bucket: ID: 96, Len: 3, Bucket Size: 154, Total Buckets: 239
Sampling from 78 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `waiting: Set(ResultStage 1)`, MaxSim Log: `waiting: Set(ResultStage 3)`.
	============  Query  ====================
	Log[1]: `waiting: Set(ResultStage 1)`
	Log[2]: `waiting: Set(ResultStage 24)`
	Log[3]: `waiting: Set(ResultStage 75)`
	============ Response ====================
LogTemplate[1]: `waiting: Set(ResultStage {stage})`
LogTemplate[2]: `waiting: Set(ResultStage {stage})`
LogTemplate[3]: `waiting: Set(ResultStage {stage})`
	============ PostProcess ====================
	Post Template: `waiting: Set(ResultStage <*>)`
	Post Template: `waiting: Set(ResultStage <*>)`
	Post Template: `waiting: Set(ResultStage <*>)`
	============ Aggregate ====================
	Aggregated Template:  waiting: Set(ResultStage <*>)
[UpdateBucket] Logs: This iter found: 154, total: 16070628/16075117, remain: 4489. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 588 -> 434, remain buckets: 56
Update Success: Time for one update logs: 0.0639040470123291, template `waiting: Set(ResultStage <*>)`
========================================================================================


Iteration 158
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 154, Total Buckets: 239
Sampling from 15 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Cleaned RDD 72`, MaxSim Log: `Cleaned RDD 62`.
	============  Query  ====================
	Log[1]: `Cleaned RDD 72`
	Log[2]: `Cleaned RDD 107`
	Log[3]: `Cleaned RDD 97`
	============ Response ====================
LogTemplate[1]: `Cleaned RDD {number}`
LogTemplate[2]: `Cleaned RDD {number}`
LogTemplate[3]: `Cleaned RDD {number}`
	============ PostProcess ====================
	Post Template: `Cleaned RDD <*>`
	Post Template: `Cleaned RDD <*>`
	Post Template: `Cleaned RDD <*>`
	============ Aggregate ====================
	Aggregated Template:  Cleaned RDD <*>
[UpdateBucket] Logs: This iter found: 16, total: 16070644/16075117, remain: 4473. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 434 -> 418, remain buckets: 56
[TemplateDB] Try Merge: `Cleaned RDD <*>` | `Removing RDD <*>`
[TemplateDB] Reject Merge, Remain Template: `Cleaned RDD <*>`
Update Success: Time for one update logs: 0.0457460880279541, template `Cleaned RDD <*>`
========================================================================================


Iteration 159
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 150, Total Buckets: 239
Sampling from 149 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`, MaxSim Log: `ShuffleMapStage 117 (reduceByKey at IPLoM.py:552) finished in 1.477 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`
	Log[2]: `ShuffleMapStage 205 (reduceByKey at IPLoM.py:552) finished in 0.127 s`
	Log[3]: `ShuffleMapStage 7 (reduceByKey at pnmf_dblp.py:423) finished in 700.648 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
LogTemplate[2]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
LogTemplate[3]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*> s)
[UpdateBucket] Logs: This iter found: 0, total: 16070644/16075117, remain: 4473. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 423 -> 423, remain buckets: 56
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*> s)`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 150, Total Buckets: 239
Sampling from 149 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`, MaxSim Log: `ShuffleMapStage 117 (reduceByKey at IPLoM.py:552) finished in 1.477 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`
	Log[2]: `ShuffleMapStage 31 (reduceByKey at pnmf4.py:295) finished in 41.258 s`
	Log[3]: `ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) finished in 391.615 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*>s)`
LogTemplate[2]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*>s)`
LogTemplate[3]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*>s)`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*>)
[UpdateBucket] Logs: This iter found: 0, total: 16070644/16075117, remain: 4473. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 423 -> 423, remain buckets: 56
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*>)`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 150, Total Buckets: 239
Sampling from 149 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`, MaxSim Log: `ShuffleMapStage 117 (reduceByKey at IPLoM.py:552) finished in 1.477 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 0 (reduceByKey at IPLoM.py:121) finished in 33.787 s`
	Log[2]: `ShuffleMapStage 2 (reduceByKey at pnmf_dblp.py:390) finished in 1.809 s`
	Log[3]: `ShuffleMapStage 7 (reduceByKey at pnmf_dblp.py:423) finished in 218.982 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
LogTemplate[2]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
LogTemplate[3]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*> s)
[UpdateBucket] Logs: This iter found: 0, total: 16070644/16075117, remain: 4473. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 423 -> 423, remain buckets: 56
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*> s)`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `ShuffleMapStage <*> (reduceByKey at IPLoM.py:<*>) finished in <*> s`
[UpdateBucket] Logs: This iter found: 4, total: 16070648/16075117, remain: 4469. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 423 -> 419, remain buckets: 56
[TemplateDB] Try Merge: `ShuffleMapStage <*> (reduceByKey at IPLoM.py:<*>) finished in <*> s` | `ShuffleMapStage <*> (aggregateByKey at IPLoM.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (<*> at IPLoM.py:<*>) finished in <*> s`
[TemplateDB] Merged: -> `ShuffleMapStage <*> (<*> at IPLoM.py:<*>) finished in <*> s`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 58/58, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
[UpdateBucket] Logs: This iter found: 0, total: 16070648/16075117, remain: 4469. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 419 -> 419, remain buckets: 56
[TemplateDB] Update Indexes: 58 -> 58 for `ShuffleMapStage <*> (<*> at IPLoM.py:<*>) finished in <*> s`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `ShuffleMapStage <*> (<*> at IPLoM.py:<*>) finished in <*> s`
Update Success: Time for one update logs: 0.03595900535583496, template `ShuffleMapStage <*> (reduceByKey at IPLoM.py:<*>) finished in <*> s`
========================================================================================


Iteration 160
Sample 3 from current logs bucket: ID: 176, Len: 9, Bucket Size: 149, Total Buckets: 239
Sampling from 77 logs, Sim Level: 2, MaxSim to anchor: 0.8000. Anchor: `Error sending message [message = GetLocations(broadcast_5_piece265)] in 1 attempts`, MaxSim Log: `Error sending message [message = GetLocations(broadcast_2_piece0)] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = GetLocations(broadcast_5_piece265)] in 1 attempts`
	Log[2]: `Error sending message [message = GetLocations(broadcast_5_piece294)] in 1 attempts`
	Log[3]: `Error sending message [message = GetLocations(broadcast_44_piece0)] in 2 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = GetLocations({broadcast_piece})] in {attempts} attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = GetLocations(<*>)] in <*> attempts`
	Post Template: `Error sending message [message = GetLocations(<*>)] in <*> attempts`
	Post Template: `Error sending message [message = GetLocations(<*>)] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = GetLocations(<*>)] in <*> attempts
[UpdateBucket] Logs: This iter found: 98, total: 16070746/16075117, remain: 4371. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 419 -> 321, remain buckets: 56
Update Success: Time for one update logs: 0.02108478546142578, template `Error sending message [message = GetLocations(<*>)] in <*> attempts`
========================================================================================


Iteration 161
Sample 3 from current logs bucket: ID: 7, Len: 2, Bucket Size: 146, Total Buckets: 239
Sampling from 145 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `ApplicationAttemptId: appattempt_1485248649253_0020_000002`, MaxSim Log: `ApplicationAttemptId: appattempt_1485248649253_0018_000001`.
	============  Query  ====================
	Log[1]: `ApplicationAttemptId: appattempt_1485248649253_0020_000002`
	============ Response ====================
LogTemplate[1]: `ApplicationAttemptId: {app_attempt_id}`
	============ PostProcess ====================
	Post Template: `ApplicationAttemptId: <*>`
	============ Aggregate ====================
	Aggregated Template:  ApplicationAttemptId: <*>
[UpdateBucket] Logs: This iter found: 146, total: 16070892/16075117, remain: 4225. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 466 -> 320, remain buckets: 55
Update Success: Time for one update logs: 0.022068023681640625, template `ApplicationAttemptId: <*>`
========================================================================================


Iteration 162
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 146, Total Buckets: 239
Sampling from 145 logs, Sim Level: 2, MaxSim to anchor: 0.6364. Anchor: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`, MaxSim Log: `ShuffleMapStage 3 (reduceByKey at pnmf4.py:295) finished in 26.550 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`
	Log[2]: `ShuffleMapStage 10 (reduceByKey at pnmf_dblp.py:423) finished in 70.596 s`
	Log[3]: `ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) finished in 459.193 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
LogTemplate[2]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
LogTemplate[3]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*> s)
[UpdateBucket] Logs: This iter found: 0, total: 16070892/16075117, remain: 4225. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 321 -> 321, remain buckets: 55
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*> s)`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 146, Total Buckets: 239
Sampling from 145 logs, Sim Level: 2, MaxSim to anchor: 0.6364. Anchor: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`, MaxSim Log: `ShuffleMapStage 3 (reduceByKey at pnmf4.py:295) finished in 26.550 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`
	Log[2]: `ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) finished in 4.170 s`
	Log[3]: `ShuffleMapStage 7 (reduceByKey at pnmf_dblp.py:423) finished in 251.234 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s) finished in <*> s`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s) finished in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*> s) finished in <*> s
[UpdateBucket] Logs: This iter found: 0, total: 16070892/16075117, remain: 4225. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 321 -> 321, remain buckets: 55
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*> s) finished in <*> s`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 146, Total Buckets: 239
Sampling from 145 logs, Sim Level: 2, MaxSim to anchor: 0.6364. Anchor: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`, MaxSim Log: `ShuffleMapStage 3 (reduceByKey at pnmf4.py:295) finished in 26.550 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 1 (reduceByKey at pnmf4.py:295) finished in 22.521 s`
	Log[2]: `ShuffleMapStage 7 (reduceByKey at pnmf_dblp.py:423) finished in 251.234 s`
	Log[3]: `ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) finished in 65.238 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
LogTemplate[2]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
LogTemplate[3]: `ShuffleMapStage {stage_num} (reduceByKey at {file}:<*> s)`  
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*> s)`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at <*> s)
[UpdateBucket] Logs: This iter found: 0, total: 16070892/16075117, remain: 4225. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 321 -> 321, remain buckets: 55
Update failed: Template can not match logs `ShuffleMapStage <*> (reduceByKey at <*> s)`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) finished in <*> s`
[UpdateBucket] Logs: This iter found: 62, total: 16070954/16075117, remain: 4163. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 321 -> 259, remain buckets: 55
Update Success: Time for one update logs: 0.014751911163330078, template `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) finished in <*> s`
========================================================================================


Iteration 163
Sample 3 from current logs bucket: ID: 13, Len: 3, Bucket Size: 142, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Registering the ApplicationMaster`
	============ Response ====================
LogTemplate[1]: `Registering the {placeholder}`
	============ PostProcess ====================
	Post Template: `Registering the <*>`
	============ Aggregate ====================
	Aggregated Template:  Registering the <*>
[UpdateBucket] Logs: This iter found: 142, total: 16071096/16075117, remain: 4021. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 418 -> 276, remain buckets: 54
Update Success: Time for one update logs: 0.06226015090942383, template `Registering the <*>`
========================================================================================


Iteration 164
Sample 1 from current logs bucket: ID: 124, Len: 5, Bucket Size: 142, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Connecting to ResourceManager at mesos-master-1/10.10.34.11:8030`
	============ Response ====================
LogTemplate[1]: `Connecting to ResourceManager at mesos-master-1/{ip_or_url}:{port}`
	============ PostProcess ====================
	Post Template: `Connecting to ResourceManager at mesos-master-1/<*>`
	============ Aggregate ====================
	Aggregated Template:  Connecting to ResourceManager at mesos-master-1/<*>
[UpdateBucket] Logs: This iter found: 142, total: 16071238/16075117, remain: 3879. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 400 -> 258, remain buckets: 53
Update Success: Time for one update logs: 0.02045726776123047, template `Connecting to ResourceManager at mesos-master-1/<*>`
========================================================================================


Iteration 165
Sample 3 from current logs bucket: ID: 201, Len: 13, Bucket Size: 142, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals`
	============ Response ====================
LogTemplate[1]: `Started progress reporter thread with (heartbeat : {number}, initial allocation : {number}) intervals`
	============ PostProcess ====================
	Post Template: `Started progress reporter thread with (heartbeat : <*> initial allocation : <*>) intervals`
	============ Aggregate ====================
	Aggregated Template:  Started progress reporter thread with (heartbeat : <*> initial allocation : <*>) intervals
[UpdateBucket] Logs: This iter found: 142, total: 16071380/16075117, remain: 3737. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 234 -> 92, remain buckets: 52
Update Success: Time for one update logs: 0.014596939086914062, template `Started progress reporter thread with (heartbeat : <*> initial allocation : <*>) intervals`
========================================================================================


Iteration 166
Sample 3 from current logs bucket: ID: 163, Len: 7, Bucket Size: 141, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Missing an output location for shuffle 0`, MaxSim Log: `Missing an output location for shuffle 78`.
	============  Query  ====================
	Log[1]: `Missing an output location for shuffle 0`
	Log[2]: `Missing an output location for shuffle 3`
	Log[3]: `Missing an output location for shuffle 78`
	============ Response ====================
LogTemplate[1]: `Missing an output location for shuffle {shuffle_id}`  
LogTemplate[2]: `Missing an output location for shuffle {shuffle_id}`  
LogTemplate[3]: `Missing an output location for shuffle {shuffle_id}`  
	============ PostProcess ====================
	Post Template: `Missing an output location for shuffle <*>`
	Post Template: `Missing an output location for shuffle <*>`
	Post Template: `Missing an output location for shuffle <*>`
	============ Aggregate ====================
	Aggregated Template:  Missing an output location for shuffle <*>
[UpdateBucket] Logs: This iter found: 147, total: 16071527/16075117, remain: 3590. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 388 -> 241, remain buckets: 51
Update Success: Time for one update logs: 0.022275924682617188, template `Missing an output location for shuffle <*>`
========================================================================================


Iteration 167
Sample 3 from current logs bucket: ID: 208, Len: 14, Bucket Size: 140, Total Buckets: 239
Sampling from 139 logs, Sim Level: 5, MaxSim to anchor: 0.6471. Anchor: `Lost task 0.2 in stage 5.1 (TID 18, mesos-slave-27): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=`, MaxSim Log: `Lost task 0.1 in stage 3.1 (TID 18, mesos-slave-28): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=`.
	============  Query  ====================
	Log[1]: `Lost task 0.2 in stage 5.1 (TID 18, mesos-slave-27): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=`
	Log[2]: `Lost task 0.1 in stage 3.3 (TID 30, mesos-slave-23): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=0, message=`
	Log[3]: `Lost task 0.1 in stage 5.1 (TID 23, mesos-slave-25): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=2, message=`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage} (TID {tid}, mesos-slave-{slave_id}): FetchFailed(null, shuffleId=0, mapId=-1, reduceId={reduce_id}, message=`

LogTemplate[2]: `Lost task {task_id} in stage {stage} (TID {tid}, mesos-slave-{slave_id}): FetchFailed(null, shuffleId=0, mapId=-1, reduceId={reduce_id}, message=`

LogTemplate[3]: `Lost task {task_id} in stage {stage} (TID {tid}, mesos-slave-{slave_id}): FetchFailed(null, shuffleId=0, mapId=-1, reduceId={reduce_id}, message=`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=
[UpdateBucket] Logs: This iter found: 123, total: 16071650/16075117, remain: 3467. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 227 -> 104, remain buckets: 51
Update Success: Time for one update logs: 0.01587367057800293, template `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
========================================================================================


Iteration 168
Sample 3 from current logs bucket: ID: 83, Len: 3, Bucket Size: 138, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting failed stages`
	============ Response ====================
LogTemplate[1]: `Resubmitting failed stages`
	============ PostProcess ====================
	Post Template: `Resubmitting failed stages`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting failed stages
[UpdateBucket] Logs: This iter found: 138, total: 16071788/16075117, remain: 3329. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 276 -> 138, remain buckets: 50
Update Success: Time for one update logs: 0.057798147201538086, template `Resubmitting failed stages`
========================================================================================


Iteration 169
Sample 1 from current logs bucket: ID: 98, Len: 3, Bucket Size: 138, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Exception in createBlockOutputStream`
	============ Response ====================
LogTemplate[1]: `Exception in createBlockOutputStream`
	============ PostProcess ====================
	Post Template: `Exception in createBlockOutputStream`
	============ Aggregate ====================
	Aggregated Template:  Exception in createBlockOutputStream
[UpdateBucket] Logs: This iter found: 60, total: 16071848/16075117, remain: 3269. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 138 -> 78, remain buckets: 50
Update Success: Time for one update logs: 0.05878400802612305, template `Exception in createBlockOutputStream`
========================================================================================


Iteration 170
Sample 1 from current logs bucket: ID: 111, Len: 4, Bucket Size: 138, Total Buckets: 239
Sampling from 78 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Missing parents: List(ShuffleMapStage 1)`, MaxSim Log: `Missing parents: List(ShuffleMapStage 3)`.
	============  Query  ====================
	Log[1]: `Missing parents: List(ShuffleMapStage 1)`
	Log[2]: `Missing parents: List(ShuffleMapStage 33)`
	Log[3]: `Missing parents: List(ShuffleMapStage 9)`
	============ Response ====================
LogTemplate[1]: `Missing parents: List(ShuffleMapStage {stage_number})`
	============ PostProcess ====================
	Post Template: `Missing parents: List(ShuffleMapStage <*>)`
	Post Template: `Missing parents: List(ShuffleMapStage <*>)`
	Post Template: `Missing parents: List(ShuffleMapStage <*>)`
	============ Aggregate ====================
	Aggregated Template:  Missing parents: List(ShuffleMapStage <*>)
[UpdateBucket] Logs: This iter found: 138, total: 16071986/16075117, remain: 3131. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 378 -> 240, remain buckets: 49
Update Success: Time for one update logs: 0.026903867721557617, template `Missing parents: List(ShuffleMapStage <*>)`
========================================================================================


Iteration 171
Sample 3 from current logs bucket: ID: 214, Len: 17, Bucket Size: 132, Total Buckets: 239
Sampling from 131 logs, Sim Level: 4, MaxSim to anchor: 0.8889. Anchor: `Lost task 7.0 in stage 1.0 (TID 9) on executor mesos-slave-27: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`, MaxSim Log: `Lost task 7.0 in stage 1.0 (TID 9) on executor mesos-slave-10: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`.
	============  Query  ====================
	Log[1]: `Lost task 7.0 in stage 1.0 (TID 9) on executor mesos-slave-27: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	Log[2]: `Lost task 20.0 in stage 1.0 (TID 22) on executor mesos-master-3: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	Log[3]: `Lost task 38.0 in stage 2.0 (TID 80) on executor mesos-slave-11: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {executor_id}) on executor {executor_host}: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*>) on executor <*>: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	Post Template: `Lost task <*> in stage <*> (TID <*>) on executor <*>: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	Post Template: `Lost task <*> in stage <*> (TID <*>) on executor <*>: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*>) on executor <*>: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
[UpdateBucket] Logs: This iter found: 132, total: 16072118/16075117, remain: 2999. 
[UpdateBucket] Buckets: Checked 2 ([213, 214]), Parent Bucket size: 132 -> 0, remain buckets: 48
Update Success: Time for one update logs: 0.011741876602172852, template `Lost task <*> in stage <*> (TID <*>) on executor <*>: org.apache.spark.api.python.PythonException (Traceback (most recent call last):`
========================================================================================


Iteration 172
Sample 3 from current logs bucket: ID: 9, Len: 2, Bucket Size: 128, Total Buckets: 239
	============  Query  ====================
	Log[1]: `MapOutputTrackerMasterEndpoint stopped!`
	============ Response ====================
LogTemplate[1]: `MapOutputTrackerMasterEndpoint stopped!`
	============ PostProcess ====================
	Post Template: `MapOutputTrackerMasterEndpoint stopped!`
	============ Aggregate ====================
	Aggregated Template:  MapOutputTrackerMasterEndpoint stopped!
[UpdateBucket] Logs: This iter found: 64, total: 16072182/16075117, remain: 2935. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 320 -> 256, remain buckets: 48
Update Success: Time for one update logs: 0.016076087951660156, template `MapOutputTrackerMasterEndpoint stopped!`
========================================================================================


Iteration 173
Sample 1 from current logs bucket: ID: 11, Len: 2, Bucket Size: 128, Total Buckets: 239
Sampling from 62 logs failed
	============  Query  ====================
	Log[1]: `YarnClusterScheduler.postStartHook done`
	============ Response ====================
LogTemplate[1]: `YarnClusterScheduler.postStartHook done`
	============ PostProcess ====================
	Post Template: `YarnClusterScheduler.postStartHook done`
	============ Aggregate ====================
	Aggregated Template:  YarnClusterScheduler.postStartHook done
[UpdateBucket] Logs: This iter found: 64, total: 16072246/16075117, remain: 2871. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 256 -> 192, remain buckets: 48
Update Success: Time for one update logs: 0.018822193145751953, template `YarnClusterScheduler.postStartHook done`
========================================================================================


Iteration 174
Sample 3 from current logs bucket: ID: 210, Len: 15, Bucket Size: 127, Total Buckets: 239
Sampling from 109 logs, Sim Level: 3, MaxSim to anchor: 0.8750. Anchor: `Container marked as failed: container_1485248649253_0126_01_000013 on host: mesos-slave-22. Exit status: 1. Diagnostics: Exception from container-launch.`, MaxSim Log: `Container marked as failed: container_1485248649253_0126_01_000041 on host: mesos-slave-22. Exit status: 1. Diagnostics: Exception from container-launch.`.
	============  Query  ====================
	Log[1]: `Container marked as failed: container_1485248649253_0126_01_000013 on host: mesos-slave-22. Exit status: 1. Diagnostics: Exception from container-launch.`
	Log[2]: `Container marked as failed: container_1485248649253_0132_01_000053 on host: mesos-slave-26. Exit status: 1. Diagnostics: Exception from container-launch.`
	Log[3]: `Container marked as failed: container_1485248649253_0076_01_000003 on host: mesos-slave-21. Exit status: 52. Diagnostics: Exception from container-launch.`
	============ Response ====================
LogTemplate[1]: `Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`

LogTemplate[2]: `Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`

LogTemplate[3]: `Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`

In this case, the dynamic variables are:
- `{container_id}`: container_1485248649253_0126_01_000013, container_1485248649253_0132_01_000053, container_1485248649253_0076_01_000003
- `{host}`: mesos-slave-22, mesos-slave-26, mesos-slave-21
- `{exit_status}`: 1, 1, 52

The log templates are the same for all three logs, with only the values of the dynamic variables changing.
	============ PostProcess ====================
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	============ Aggregate ====================
	Aggregated Template:  Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.
[UpdateBucket] Logs: This iter found: 127, total: 16072373/16075117, remain: 2744. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 207 -> 80, remain buckets: 47
Update Success: Time for one update logs: 0.013164997100830078, template `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
========================================================================================


Iteration 175
Sample 3 from current logs bucket: ID: 168, Len: 8, Bucket Size: 126, Total Buckets: 239
Sampling from 125 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Failed to send RPC 7566235838710499706 to mesos-slave-06/10.10.34.16:33023: java.nio.channels.ClosedChannelException`, MaxSim Log: `Failed to send RPC 8616227898200151329 to mesos-slave-06/10.10.34.16:33023: java.nio.channels.ClosedChannelException`.
	============  Query  ====================
	Log[1]: `Failed to send RPC 7566235838710499706 to mesos-slave-06/10.10.34.16:33023: java.nio.channels.ClosedChannelException`
	Log[2]: `Failed to send RPC 6364117827745496549 to mesos-slave-20/10.10.34.30:60510: java.nio.channels.ClosedChannelException`
	Log[3]: `Failed to send RPC 8551390897890018762 to mesos-master-3/10.10.34.13:46011: java.nio.channels.ClosedChannelException`
	============ Response ====================
LogTemplate[1]: `Failed to send RPC {rpc_id} to mesos-slave-{slave_id}/{ip}: java.nio.channels.ClosedChannelException`
LogTemplate[2]: `Failed to send RPC {rpc_id} to mesos-slave-{slave_id}/{ip}: java.nio.channels.ClosedChannelException`
LogTemplate[3]: `Failed to send RPC {rpc_id} to mesos-master-{master_id}/{ip}: java.nio.channels.ClosedChannelException`
	============ PostProcess ====================
	Post Template: `Failed to send RPC <*> to mesos-slave-<*>: java.nio.channels.ClosedChannelException`
	Post Template: `Failed to send RPC <*> to mesos-slave-<*>: java.nio.channels.ClosedChannelException`
	Post Template: `Failed to send RPC <*> to mesos-master-<*>: java.nio.channels.ClosedChannelException`
	============ Aggregate ====================
	Aggregated Template:  Failed to send RPC <*> to mesos-slave-<*>: java.nio.channels.ClosedChannelException
[UpdateBucket] Logs: This iter found: 78, total: 16072451/16075117, remain: 2666. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 220 -> 142, remain buckets: 47
Update Success: Time for one update logs: 0.017880916595458984, template `Failed to send RPC <*> to mesos-slave-<*>: java.nio.channels.ClosedChannelException`
========================================================================================


Iteration 176
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 125, Total Buckets: 239
Sampling from 3 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Stage 1 was cancelled`, MaxSim Log: `Stage 3 was cancelled`.
	============  Query  ====================
	Log[1]: `Stage 1 was cancelled`
	Log[2]: `Stage 3 was cancelled`
	Log[3]: `Stage 108 was cancelled`
	============ Response ====================
LogTemplate[1]: `Stage {number} was cancelled`
LogTemplate[2]: `Stage {number} was cancelled`
LogTemplate[3]: `Stage {number} was cancelled`
	============ PostProcess ====================
	Post Template: `Stage <*> was cancelled`
	Post Template: `Stage <*> was cancelled`
	Post Template: `Stage <*> was cancelled`
	============ Aggregate ====================
	Aggregated Template:  Stage <*> was cancelled
[UpdateBucket] Logs: This iter found: 26, total: 16072477/16075117, remain: 2640. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 240 -> 214, remain buckets: 47
Update Success: Time for one update logs: 0.023257970809936523, template `Stage <*> was cancelled`
========================================================================================


Iteration 177
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 124, Total Buckets: 239
Sampling from 9 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Lost an executor 7 (already removed): Pending loss reason.`, MaxSim Log: `Lost an executor 9 (already removed): Pending loss reason.`.
	============  Query  ====================
	Log[1]: `Lost an executor 7 (already removed): Pending loss reason.`
	Log[2]: `Lost an executor 2 (already removed): Pending loss reason.`
	Log[3]: `Lost an executor 17 (already removed): Pending loss reason.`
	============ Response ====================
LogTemplate[1]: `Lost an executor {executor_id} (already removed): Pending loss reason.`
	============ PostProcess ====================
	Post Template: `Lost an executor <*> (already removed): Pending loss reason.`
	Post Template: `Lost an executor <*> (already removed): Pending loss reason.`
	Post Template: `Lost an executor <*> (already removed): Pending loss reason.`
	============ Aggregate ====================
	Aggregated Template:  Lost an executor <*> (already removed): Pending loss reason.
[UpdateBucket] Logs: This iter found: 18, total: 16072495/16075117, remain: 2622. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 259 -> 241, remain buckets: 47
Update Success: Time for one update logs: 0.01977086067199707, template `Lost an executor <*> (already removed): Pending loss reason.`
========================================================================================


Iteration 178
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 122, Total Buckets: 239
Sampling from 77 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Driver terminated or disconnected! Shutting down. mesos-master-1:35910`, MaxSim Log: `Driver terminated or disconnected! Shutting down. mesos-master-1:43537`.
	============  Query  ====================
	Log[1]: `Driver terminated or disconnected! Shutting down. mesos-master-1:35910`
	Log[2]: `Driver terminated or disconnected! Shutting down. mesos-master-1:42303`
	Log[3]: `Driver terminated or disconnected! Shutting down. 10.10.34.11:51096`
	============ Response ====================
LogTemplate[1]: `Driver terminated or disconnected! Shutting down. mesos-master-1:{port}`

LogTemplate[2]: `Driver terminated or disconnected! Shutting down. mesos-master-1:{port}`

LogTemplate[3]: `Driver terminated or disconnected! Shutting down. {ip}:{port}`
	============ PostProcess ====================
	Post Template: `Driver terminated or disconnected! Shutting down. mesos-master-<*>`
	Post Template: `Driver terminated or disconnected! Shutting down. mesos-master-<*>`
	Post Template: `Driver terminated or disconnected! Shutting down. <*>`
	============ Aggregate ====================
	Aggregated Template:  Driver terminated or disconnected! Shutting down. mesos-master-<*>
[UpdateBucket] Logs: This iter found: 76, total: 16072571/16075117, remain: 2546. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 241 -> 165, remain buckets: 47
Update Success: Time for one update logs: 0.023524045944213867, template `Driver terminated or disconnected! Shutting down. mesos-master-<*>`
========================================================================================


Iteration 179
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 121, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `User application exited with status 1`, MaxSim Log: `Issue communicating with driver in heartbeater`.
	============  Query  ====================
	Log[1]: `User application exited with status 1`
	============ Response ====================
LogTemplate[1]: `User application exited with status {status}`
	============ PostProcess ====================
	Post Template: `User application exited with status <*>`
	============ Aggregate ====================
	Aggregated Template:  User application exited with status <*>
[UpdateBucket] Logs: This iter found: 57, total: 16072628/16075117, remain: 2489. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 266 -> 209, remain buckets: 47
Update Success: Time for one update logs: 0.021042823791503906, template `User application exited with status <*>`
========================================================================================


Iteration 180
Sample 3 from current logs bucket: ID: 155, Len: 7, Bucket Size: 119, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Waiting for application to be successfully unregistered.`
	============ Response ====================
LogTemplate[1]: `Waiting for application to be successfully unregistered.`
	============ PostProcess ====================
	Post Template: `Waiting for application to be successfully unregistered.`
	============ Aggregate ====================
	Aggregated Template:  Waiting for application to be successfully unregistered.
[UpdateBucket] Logs: This iter found: 119, total: 16072747/16075117, remain: 2370. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 165 -> 46, remain buckets: 46
Update Success: Time for one update logs: 0.025217056274414062, template `Waiting for application to be successfully unregistered.`
========================================================================================


Iteration 181
Sample 3 from current logs bucket: ID: 107, Len: 4, Bucket Size: 115, Total Buckets: 239
Sampling from 114 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Deleting staging directory .sparkStaging/application_1485248649253_0020`, MaxSim Log: `Deleting staging directory .sparkStaging/application_1485248649253_0018`.
	============  Query  ====================
	Log[1]: `Deleting staging directory .sparkStaging/application_1485248649253_0020`
	Log[2]: `Deleting staging directory .sparkStaging/application_1485248649253_0059`
	Log[3]: `Deleting staging directory .sparkStaging/application_1485248649253_0062`
	============ Response ====================
LogTemplate[1]: `Deleting staging directory .sparkStaging/application_{app_id}`  
LogTemplate[2]: `Deleting staging directory .sparkStaging/application_{app_id}`  
LogTemplate[3]: `Deleting staging directory .sparkStaging/application_{app_id}`  
	============ PostProcess ====================
	Post Template: `Deleting staging directory .sparkStaging/application_<*>`
	Post Template: `Deleting staging directory .sparkStaging/application_<*>`
	Post Template: `Deleting staging directory .sparkStaging/application_<*>`
	============ Aggregate ====================
	Aggregated Template:  Deleting staging directory .sparkStaging/application_<*>
[UpdateBucket] Logs: This iter found: 115, total: 16072862/16075117, remain: 2255. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 214 -> 99, remain buckets: 45
Update Success: Time for one update logs: 0.025707006454467773, template `Deleting staging directory .sparkStaging/application_<*>`
========================================================================================


Iteration 182
Sample 3 from current logs bucket: ID: 220, Len: 20, Bucket Size: 110, Total Buckets: 239
Sampling from 109 logs, Sim Level: 5, MaxSim to anchor: 0.8182. Anchor: `Lost task 12.0 in stage 1.0 (TID 14, mesos-slave-24): java.io.IOException: Cannot run program "/home/curi/anaconda2/bin/python": error=2, No such file or directory`, MaxSim Log: `Lost task 8.0 in stage 12.0 (TID 491, mesos-slave-24): java.io.IOException: Cannot run program "/home/curi/anaconda2/bin/python": error=2, No such file or directory`.
	============  Query  ====================
	Log[1]: `Lost task 12.0 in stage 1.0 (TID 14, mesos-slave-24): java.io.IOException: Cannot run program "/home/curi/anaconda2/bin/python": error=2, No such file or directory`
	Log[2]: `Lost task 4.0 in stage 7.0 (TID 264, mesos-slave-24): java.io.IOException: Cannot run program "/home/curi/anaconda2/bin/python": error=2, No such file or directory`
	Log[3]: `Lost task 11.0 in stage 53.0 (TID 2269, mesos-master-2): java.io.IOException: Cannot run program "/home/curi/anaconda2/bin/python": error=2, No such file or directory`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {node}): java.io.IOException: Cannot run program "{file_path}": error=2, No such file or directory`  
LogTemplate[2]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {node}): java.io.IOException: Cannot run program "{file_path}": error=2, No such file or directory`  
LogTemplate[3]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {node}): java.io.IOException: Cannot run program "{file_path}": error=2, No such file or directory`  
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory
[UpdateBucket] Logs: This iter found: 108, total: 16072970/16075117, remain: 2147. 
[UpdateBucket] Buckets: Checked 2 ([220, 221]), Parent Bucket size: 116 -> 8, remain buckets: 45
Update Success: Time for one update logs: 0.011400938034057617, template `Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory`
========================================================================================


Iteration 183
Sample 3 from current logs bucket: ID: 216, Len: 18, Bucket Size: 107, Total Buckets: 239
Sampling from 71 logs, Sim Level: 2, MaxSim to anchor: 0.8889. Anchor: `Container marked as failed: container_1485248649253_0037_01_000002 on host: mesos-slave-16. Exit status: -100. Diagnostics: Container expired since it was unused`, MaxSim Log: `Container marked as failed: container_1485248649253_0126_01_000003 on host: mesos-slave-16. Exit status: -100. Diagnostics: Container expired since it was unused`.
	============  Query  ====================
	Log[1]: `Container marked as failed: container_1485248649253_0037_01_000002 on host: mesos-slave-16. Exit status: -100. Diagnostics: Container expired since it was unused`
	Log[2]: `Container marked as failed: container_1485248649253_0072_02_000014 on host: mesos-slave-09. Exit status: -100. Diagnostics: Container expired since it was unused`
	Log[3]: `Container marked as failed: container_1485248649253_0174_01_000012 on host: mesos-slave-15. Exit status: -100. Diagnostics: Container expired since it was unused`
	============ Response ====================
LogTemplate[1]: `Container marked as failed: container_<*> on host: mesos-slave-<*>. Exit status: -100. Diagnostics: Container expired since it was unused`
	============ PostProcess ====================
	Post Template: `Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused`
	Post Template: `Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused`
	Post Template: `Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused`
	============ Aggregate ====================
	Aggregated Template:  Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused
[UpdateBucket] Logs: This iter found: 107, total: 16073077/16075117, remain: 2040. 
[UpdateBucket] Buckets: Checked 2 ([215, 216]), Parent Bucket size: 107 -> 0, remain buckets: 44
Update Success: Time for one update logs: 0.012195110321044922, template `Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused`
========================================================================================


Iteration 184
Sample 3 from current logs bucket: ID: 133, Len: 6, Bucket Size: 106, Total Buckets: 239
Sampling from 105 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.23:45586]`, MaxSim Log: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.31:32842]`.
	============  Query  ====================
	Log[1]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.23:45586]`
	Log[2]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.20:57719]`
	Log[3]: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:47912]`
	============ Response ====================
LogTemplate[1]: `Remoting started; listening on addresses :[akka.tcp://<actor_system>@{ip}:<port>]`
	============ PostProcess ====================
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<actor_system>@<*>:<port>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<actor_system>@<*>:<port>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<actor_system>@<*>:<port>]`
	============ Aggregate ====================
	Aggregated Template:  Remoting started; listening on addresses :[akka.tcp://<actor_system>@<*>:<port>]
[UpdateBucket] Logs: This iter found: 0, total: 16073077/16075117, remain: 2040. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 209 -> 209, remain buckets: 44
Update failed: Template can not match logs `Remoting started; listening on addresses :[akka.tcp://<actor_system>@<*>:<port>]`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 133, Len: 6, Bucket Size: 106, Total Buckets: 239
Sampling from 105 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.23:45586]`, MaxSim Log: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.31:32842]`.
	============  Query  ====================
	Log[1]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.23:45586]`
	Log[2]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.10.34.30:53059]`
	Log[3]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@mesos-slave-30:52168]`
	============ Response ====================
LogTemplate[1]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@{ip_address}:{port}]`
LogTemplate[2]: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@{ip_address}:{port}]`
LogTemplate[3]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@{hostname}:{port}]`
	============ PostProcess ====================
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@<*>]`
	============ Aggregate ====================
	Aggregated Template:  Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@<*>]
[UpdateBucket] Logs: This iter found: 64, total: 16073141/16075117, remain: 1976. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 209 -> 145, remain buckets: 44
[TemplateDB] Try Merge: `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@<*>]` | `Remoting started; listening on addresses :[akka.tcp://sparkExecutorActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://spark<*>rActorSystem@<*>]`
[TemplateDB] Merged: -> `Remoting started; listening on addresses :[akka.tcp://spark<*>rActorSystem@<*>]`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2336/2336, in child Bucket [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]
[UpdateBucket] Logs: This iter found: 0, total: 16073141/16075117, remain: 1976. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 145 -> 145, remain buckets: 44
[TemplateDB] Update Indexes: 2336 -> 2336 for `Remoting started; listening on addresses :[akka.tcp://spark<*>rActorSystem@<*>]`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Remoting started; listening on addresses :[akka.tcp://spark<*>rActorSystem@<*>]`
Update Success: Time for one update logs: 0.0868523120880127, template `Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@<*>]`
========================================================================================


Iteration 185
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 106, Total Buckets: 239
Sampling from 65 logs failed
	============  Query  ====================
	Log[1]: `This may have been caused by a prior exception:`
	============ Response ====================
LogTemplate[1]: `This may have been caused by a prior exception:`
	============ PostProcess ====================
	Post Template: `This may have been caused by a prior exception:`
	============ Aggregate ====================
	Aggregated Template:  This may have been caused by a prior exception:
[UpdateBucket] Logs: This iter found: 35, total: 16073176/16075117, remain: 1941. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 241 -> 206, remain buckets: 44
Update Success: Time for one update logs: 0.015419244766235352, template `This may have been caused by a prior exception:`
========================================================================================


Iteration 186
Sample 3 from current logs bucket: ID: 128, Len: 5, Bucket Size: 104, Total Buckets: 239
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Starting job: count at pnmf4.py:333`, MaxSim Log: `Starting job: count at pnmf4.py:353`.
	============  Query  ====================
	Log[1]: `Starting job: count at pnmf4.py:333`
	Log[2]: `Starting job: count at pnmf4.py:353`
	Log[3]: `Starting job: count at IPLoM.py:161`
	============ Response ====================
LogTemplate[1]: `Starting job: count at {script}:{line_number}`  
LogTemplate[2]: `Starting job: count at {script}:{line_number}`  
LogTemplate[3]: `Starting job: count at {script}:{line_number}`  
	============ PostProcess ====================
	Post Template: `Starting job: count at <*>`
	Post Template: `Starting job: count at <*>`
	Post Template: `Starting job: count at <*>`
	============ Aggregate ====================
	Aggregated Template:  Starting job: count at <*>
[UpdateBucket] Logs: This iter found: 104, total: 16073280/16075117, remain: 1837. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 258 -> 154, remain buckets: 43
[TemplateDB] Try Merge: `Starting job: count at <*>` | `Starting job: collect at <*>`
[TemplateDB] Reject Merge, Remain Template: `Starting job: count at <*>`
Update Success: Time for one update logs: 0.02448892593383789, template `Starting job: count at <*>`
========================================================================================


Iteration 187
Sample 3 from current logs bucket: ID: 225, Len: 25, Bucket Size: 103, Total Buckets: 239
Sampling from 6 logs, Sim Level: 1, MaxSim to anchor: 0.9200. Anchor: `Connection to mesos-master-1/10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`, MaxSim Log: `Connection to /10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`.
	============  Query  ====================
	Log[1]: `Connection to mesos-master-1/10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Log[2]: `Connection to mesos-master-1/10.10.34.11:34641 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Log[3]: `Connection to /10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ Response ====================
LogTemplate[1]: `Connection to mesos-master-1/{ip_or_url} has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`

LogTemplate[2]: `Connection to mesos-master-1/{ip_or_url} has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`

LogTemplate[3]: `Connection to /{ip_or_url} has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ PostProcess ====================
	Post Template: `Connection to mesos-master-1/<*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Post Template: `Connection to mesos-master-1/<*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Post Template: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ Aggregate ====================
	Aggregated Template:  Connection to mesos-master-1/<*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.
[UpdateBucket] Logs: This iter found: 84, total: 16073364/16075117, remain: 1753. 
[UpdateBucket] Buckets: Checked 2 ([225, 226]), Parent Bucket size: 107 -> 23, remain buckets: 43
Update Success: Time for one update logs: 0.014583110809326172, template `Connection to mesos-master-1/<*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
========================================================================================


Iteration 188
Sample 3 from current logs bucket: ID: 199, Len: 12, Bucket Size: 101, Total Buckets: 239
Sampling from 24 logs, Sim Level: 1, MaxSim to anchor: 0.0455. Anchor: `Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)`, MaxSim Log: `Lost executor 8 on mesos-slave-05: Container container_1485248649253_0036_02_000014 exited from explicit termination request.`.
	============  Query  ====================
	Log[1]: `Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)`
	============ Response ====================
LogTemplate[1]: `Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)`
	============ PostProcess ====================
	Post Template: `Unregistering ApplicationMaster with FAILED (diag message: User application exited with status <*>)`
	============ Aggregate ====================
	Aggregated Template:  Unregistering ApplicationMaster with FAILED (diag message: User application exited with status <*>)
[UpdateBucket] Logs: This iter found: 30, total: 16073394/16075117, remain: 1723. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 114 -> 84, remain buckets: 43
Update Success: Time for one update logs: 0.012526988983154297, template `Unregistering ApplicationMaster with FAILED (diag message: User application exited with status <*>)`
========================================================================================


Iteration 189
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 99, Total Buckets: 239
Sampling from 78 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Driver now available: 10.10.34.11:35910`, MaxSim Log: `Driver now available: 10.10.34.11:43537`.
	============  Query  ====================
	Log[1]: `Driver now available: 10.10.34.11:35910`
	Log[2]: `Driver now available: 10.10.34.11:35430`
	Log[3]: `Driver now available: 10.10.34.11:32921`
	============ Response ====================
LogTemplate[1]: `Driver now available: {ip_or_url}:{port}`
LogTemplate[2]: `Driver now available: {ip_or_url}:{port}`
LogTemplate[3]: `Driver now available: {ip_or_url}:{port}`
	============ PostProcess ====================
	Post Template: `Driver now available: <*>`
	Post Template: `Driver now available: <*>`
	Post Template: `Driver now available: <*>`
	============ Aggregate ====================
	Aggregated Template:  Driver now available: <*>
[UpdateBucket] Logs: This iter found: 81, total: 16073475/16075117, remain: 1642. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 99 -> 18, remain buckets: 43
Update Success: Time for one update logs: 0.026247024536132812, template `Driver now available: <*>`
========================================================================================


Iteration 190
Sample 3 from current logs bucket: ID: 187, Len: 10, Bucket Size: 97, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.1111. Anchor: `SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8`, MaxSim Log: `Another thread is loading rdd_27_39, waiting for it to finish...`.
	============  Query  ====================
	Log[1]: `SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8`
	============ Response ====================
LogTemplate[1]: `SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: {number}`
	============ PostProcess ====================
	Post Template: `SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: <*>`
	============ Aggregate ====================
	Aggregated Template:  SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: <*>
[UpdateBucket] Logs: This iter found: 54, total: 16073529/16075117, remain: 1588. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 97 -> 43, remain buckets: 43
Update Success: Time for one update logs: 0.0072019100189208984, template `SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: <*>`
========================================================================================


Iteration 191
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 96, Total Buckets: 239
Sampling from 17 logs failed
	============  Query  ====================
	Log[1]: `Python worker exited unexpectedly (crashed)`
	============ Response ====================
LogTemplate[1]: `Python worker exited unexpectedly (crashed)`
	============ PostProcess ====================
	Post Template: `Python worker exited unexpectedly (crashed)`
	============ Aggregate ====================
	Aggregated Template:  Python worker exited unexpectedly (crashed)
[UpdateBucket] Logs: This iter found: 35, total: 16073564/16075117, remain: 1553. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 154 -> 119, remain buckets: 43
Update Success: Time for one update logs: 0.017881155014038086, template `Python worker exited unexpectedly (crashed)`
========================================================================================


Iteration 192
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 94, Total Buckets: 239
Sampling from 18 logs, Sim Level: 2, MaxSim to anchor: 0.1429. Anchor: `Starting the user application in a separate Thread`, MaxSim Log: `Reporter thread fails 1 time(s) in a row.`.
	============  Query  ====================
	Log[1]: `Starting the user application in a separate Thread`
	============ Response ====================
LogTemplate[1]: `Starting the user application in a separate Thread`
	============ PostProcess ====================
	Post Template: `Starting the user application in a separate Thread`
	============ Aggregate ====================
	Aggregated Template:  Starting the user application in a separate Thread
[UpdateBucket] Logs: This iter found: 64, total: 16073628/16075117, remain: 1489. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 142 -> 78, remain buckets: 43
Update Success: Time for one update logs: 0.009625911712646484, template `Starting the user application in a separate Thread`
========================================================================================


Iteration 193
Sample 3 from current logs bucket: ID: 204, Len: 13, Bucket Size: 92, Total Buckets: 239
Sampling from 25 logs, Sim Level: 2, MaxSim to anchor: 0.0417. Anchor: `Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)`, MaxSim Log: `Removing executor 8 with no recent heartbeats: 167979 ms exceeds timeout 120000 ms`.
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: <*> (reason: User application exited with status <*>)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: User application exited with status <*>)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <*> (reason: User application exited with status <*>)
[UpdateBucket] Logs: This iter found: 57, total: 16073685/16075117, remain: 1432. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 92 -> 35, remain buckets: 43
Update Success: Time for one update logs: 0.014869928359985352, template `Final app status: FAILED, exitCode: <*> (reason: User application exited with status <*>)`
========================================================================================


Iteration 194
Sample 3 from current logs bucket: ID: 209, Len: 14, Bucket Size: 87, Total Buckets: 239
Sampling from 70 logs, Sim Level: 3, MaxSim to anchor: 0.8667. Anchor: `Ignoring response for RPC 6373440704166081624 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`, MaxSim Log: `Ignoring response for RPC 6596629245993899365 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`.
	============  Query  ====================
	Log[1]: `Ignoring response for RPC 6373440704166081624 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`
	Log[2]: `Ignoring response for RPC 4844382251313928929 from mesos-master-3/10.10.34.13:40989 (273 bytes) since it is not outstanding`
	Log[3]: `Ignoring response for RPC 5623435829345208755 from mesos-master-3/10.10.34.13:46011 (305 bytes) since it is not outstanding`
	============ Response ====================
LogTemplate[1]: `Ignoring response for RPC {rpc_id} from mesos-master-1/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
LogTemplate[2]: `Ignoring response for RPC {rpc_id} from mesos-master-3/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
LogTemplate[3]: `Ignoring response for RPC {rpc_id} from mesos-master-3/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
	============ PostProcess ====================
	Post Template: `Ignoring response for RPC <*> from mesos-master-1/<*> (<*> bytes) since it is not outstanding`
	Post Template: `Ignoring response for RPC <*> from mesos-master-3/<*> (<*> bytes) since it is not outstanding`
	Post Template: `Ignoring response for RPC <*> from mesos-master-3/<*> (<*> bytes) since it is not outstanding`
	============ Aggregate ====================
	Aggregated Template:  Ignoring response for RPC <*> from mesos-master-3/<*> (<*> bytes) since it is not outstanding
[UpdateBucket] Logs: This iter found: 66, total: 16073751/16075117, remain: 1366. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 104 -> 38, remain buckets: 43
Update Success: Time for one update logs: 0.015073060989379883, template `Ignoring response for RPC <*> from mesos-master-3/<*> (<*> bytes) since it is not outstanding`
========================================================================================


Iteration 195
Sample 3 from current logs bucket: ID: 179, Len: 9, Bucket Size: 84, Total Buckets: 239
Sampling from 83 logs, Sim Level: 3, MaxSim to anchor: 0.8000. Anchor: `ShuffleMapStage 1 (reduceByKey at pnmf_dblp.py:389) finished in 22.465 s`, MaxSim Log: `ShuffleMapStage 1 (reduceByKey at pnmf_dblp.py:389) finished in 21.441 s`.
	============  Query  ====================
	Log[1]: `ShuffleMapStage 1 (reduceByKey at pnmf_dblp.py:389) finished in 22.465 s`
	Log[2]: `ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) finished in 39.313 s`
	Log[3]: `ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) finished in 18.747 s`
	============ Response ====================
LogTemplate[1]: `ShuffleMapStage {stage_num} (reduceByKey at pnmf_dblp.py:{line_num}) finished in {duration} s`
	============ PostProcess ====================
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s
[UpdateBucket] Logs: This iter found: 68, total: 16073819/16075117, remain: 1298. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 206 -> 138, remain buckets: 43
[TemplateDB] Try Merge: `ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s` | `ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) finished in <*> s`
	Post Template: `ShuffleMapStage <*> (reduceByKey at <*>.py:<*>) finished in <*> s`
[TemplateDB] Merged: -> `ShuffleMapStage <*> (reduceByKey at <*>.py:<*>) finished in <*> s`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 130/130, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
[UpdateBucket] Logs: This iter found: 16, total: 16073835/16075117, remain: 1282. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 138 -> 122, remain buckets: 42
[TemplateDB] Update Indexes: 130 -> 146 for `ShuffleMapStage <*> (reduceByKey at <*>.py:<*>) finished in <*> s`
[TemplateBaseUpdate] Match unparsed logs 16 with new template `ShuffleMapStage <*> (reduceByKey at <*>.py:<*>) finished in <*> s`
Update Success: Time for one update logs: 0.04658102989196777, template `ShuffleMapStage <*> (reduceByKey at pnmf_dblp.py:<*>) finished in <*> s`
========================================================================================


Iteration 196
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 80, Total Buckets: 239
Sampling from 74 logs, Sim Level: 9, MaxSim to anchor: 0.7647. Anchor: `Lost task 25.0 in stage 1.0 (TID 27, mesos-slave-27): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`, MaxSim Log: `Lost task 25.1 in stage 1.0 (TID 51, mesos-slave-27): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`.
	============  Query  ====================
	Log[1]: `Lost task 25.0 in stage 1.0 (TID 27, mesos-slave-27): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	Log[2]: `Lost task 13.0 in stage 2.0 (TID 55, mesos-slave-11): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	Log[3]: `Lost task 0.0 in stage 2.1 (TID 12, mesos-master-2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-{node_id}): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
[UpdateBucket] Logs: This iter found: 35, total: 16073870/16075117, remain: 1247. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 80 -> 45, remain buckets: 42
Update Success: Time for one update logs: 0.010111093521118164, template `Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):`
========================================================================================


Iteration 197
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 78, Total Buckets: 239
Sampling from 5 logs failed
	============  Query  ====================
	Log[1]: `Excluding datanode DatanodeInfoWithStorage[10.10.34.15:50010,DS-8de4ae37-fac2-404a-a8e3-dcecd440f907,DISK]`
	============ Response ====================
LogTemplate[1]: `Excluding datanode DatanodeInfoWithStorage[{ip_or_url},<*>]`
	============ PostProcess ====================
	Post Template: `Excluding datanode DatanodeInfoWithStorage[<*>]`
	============ Aggregate ====================
	Aggregated Template:  Excluding datanode DatanodeInfoWithStorage[<*>]
[UpdateBucket] Logs: This iter found: 60, total: 16073930/16075117, remain: 1187. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 78 -> 18, remain buckets: 42
Update Success: Time for one update logs: 0.060491085052490234, template `Excluding datanode DatanodeInfoWithStorage[<*>]`
========================================================================================


Iteration 198
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 71, Total Buckets: 239
Sampling from 38 logs, Sim Level: 3, MaxSim to anchor: 0.8000. Anchor: `ResultStage 5 (collect at pnmf4.py:377) failed in 1052.368 s`, MaxSim Log: `ResultStage 5 (collect at pnmf4.py:377) failed in 112.088 s`.
	============  Query  ====================
	Log[1]: `ResultStage 5 (collect at pnmf4.py:377) failed in 1052.368 s`
	Log[2]: `ResultStage 108 (collect at pnmf.py:279) failed in 0.354 s`
	Log[3]: `ResultStage 3 (collect at pnmf4.py:376) failed in 733.152 s`
	============ Response ====================
LogTemplate[1]: `ResultStage {stage_num} (collect at {script}:377) failed in {duration} s`
LogTemplate[2]: `ResultStage {stage_num} (collect at {script}:279) failed in {duration} s`
LogTemplate[3]: `ResultStage {stage_num} (collect at {script}:376) failed in {duration} s`
	============ PostProcess ====================
	Post Template: `ResultStage <*> (collect at <*>) failed in <*> s`
	Post Template: `ResultStage <*> (collect at <*>) failed in <*> s`
	Post Template: `ResultStage <*> (collect at <*>) failed in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ResultStage <*> (collect at <*>) failed in <*> s
[UpdateBucket] Logs: This iter found: 26, total: 16073956/16075117, remain: 1161. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 122 -> 96, remain buckets: 42
[TemplateDB] Try Merge: `ResultStage <*> (collect at <*>) failed in <*> s` | `ResultStage <*> (collect at <*>) finished in <*> s`
[TemplateDB] Reject Merge, Remain Template: `ResultStage <*> (collect at <*>) failed in <*> s`
Update Success: Time for one update logs: 0.01820993423461914, template `ResultStage <*> (collect at <*>) failed in <*> s`
========================================================================================


Iteration 199
Sample 3 from current logs bucket: ID: 199, Len: 12, Bucket Size: 71, Total Buckets: 239
Sampling from 48 logs, Sim Level: 1, MaxSim to anchor: 0.0435. Anchor: `Lost task 33.3 in stage 1.0 (TID 72, mesos-master-3): TaskKilled (killed intentionally)`, MaxSim Log: `Lost executor 8 on mesos-slave-05: Executor heartbeat timed out after 167979 ms`.
	============  Query  ====================
	Log[1]: `Lost task 33.3 in stage 1.0 (TID 72, mesos-master-3): TaskKilled (killed intentionally)`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage} (TID {task_id}, {executor}): {reason}`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): <*>`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): <*>
[UpdateBucket] Logs: This iter found: 14, total: 16073970/16075117, remain: 1147. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 84 -> 70, remain buckets: 41
Update Success: Time for one update logs: 0.014494895935058594, template `Lost task <*> in stage <*> (TID <*> <*>): <*>`
========================================================================================


Iteration 200
Sample 3 from current logs bucket: ID: 199, Len: 12, Bucket Size: 70, Total Buckets: 239
Sampling from 21 logs, Sim Level: 3, MaxSim to anchor: 0.5000. Anchor: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1003843761537, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=/opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0076/blockmgr-dc037334-5e92-45ae-b7b7-642e0abd235d/0c/shuffle_0_0_0.data, offset=0, length=2045089323}} to /10.10.34.27:58087; closing connection`, MaxSim Log: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=563371592329, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=/opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0068/blockmgr-93ca9a72-613d-4f49-b981-c57886eb2c85/0c/shuffle_0_0_0.data, offset=0, length=1269361191}} to /10.10.34.16:45985; closing connection`.
	============  Query  ====================
	Log[1]: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=1003843761537, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=/opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0076/blockmgr-dc037334-5e92-45ae-b7b7-642e0abd235d/0c/shuffle_0_0_0.data, offset=0, length=2045089323}} to /10.10.34.27:58087; closing connection`
	Log[2]: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=563371592329, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=/opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0068/blockmgr-93ca9a72-613d-4f49-b981-c57886eb2c85/0c/shuffle_0_0_0.data, offset=0, length=1269361191}} to /10.10.34.16:45985; closing connection`
	============ Response ====================
LogTemplate[1]: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=<*>, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=<*>, offset=0, length=<*>}} to /{ip_or_url}; closing connection`  
LogTemplate[2]: `Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=<*>, chunkIndex=0}, buffer=FileSegmentManagedBuffer{file=<*>, offset=0, length=<*>}} to /{ip_or_url}; closing connection`  
	============ PostProcess ====================
	Post Template: `Error sending result <*> buffer=<*>} to /<*>; closing connection`
	Post Template: `Error sending result <*> buffer=<*>} to /<*>; closing connection`
	============ Aggregate ====================
	Aggregated Template:  Error sending result <*> buffer=<*>} to /<*>; closing connection
[UpdateBucket] Logs: This iter found: 22, total: 16073992/16075117, remain: 1125. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 70 -> 48, remain buckets: 41
Update Success: Time for one update logs: 0.010502815246582031, template `Error sending result <*> buffer=<*>} to /<*>; closing connection`
========================================================================================


Iteration 201
Sample 3 from current logs bucket: ID: 8, Len: 2, Bucket Size: 64, Total Buckets: 239
	============  Query  ====================
	Log[1]: `BlockManagerMaster stopped`
	============ Response ====================
LogTemplate[1]: `BlockManagerMaster stopped`
	============ PostProcess ====================
	Post Template: `BlockManagerMaster stopped`
	============ Aggregate ====================
	Aggregated Template:  BlockManagerMaster stopped
[UpdateBucket] Logs: This iter found: 64, total: 16074056/16075117, remain: 1061. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 192 -> 128, remain buckets: 40
[TemplateDB] Try Merge: `BlockManagerMaster stopped` | `BlockManager stopped`
[TemplateDB] Reject Merge, Remain Template: `BlockManagerMaster stopped`
Update Success: Time for one update logs: 0.01731705665588379, template `BlockManagerMaster stopped`
========================================================================================


Iteration 202
Sample 1 from current logs bucket: ID: 9, Len: 2, Bucket Size: 64, Total Buckets: 239
	============  Query  ====================
	Log[1]: `OutputCommitCoordinator stopped!`
	============ Response ====================
LogTemplate[1]: `OutputCommitCoordinator stopped!`
	============ PostProcess ====================
	Post Template: `OutputCommitCoordinator stopped!`
	============ Aggregate ====================
	Aggregated Template:  OutputCommitCoordinator stopped!
[UpdateBucket] Logs: This iter found: 64, total: 16074120/16075117, remain: 997. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 128 -> 64, remain buckets: 39
[TemplateDB] Try Merge: `OutputCommitCoordinator stopped!` | `MapOutputTrackerMasterEndpoint stopped!`
[TemplateDB] Reject Merge, Remain Template: `OutputCommitCoordinator stopped!`
Update Success: Time for one update logs: 0.01885700225830078, template `OutputCommitCoordinator stopped!`
========================================================================================


Iteration 203
Sample 1 from current logs bucket: ID: 11, Len: 2, Bucket Size: 64, Total Buckets: 239
Sampling from 59 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204381_2463557`, MaxSim Log: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204399_2463575`.
	============  Query  ====================
	Log[1]: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204381_2463557`
	============ Response ====================
LogTemplate[1] Abandoning {bp_id}:{blk_id}
	============ PostProcess ====================
	Post Template: `Abandoning BP-<*>:blk_1076204381_2463557`
	============ Aggregate ====================
	Aggregated Template:  Abandoning BP-<*>:blk_1076204381_2463557
[UpdateBucket] Logs: This iter found: 1, total: 16074121/16075117, remain: 996. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 64 -> 63, remain buckets: 39
Update Success: Time for one update logs: 0.01834392547607422, template `Abandoning BP-<*>:blk_1076204381_2463557`
========================================================================================


Iteration 204
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 64, Total Buckets: 239
Sampling from 13 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Reporting 1066 blocks to the master.`, MaxSim Log: `Reporting 1068 blocks to the master.`.
	============  Query  ====================
	Log[1]: `Reporting 1066 blocks to the master.`
	Log[2]: `Reporting 1068 blocks to the master.`
	Log[3]: `Reporting 1064 blocks to the master.`
	============ Response ====================
LogTemplate[1]: `Reporting {blocks} blocks to the master.`  
LogTemplate[2]: `Reporting {blocks} blocks to the master.`  
LogTemplate[3]: `Reporting {blocks} blocks to the master.`  
	============ PostProcess ====================
	Post Template: `Reporting <*> blocks to the master.`
	Post Template: `Reporting <*> blocks to the master.`
	Post Template: `Reporting <*> blocks to the master.`
	============ Aggregate ====================
	Aggregated Template:  Reporting <*> blocks to the master.
[UpdateBucket] Logs: This iter found: 6, total: 16074127/16075117, remain: 990. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 145 -> 139, remain buckets: 39
Update Success: Time for one update logs: 0.014733076095581055, template `Reporting <*> blocks to the master.`
========================================================================================


Iteration 205
Sample 3 from current logs bucket: ID: 11, Len: 2, Bucket Size: 63, Total Buckets: 239
Sampling from 58 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204399_2463575`, MaxSim Log: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204423_2463599`.
	============  Query  ====================
	Log[1]: `Abandoning BP-108841162-10.10.34.11-1440074360971:blk_1076204399_2463575`
	============ Response ====================
LogTemplate[1] Abandoning BP-<*>:<*>{blk_id}
	============ PostProcess ====================
	Post Template: `Abandoning BP-<*>:blk_1076204399_2463575`
	============ Aggregate ====================
	Aggregated Template:  Abandoning BP-<*>:blk_1076204399_2463575
[UpdateBucket] Logs: This iter found: 1, total: 16074128/16075117, remain: 989. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 63 -> 62, remain buckets: 39
[TemplateDB] Try Merge: `Abandoning BP-<*>:blk_1076204399_2463575` | `Abandoning BP-<*>:blk_1076204381_2463557`
	Post Template: `Abandoning BP-<*>`
[TemplateDB] Merged: -> `Abandoning BP-<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2/2, in child Bucket [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
[UpdateBucket] Logs: This iter found: 58, total: 16074186/16075117, remain: 931. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 62 -> 4, remain buckets: 39
[TemplateDB] Update Indexes: 2 -> 60 for `Abandoning BP-<*>`
[TemplateBaseUpdate] Match unparsed logs 58 with new template `Abandoning BP-<*>`
Update Success: Time for one update logs: 0.03553915023803711, template `Abandoning BP-<*>:blk_1076204399_2463575`
========================================================================================


Iteration 206
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 61, Total Buckets: 239
Sampling from 10 logs, Sim Level: 1, MaxSim to anchor: 0.1111. Anchor: `Told to re-register on heartbeat`, MaxSim Log: `Requesting to kill executor(s) 8`.
	============  Query  ====================
	Log[1]: `Told to re-register on heartbeat`
	============ Response ====================
LogTemplate[1]: `Told to re-register on heartbeat`
	============ PostProcess ====================
	Post Template: `Told to re-register on heartbeat`
	============ Aggregate ====================
	Aggregated Template:  Told to re-register on heartbeat
[UpdateBucket] Logs: This iter found: 1, total: 16074187/16075117, remain: 930. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 119 -> 118, remain buckets: 39
Update Success: Time for one update logs: 0.019404172897338867, template `Told to re-register on heartbeat`
========================================================================================


Iteration 207
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 60, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Interrupted while trying for connection`
	============ Response ====================
LogTemplate[1]: `Interrupted while trying for connection`
	============ PostProcess ====================
	Post Template: `Interrupted while trying for connection`
	============ Aggregate ====================
	Aggregated Template:  Interrupted while trying for connection
[UpdateBucket] Logs: This iter found: 1, total: 16074188/16075117, remain: 929. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 118 -> 117, remain buckets: 39
Update Success: Time for one update logs: 0.020135164260864258, template `Interrupted while trying for connection`
========================================================================================


Iteration 208
Sample 1 from current logs bucket: ID: 132, Len: 5, Bucket Size: 59, Total Buckets: 239
Sampling from 9 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Requesting to kill executor(s) 8`, MaxSim Log: `Requesting to kill executor(s) 1`.
	============  Query  ====================
	Log[1]: `Requesting to kill executor(s) 8`
	Log[2]: `Requesting to kill executor(s) 13`
	Log[3]: `Requesting to kill executor(s) 4`
	============ Response ====================
LogTemplate[1]: `Requesting to kill executor(s) {executor_id}`  
LogTemplate[2]: `Requesting to kill executor(s) {executor_id}`  
LogTemplate[3]: `Requesting to kill executor(s) {executor_id}`  
	============ PostProcess ====================
	Post Template: `Requesting to kill executor(s) <*>`
	Post Template: `Requesting to kill executor(s) <*>`
	Post Template: `Requesting to kill executor(s) <*>`
	============ Aggregate ====================
	Aggregated Template:  Requesting to kill executor(s) <*>
[UpdateBucket] Logs: This iter found: 24, total: 16074212/16075117, remain: 905. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 117 -> 93, remain buckets: 39
Update Success: Time for one update logs: 0.01804208755493164, template `Requesting to kill executor(s) <*>`
========================================================================================


Iteration 209
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 58, Total Buckets: 239
Sampling from 12 logs failed
	============  Query  ====================
	Log[1]: `Error occurred while fetching local blocks`
	============ Response ====================
LogTemplate[1]: `Error occurred while fetching local blocks`
	============ PostProcess ====================
	Post Template: `Error occurred while fetching local blocks`
	============ Aggregate ====================
	Aggregated Template:  Error occurred while fetching local blocks
[UpdateBucket] Logs: This iter found: 7, total: 16074219/16075117, remain: 898. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 139 -> 132, remain buckets: 39
Update Success: Time for one update logs: 0.009473085403442383, template `Error occurred while fetching local blocks`
========================================================================================


Iteration 210
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 51, Total Buckets: 239
Sampling from 11 logs failed
	============  Query  ====================
	Log[1]: `Issue communicating with driver in heartbeater`
	============ Response ====================
LogTemplate[1]: `Issue communicating with driver in heartbeater`
	============ PostProcess ====================
	Post Template: `Issue communicating with driver in heartbeater`
	============ Aggregate ====================
	Aggregated Template:  Issue communicating with driver in heartbeater
[UpdateBucket] Logs: This iter found: 27, total: 16074246/16075117, remain: 871. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 132 -> 105, remain buckets: 39
Update Success: Time for one update logs: 0.01944589614868164, template `Issue communicating with driver in heartbeater`
========================================================================================


Iteration 211
Sample 3 from current logs bucket: ID: 176, Len: 9, Bucket Size: 51, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Error sending message [message = RetrieveSparkProps] in 1 attempts`, MaxSim Log: `Error sending message [message = RetrieveSparkProps] in 2 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = RetrieveSparkProps] in 1 attempts`
	Log[2]: `Error sending message [message = RetrieveSparkProps] in 2 attempts`
	Log[3]: `Error sending message [message = RetrieveSparkProps] in 3 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = {message}] in {attempts} attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = <*>] in <*> attempts`
	Post Template: `Error sending message [message = <*>] in <*> attempts`
	Post Template: `Error sending message [message = <*>] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = <*>] in <*> attempts
[UpdateBucket] Logs: This iter found: 51, total: 16074297/16075117, remain: 820. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 96 -> 45, remain buckets: 38
[TemplateDB] Try Merge: `Error sending message [message = <*>] in <*> attempts` | `Error sending message [message = GetLocations(<*>)] in <*> attempts`
	Post Template: `Error sending message [message = <*>] in <*> attempts`
[TemplateDB] Merged: -> `Error sending message [message = <*>] in <*> attempts`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 149/149, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
Update Success: Time for one update logs: 0.025738000869750977, template `Error sending message [message = <*>] in <*> attempts`
========================================================================================


Iteration 212
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 49, Total Buckets: 239
Sampling from 45 logs, Sim Level: 4, MaxSim to anchor: 0.5714. Anchor: `Error sending result RpcResponse{requestId=8054183328166237564, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=274 cap=274]}} to mesos-slave-05/10.10.34.15:34469; closing connection`, MaxSim Log: `Error sending result RpcResponse{requestId=6963534815674450023, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=307 cap=307]}} to mesos-slave-05/10.10.34.15:34469; closing connection`.
	============  Query  ====================
	Log[1]: `Error sending result RpcResponse{requestId=8054183328166237564, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=274 cap=274]}} to mesos-slave-05/10.10.34.15:34469; closing connection`
	Log[2]: `Error sending result RpcResponse{requestId=6963534815674450023, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=307 cap=307]}} to mesos-slave-05/10.10.34.15:34469; closing connection`
	============ Response ====================
LogTemplate[1]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=274 cap=274]}} to mesos-slave-05/{ip_or_url}; closing connection`  
LogTemplate[2]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=307 cap=307]}} to mesos-slave-05/{ip_or_url}; closing connection`  
	============ PostProcess ====================
	Post Template: `Error sending result <*>} to mesos-slave-05/<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-slave-05/<*>; closing connection`
	============ Aggregate ====================
	Aggregated Template:  Error sending result <*>} to mesos-slave-05/<*>; closing connection
[UpdateBucket] Logs: This iter found: 4, total: 16074301/16075117, remain: 816. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 49 -> 45, remain buckets: 38
Update Success: Time for one update logs: 0.017173051834106445, template `Error sending result <*>} to mesos-slave-05/<*>; closing connection`
========================================================================================


Iteration 213
Sample 3 from current logs bucket: ID: 168, Len: 8, Bucket Size: 48, Total Buckets: 239
Sampling from 47 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Failed to send RPC 8473052502767486838 to mesos-master-1/10.10.34.11:51096: java.nio.channels.ClosedChannelException`, MaxSim Log: `Failed to send RPC 8025844902466882010 to mesos-master-1/10.10.34.11:51096: java.nio.channels.ClosedChannelException`.
	============  Query  ====================
	Log[1]: `Failed to send RPC 8473052502767486838 to mesos-master-1/10.10.34.11:51096: java.nio.channels.ClosedChannelException`
	Log[2]: `Failed to send RPC 7405029226587737407 to mesos-master-3/10.10.34.13:41309: java.nio.channels.ClosedChannelException`
	Log[3]: `Failed to send RPC 8476040790958197306 to mesos-master-2/10.10.34.12:56239: java.nio.channels.ClosedChannelException`
	============ Response ====================
LogTemplate[1]: `Failed to send RPC {rpc_id} to {mesos_master}/{ip_port}: java.nio.channels.ClosedChannelException`
LogTemplate[2]: `Failed to send RPC {rpc_id} to {mesos_master}/{ip_port}: java.nio.channels.ClosedChannelException`
LogTemplate[3]: `Failed to send RPC {rpc_id} to {mesos_master}/{ip_port}: java.nio.channels.ClosedChannelException`
	============ PostProcess ====================
	Post Template: `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
	Post Template: `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
	Post Template: `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
	============ Aggregate ====================
	Aggregated Template:  Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException
[UpdateBucket] Logs: This iter found: 48, total: 16074349/16075117, remain: 768. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 78 -> 30, remain buckets: 37
[TemplateDB] Try Merge: `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException` | `Failed to send RPC <*> to mesos-slave-<*>: java.nio.channels.ClosedChannelException`
	Post Template: `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
[TemplateDB] Merged: -> `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 126/126, in child Bucket [165, 166, 167, 168, 169, 170]
Update Success: Time for one update logs: 0.01424407958984375, template `Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException`
========================================================================================


Iteration 214
Sample 3 from current logs bucket: ID: 199, Len: 12, Bucket Size: 48, Total Buckets: 239
Sampling from 47 logs, Sim Level: 5, MaxSim to anchor: 0.7143. Anchor: `Lost executor 8 on mesos-slave-05: Executor heartbeat timed out after 167979 ms`, MaxSim Log: `Lost executor 4 on mesos-slave-05: Executor heartbeat timed out after 143711 ms`.
	============  Query  ====================
	Log[1]: `Lost executor 8 on mesos-slave-05: Executor heartbeat timed out after 167979 ms`
	Log[2]: `Lost executor 4 on mesos-slave-26: Executor heartbeat timed out after 142872 ms`
	Log[3]: `Lost executor 12 on mesos-master-1: Executor heartbeat timed out after 125162 ms`
	============ Response ====================
LogTemplate[1]: `Lost executor {executor_id} on {host}: Executor heartbeat timed out after {timeout} ms`
LogTemplate[2]: `Lost executor {executor_id} on {host}: Executor heartbeat timed out after {timeout} ms`
LogTemplate[3]: `Lost executor {executor_id} on {host}: Executor heartbeat timed out after {timeout} ms`
	============ PostProcess ====================
	Post Template: `Lost executor <*> on <*>: Executor heartbeat timed out after <*> ms`
	Post Template: `Lost executor <*> on <*>: Executor heartbeat timed out after <*> ms`
	Post Template: `Lost executor <*> on <*>: Executor heartbeat timed out after <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Lost executor <*> on <*>: Executor heartbeat timed out after <*> ms
[UpdateBucket] Logs: This iter found: 24, total: 16074373/16075117, remain: 744. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 48 -> 24, remain buckets: 37
Update Success: Time for one update logs: 0.0061359405517578125, template `Lost executor <*> on <*>: Executor heartbeat timed out after <*> ms`
========================================================================================


Iteration 215
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 46, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Driver terminated or disconnected! Shutting down. 10.10.34.11:51096`, MaxSim Log: `Driver terminated or disconnected! Shutting down. 10.10.34.11:45410`.
	============  Query  ====================
	Log[1]: `Driver terminated or disconnected! Shutting down. 10.10.34.11:51096`
	Log[2]: `Driver terminated or disconnected! Shutting down. 10.10.34.11:45410`
	============ Response ====================
LogTemplate[1]: `Driver terminated or disconnected! Shutting down. {ip_or_port}`

LogTemplate[2]: `Driver terminated or disconnected! Shutting down. {ip_or_port}`
	============ PostProcess ====================
	Post Template: `Driver terminated or disconnected! Shutting down. <*>`
	Post Template: `Driver terminated or disconnected! Shutting down. <*>`
	============ Aggregate ====================
	Aggregated Template:  Driver terminated or disconnected! Shutting down. <*>
[UpdateBucket] Logs: This iter found: 2, total: 16074375/16075117, remain: 742. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 46 -> 44, remain buckets: 37
[TemplateDB] Try Merge: `Driver terminated or disconnected! Shutting down. <*>` | `Driver terminated or disconnected! Shutting down. mesos-master-<*>`
	Post Template: `Driver terminated or disconnected! Shutting down. <*>`
[TemplateDB] Merged: -> `Driver terminated or disconnected! Shutting down. <*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 78/78, in child Bucket [146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]
Update Success: Time for one update logs: 0.039134979248046875, template `Driver terminated or disconnected! Shutting down. <*>`
========================================================================================


Iteration 216
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 45, Total Buckets: 239
Sampling from 12 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `ResultStage 8 (count at pnmf_dblp.py:425) failed in 96.238 s`, MaxSim Log: `ResultStage 8 (count at pnmf_dblp.py:425) failed in 45.945 s`.
	============  Query  ====================
	Log[1]: `ResultStage 8 (count at pnmf_dblp.py:425) failed in 96.238 s`
	Log[2]: `ResultStage 8 (count at pnmf_dblp.py:425) failed in 80.005 s`
	Log[3]: `ResultStage 8 (count at pnmf_dblp.py:425) failed in 54.519 s`
	============ Response ====================
LogTemplate[1]: `ResultStage <{stage_num}> (count at {file_path}) failed in {duration} s`
	============ PostProcess ====================
	Post Template: `ResultStage <*> (count at <*>) failed in <*> s`
	Post Template: `ResultStage <*> (count at <*>) failed in <*> s`
	Post Template: `ResultStage <*> (count at <*>) failed in <*> s`
	============ Aggregate ====================
	Aggregated Template:  ResultStage <*> (count at <*>) failed in <*> s
[UpdateBucket] Logs: This iter found: 13, total: 16074388/16075117, remain: 729. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 45 -> 32, remain buckets: 37
[TemplateDB] Try Merge: `ResultStage <*> (count at <*>) failed in <*> s` | `ResultStage <*> (collect at <*>) failed in <*> s`
	Post Template: `ResultStage <*> (<*> at <*>) failed in <*> s`
[TemplateDB] Merged: -> `ResultStage <*> (<*> at <*>) failed in <*> s`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 39/39, in child Bucket [171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]
[UpdateBucket] Logs: This iter found: 0, total: 16074388/16075117, remain: 729. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 32 -> 32, remain buckets: 37
[TemplateDB] Update Indexes: 39 -> 39 for `ResultStage <*> (<*> at <*>) failed in <*> s`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `ResultStage <*> (<*> at <*>) failed in <*> s`
Update Success: Time for one update logs: 0.03617072105407715, template `ResultStage <*> (count at <*>) failed in <*> s`
========================================================================================


Iteration 217
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 45, Total Buckets: 239
Sampling from 41 logs, Sim Level: 4, MaxSim to anchor: 0.6923. Anchor: `Error sending result RpcResponse{requestId=8368974885283700037, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-10/10.10.34.20:43262; closing connection`, MaxSim Log: `Error sending result RpcResponse{requestId=4830902348053461854, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-10/10.10.34.20:51768; closing connection`.
	============  Query  ====================
	Log[1]: `Error sending result RpcResponse{requestId=8368974885283700037, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-10/10.10.34.20:43262; closing connection`
	Log[2]: `Error sending result RpcResponse{requestId=7448052572406148083, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-11/10.10.34.21:43114; closing connection`
	Log[3]: `Error sending result RpcResponse{requestId=4830902348053461854, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-10/10.10.34.20:51768; closing connection`
	============ Response ====================
LogTemplate[1]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-slave-<*>/<*>; closing connection`
	============ PostProcess ====================
	Post Template: `Error sending result <*>} to mesos-slave-<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-slave-<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-slave-<*>; closing connection`
	============ Aggregate ====================
	Aggregated Template:  Error sending result <*>} to mesos-slave-<*>; closing connection
[UpdateBucket] Logs: This iter found: 27, total: 16074415/16075117, remain: 702. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 45 -> 18, remain buckets: 37
[TemplateDB] Try Merge: `Error sending result <*>} to mesos-slave-<*>; closing connection` | `Error sending result <*>} to mesos-slave-05/<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-slave-<*>; closing connection`
[TemplateDB] Merged: -> `Error sending result <*>} to mesos-slave-<*>; closing connection`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 31/31, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
Update Success: Time for one update logs: 0.01795196533203125, template `Error sending result <*>} to mesos-slave-<*>; closing connection`
========================================================================================


Iteration 218
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 45, Total Buckets: 239
Sampling from 39 logs, Sim Level: 5, MaxSim to anchor: 0.1538. Anchor: `Lost task 0.0 in stage 5.0 (TID 8) on executor mesos-slave-21: java.lang.OutOfMemoryError (null) [duplicate 1]`, MaxSim Log: `Ignoring task-finished event for 0.0 in stage 3.0 because task 0 has already completed successfully`.
	============  Query  ====================
	Log[1]: `Lost task 0.0 in stage 5.0 (TID 8) on executor mesos-slave-21: java.lang.OutOfMemoryError (null) [duplicate 1]`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage} (TID {tid}) on executor {executor}: java.lang.OutOfMemoryError ({error_type}) [duplicate {duplicate_num}]`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*>) on executor <*>: java.lang.OutOfMemoryError (<*>) [duplicate <*>]`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*>) on executor <*>: java.lang.OutOfMemoryError (<*>) [duplicate <*>]
[UpdateBucket] Logs: This iter found: 1, total: 16074416/16075117, remain: 701. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 45 -> 44, remain buckets: 37
Update Success: Time for one update logs: 0.006017923355102539, template `Lost task <*> in stage <*> (TID <*>) on executor <*>: java.lang.OutOfMemoryError (<*>) [duplicate <*>]`
========================================================================================


Iteration 219
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 44, Total Buckets: 239
Sampling from 7 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-6b9f7dbf-6753-44ec-aef0-44a90e30f5bf`, MaxSim Log: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-2a4b09bf-53df-4934-b530-cf2931e85357`.
	============  Query  ====================
	Log[1]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1448006111297_0137/blockmgr-6b9f7dbf-6753-44ec-aef0-44a90e30f5bf`
	Log[2]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0076/blockmgr-5eefbe39-4165-4647-82c9-2b9bcb93625d`
	Log[3]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_1485248649253_0027/blockmgr-7dedbb8f-c971-49f9-bd46-5cf4c541eb5c`
	============ Response ====================
LogTemplate[1]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`

LogTemplate[2]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`

LogTemplate[3]: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	============ PostProcess ====================
	Post Template: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	Post Template: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	Post Template: `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	============ Aggregate ====================
	Aggregated Template:  Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>
[UpdateBucket] Logs: This iter found: 8, total: 16074424/16075117, remain: 693. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 44 -> 36, remain buckets: 37
Update Success: Time for one update logs: 0.026318788528442383, template `Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
========================================================================================


Iteration 220
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 44, Total Buckets: 239
Sampling from 41 logs, Sim Level: 7, MaxSim to anchor: 0.9333. Anchor: `Ignoring task-finished event for 3.0 in stage 3.0 because task 3 has already completed successfully`, MaxSim Log: `Ignoring task-finished event for 3.0 in stage 5.0 because task 3 has already completed successfully`.
	============  Query  ====================
	Log[1]: `Ignoring task-finished event for 3.0 in stage 3.0 because task 3 has already completed successfully`
	Log[2]: `Ignoring task-finished event for 1.0 in stage 3.0 because task 1 has already completed successfully`
	Log[3]: `Ignoring task-finished event for 0.0 in stage 5.1 because task 0 has already completed successfully`
	============ Response ====================
LogTemplate[1]: `Ignoring task-finished event for {number} in stage {number} because task {number} has already completed successfully`
LogTemplate[2]: `Ignoring task-finished event for {number} in stage {number} because task {number} has already completed successfully`
LogTemplate[3]: `Ignoring task-finished event for {number} in stage {number} because task {number} has already completed successfully`
	============ PostProcess ====================
	Post Template: `Ignoring task-finished event for <*> in stage <*> because task <*> has already completed successfully`
	Post Template: `Ignoring task-finished event for <*> in stage <*> because task <*> has already completed successfully`
	Post Template: `Ignoring task-finished event for <*> in stage <*> because task <*> has already completed successfully`
	============ Aggregate ====================
	Aggregated Template:  Ignoring task-finished event for <*> in stage <*> because task <*> has already completed successfully
[UpdateBucket] Logs: This iter found: 6, total: 16074430/16075117, remain: 687. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 44 -> 38, remain buckets: 37
Update Success: Time for one update logs: 0.009788990020751953, template `Ignoring task-finished event for <*> in stage <*> because task <*> has already completed successfully`
========================================================================================


Iteration 221
Sample 3 from current logs bucket: ID: 187, Len: 10, Bucket Size: 43, Total Buckets: 239
Sampling from 21 logs, Sim Level: 3, MaxSim to anchor: 0.8182. Anchor: `Task 25 in stage 1.0 failed 4 times; aborting job`, MaxSim Log: `Task 8 in stage 1.0 failed 4 times; aborting job`.
	============  Query  ====================
	Log[1]: `Task 25 in stage 1.0 failed 4 times; aborting job`
	Log[2]: `Task 44 in stage 1.0 failed 4 times; aborting job`
	Log[3]: `Task 28 in stage 2.0 failed 4 times; aborting job`
	============ Response ====================
LogTemplate[1]: `Task {task_id} in stage {stage_id} failed 4 times; aborting job`
	============ PostProcess ====================
	Post Template: `Task <*> in stage <*> failed <*> times; aborting job`
	Post Template: `Task <*> in stage <*> failed <*> times; aborting job`
	Post Template: `Task <*> in stage <*> failed <*> times; aborting job`
	============ Aggregate ====================
	Aggregated Template:  Task <*> in stage <*> failed <*> times; aborting job
[UpdateBucket] Logs: This iter found: 21, total: 16074451/16075117, remain: 666. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 43 -> 22, remain buckets: 37
Update Success: Time for one update logs: 0.012538909912109375, template `Task <*> in stage <*> failed <*> times; aborting job`
========================================================================================


Iteration 222
Sample 3 from current logs bucket: ID: 133, Len: 6, Bucket Size: 42, Total Buckets: 239
Sampling from 41 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:44924]`, MaxSim Log: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@mesos-slave-30:45653]`.
	============  Query  ====================
	Log[1]: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:44924]`
	Log[2]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@mesos-slave-30:59360]`
	Log[3]: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:40045]`
	============ Response ====================
LogTemplate[1]: `Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-30:<port>]`
	============ PostProcess ====================
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-<*>:<port>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-<*>:<port>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-<*>:<port>]`
	============ Aggregate ====================
	Aggregated Template:  Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-<*>:<port>]
[UpdateBucket] Logs: This iter found: 0, total: 16074451/16075117, remain: 666. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 105 -> 105, remain buckets: 37
Update failed: Template can not match logs `Remoting started; listening on addresses :[akka.tcp://<service>@mesos-slave-<*>:<port>]`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 133, Len: 6, Bucket Size: 42, Total Buckets: 239
Sampling from 41 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:44924]`, MaxSim Log: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@mesos-slave-30:45653]`.
	============  Query  ====================
	Log[1]: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:44924]`
	Log[2]: `Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@mesos-slave-30:38752]`
	Log[3]: `Remoting started; listening on addresses :[akka.tcp://sparkExecutor@mesos-slave-30:33003]`
	============ Response ====================
LogTemplate[1]: `Remoting started; listening on addresses :[akka.tcp://{actor}@mesos-slave-30:{port}]`
	============ PostProcess ====================
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]`
	============ Aggregate ====================
	Aggregated Template:  Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]
[UpdateBucket] Logs: This iter found: 42, total: 16074493/16075117, remain: 624. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 105 -> 63, remain buckets: 36
[TemplateDB] Try Merge: `Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]` | `Remoting started; listening on addresses :[akka.tcp://spark<*>rActorSystem@<*>]`
	Post Template: `Remoting started; listening on addresses :[akka.tcp://<*>]`
[TemplateDB] Merged: -> `Remoting started; listening on addresses :[akka.tcp://<*>]`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2378/2378, in child Bucket [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]
[UpdateBucket] Logs: This iter found: 0, total: 16074493/16075117, remain: 624. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 63 -> 63, remain buckets: 36
[TemplateDB] Update Indexes: 2378 -> 2378 for `Remoting started; listening on addresses :[akka.tcp://<*>]`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Remoting started; listening on addresses :[akka.tcp://<*>]`
Update Success: Time for one update logs: 0.07840418815612793, template `Remoting started; listening on addresses :[akka.tcp://<*>@mesos-slave-<*>]`
========================================================================================


Iteration 223
Sample 3 from current logs bucket: ID: 140, Len: 6, Bucket Size: 39, Total Buckets: 239
Sampling from 37 logs, Sim Level: 2, MaxSim to anchor: 0.5000. Anchor: `Removing block manager BlockManagerId(5, mesos-master-2, 56213)`, MaxSim Log: `Removing block manager BlockManagerId(6, mesos-master-2, 36003)`.
	============  Query  ====================
	Log[1]: `Removing block manager BlockManagerId(5, mesos-master-2, 56213)`
	Log[2]: `Removing block manager BlockManagerId(7, mesos-master-2, 42517)`
	Log[3]: `Removing block manager BlockManagerId(8, mesos-master-2, 49207)`
	============ Response ====================
LogTemplate[1]: `Removing block manager BlockManagerId(<*>, mesos-master-2, <*>)`  
LogTemplate[2]: `Removing block manager BlockManagerId(<*>, mesos-master-2, <*>)`  
LogTemplate[3]: `Removing block manager BlockManagerId(<*>, mesos-master-2, <*>)`  
	============ PostProcess ====================
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)`
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)`
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)`
	============ Aggregate ====================
	Aggregated Template:  Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)
[UpdateBucket] Logs: This iter found: 39, total: 16074532/16075117, remain: 585. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 63 -> 24, remain buckets: 35
[TemplateDB] Try Merge: `Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)` | `Removing block manager BlockManagerId(<*>, mesos-slave-<*>, <*>)`
	Post Template: `Removing block manager BlockManagerId(<*>, mesos-<*>, <*>)`
[TemplateDB] Merged: -> `Removing block manager BlockManagerId(<*>, mesos-<*>, <*>)`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 324/324, in child Bucket [133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]
[UpdateBucket] Logs: This iter found: 0, total: 16074532/16075117, remain: 585. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 24 -> 24, remain buckets: 35
[TemplateDB] Update Indexes: 324 -> 324 for `Removing block manager BlockManagerId(<*>, mesos-<*>, <*>)`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Removing block manager BlockManagerId(<*>, mesos-<*>, <*>)`
Update Success: Time for one update logs: 0.028216123580932617, template `Removing block manager BlockManagerId(<*>, mesos-master-<*>, <*>)`
========================================================================================


Iteration 224
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 38, Total Buckets: 239
Sampling from 36 logs, Sim Level: 4, MaxSim to anchor: 0.7647. Anchor: `Resubmitting ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 0, 1`, MaxSim Log: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 1, 2`.
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 0, 1`
	Log[2]: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 1, 3`
	Log[3]: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 1, 2`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) because some of its tasks had failed: {task_list}`

LogTemplate[2]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) because some of its tasks had failed: {task_list}`

LogTemplate[3]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) because some of its tasks had failed: {task_list}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 3, total: 16074535/16075117, remain: 582. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 38 -> 35, remain buckets: 35
Update Success: Time for one update logs: 0.003384113311767578, template `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 225
Sample 3 from current logs bucket: ID: 126, Len: 5, Bucket Size: 37, Total Buckets: 239
Sampling from 22 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Exception in connection from mesos-master-1/10.10.34.11:60970`, MaxSim Log: `Exception in connection from mesos-master-2/10.10.34.12:36003`.
	============  Query  ====================
	Log[1]: `Exception in connection from mesos-master-1/10.10.34.11:60970`
	Log[2]: `Exception in connection from mesos-master-3/10.10.34.13:41763`
	Log[3]: `Exception in connection from /10.10.34.27:58087`
	============ Response ====================
LogTemplate[1]: `Exception in connection from {server}/{ip_or_port}`  
LogTemplate[2]: `Exception in connection from {server}/{ip_or_port}`  
LogTemplate[3]: `Exception in connection from {ip_or_port}`  
	============ PostProcess ====================
	Post Template: `Exception in connection from <*>`
	Post Template: `Exception in connection from <*>`
	Post Template: `Exception in connection from <*>`
	============ Aggregate ====================
	Aggregated Template:  Exception in connection from <*>
[UpdateBucket] Logs: This iter found: 37, total: 16074572/16075117, remain: 545. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 93 -> 56, remain buckets: 34
[TemplateDB] Try Merge: `Exception in connection from <*>` | `Exception in connection from mesos-slave-<*>`
	Post Template: `Exception in connection from <*>`
[TemplateDB] Merged: -> `Exception in connection from <*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 190/190, in child Bucket [119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]
Update Success: Time for one update logs: 0.03138113021850586, template `Exception in connection from <*>`
========================================================================================


Iteration 226
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 36, Total Buckets: 239
Sampling from 3 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Got told to re-register updating block broadcast_16_piece0`, MaxSim Log: `Got told to re-register updating block broadcast_11_piece0`.
	============  Query  ====================
	Log[1]: `Got told to re-register updating block broadcast_16_piece0`
	Log[2]: `Got told to re-register updating block broadcast_10_piece0`
	Log[3]: `Got told to re-register updating block broadcast_11_piece0`
	============ Response ====================
LogTemplate[1]: `Got told to re-register updating block broadcast_{block_id}_piece0`  
LogTemplate[2]: `Got told to re-register updating block broadcast_{block_id}_piece0`  
LogTemplate[3]: `Got told to re-register updating block broadcast_{block_id}_piece0`  
	============ PostProcess ====================
	Post Template: `Got told to re-register updating block <*>`
	Post Template: `Got told to re-register updating block <*>`
	Post Template: `Got told to re-register updating block <*>`
	============ Aggregate ====================
	Aggregated Template:  Got told to re-register updating block <*>
[UpdateBucket] Logs: This iter found: 5, total: 16074577/16075117, remain: 540. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 36 -> 31, remain buckets: 34
Update Success: Time for one update logs: 0.023914575576782227, template `Got told to re-register updating block <*>`
========================================================================================


Iteration 227
Sample 3 from current logs bucket: ID: 229, Len: 28, Bucket Size: 36, Total Buckets: 239
Sampling from 35 logs, Sim Level: 5, MaxSim to anchor: 0.8667. Anchor: `Lost task 30.0 in stage 1.0 (TID 32, mesos-slave-05): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 167979 ms`, MaxSim Log: `Lost task 6.0 in stage 1.0 (TID 8, mesos-slave-05): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 167979 ms`.
	============  Query  ====================
	Log[1]: `Lost task 30.0 in stage 1.0 (TID 32, mesos-slave-05): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 167979 ms`
	Log[2]: `Lost task 20.0 in stage 11.0 (TID 1595, mesos-master-1): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 125162 ms`
	Log[3]: `Lost task 0.0 in stage 3.0 (TID 10, mesos-slave-13): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 137299 ms`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {task_instance_id}, {executor_host}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Executor heartbeat timed out after {timeout_duration} ms`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Executor heartbeat timed out after <*> ms`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Executor heartbeat timed out after <*> ms`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Executor heartbeat timed out after <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Executor heartbeat timed out after <*> ms
[UpdateBucket] Logs: This iter found: 35, total: 16074612/16075117, remain: 505. 
[UpdateBucket] Buckets: Checked 1 ([229]), Parent Bucket size: 36 -> 1, remain buckets: 34
Update Success: Time for one update logs: 0.0062448978424072266, template `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Executor heartbeat timed out after <*> ms`
========================================================================================


Iteration 228
Sample 3 from current logs bucket: ID: 132, Len: 5, Bucket Size: 35, Total Buckets: 239
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.4286. Anchor: `waiting: Set(ShuffleMapStage 2, ResultStage 3)`, MaxSim Log: `waiting: Set(ShuffleMapStage 7, ResultStage 8)`.
	============  Query  ====================
	Log[1]: `waiting: Set(ShuffleMapStage 2, ResultStage 3)`
	============ Response ====================
LogTemplate[1]: `waiting: Set(<*>, <*>)`
	============ PostProcess ====================
	Post Template: `waiting: Set(<*>, <*>)`
	============ Aggregate ====================
	Aggregated Template:  waiting: Set(<*>, <*>)
[UpdateBucket] Logs: This iter found: 35, total: 16074647/16075117, remain: 470. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 56 -> 21, remain buckets: 33
Update Success: Time for one update logs: 0.021919965744018555, template `waiting: Set(<*>, <*>)`
========================================================================================


Iteration 229
Sample 3 from current logs bucket: ID: 204, Len: 13, Bucket Size: 35, Total Buckets: 239
Sampling from 9 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(21, mesos-slave-13, 57719),broadcast_5_piece323,StorageLevel(false, true, false, false, 1),4194304,0,0))`, MaxSim Log: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(19, mesos-slave-27, 34660),broadcast_4_piece119,StorageLevel(false, true, false, false, 1),4194304,0,0))`.
	============  Query  ====================
	Log[1]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(21, mesos-slave-13, 57719),broadcast_5_piece323,StorageLevel(false, true, false, false, 1),4194304,0,0))`
	Log[2]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(19, mesos-slave-27, 34660),broadcast_4_piece119,StorageLevel(false, true, false, false, 1),4194304,0,0))`
	Log[3]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(20, mesos-slave-25, 55339),rdd_27_9,StorageLevel(false, true, false, false, 1),26,0,0))`
	============ Response ====================
LogTemplate[1]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>))`  
LogTemplate[2]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>))`  
LogTemplate[3]: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>))`  
	============ PostProcess ====================
	Post Template: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))`
	Post Template: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))`
	Post Template: `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))`
	============ Aggregate ====================
	Aggregated Template:  SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))
[UpdateBucket] Logs: This iter found: 10, total: 16074657/16075117, remain: 460. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 35 -> 25, remain buckets: 33
Update Success: Time for one update logs: 0.01057291030883789, template `SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))`
========================================================================================


Iteration 230
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 35, Total Buckets: 239
Sampling from 34 logs failed
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.SparkException: Failed to connect to driver!)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: <*>, (reason: Uncaught exception: <*>)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <*>)
[UpdateBucket] Logs: This iter found: 1, total: 16074658/16075117, remain: 459. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 35 -> 34, remain buckets: 33
Update Success: Time for one update logs: 0.009202957153320312, template `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <*>)`
========================================================================================


Iteration 231
Sample 3 from current logs bucket: ID: 211, Len: 15, Bucket Size: 34, Total Buckets: 239
Sampling from 33 logs, Sim Level: 3, MaxSim to anchor: 0.5882. Anchor: `Error sending message [message = UpdateBlockInfo(BlockManagerId(4, mesos-slave-13, 40185),broadcast_114_piece0,StorageLevel(false, false, false, false, 1),0,0,0)] in 1 attempts`, MaxSim Log: `Error sending message [message = UpdateBlockInfo(BlockManagerId(10, mesos-slave-13, 60845),rdd_27_70,StorageLevel(false, true, false, false, 1),117473855,0,0)] in 1 attempts`.
	============  Query  ====================
	Log[1]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(4, mesos-slave-13, 40185),broadcast_114_piece0,StorageLevel(false, false, false, false, 1),0,0,0)] in 1 attempts`
	Log[2]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(20, mesos-slave-25, 55339),rdd_27_6,StorageLevel(false, true, false, false, 1),26,0,0)] in 1 attempts`
	Log[3]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(10, mesos-slave-13, 60845),rdd_27_70,StorageLevel(false, true, false, false, 1),117473855,0,0)] in 1 attempts`
	============ Response ====================
LogTemplate[1]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>)] in 1 attempts`
LogTemplate[2]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>)] in 1 attempts`
LogTemplate[3]: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*>, <*>),<*>,StorageLevel(<*>, <*>, <*>, <*>, <*>),<*>,<*>,<*>)] in 1 attempts`
	============ PostProcess ====================
	Post Template: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts`
	Post Template: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts`
	Post Template: `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts`
	============ Aggregate ====================
	Aggregated Template:  Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts
[UpdateBucket] Logs: This iter found: 34, total: 16074692/16075117, remain: 425. 
[UpdateBucket] Buckets: Checked 2 ([210, 211]), Parent Bucket size: 34 -> 0, remain buckets: 32
Update Success: Time for one update logs: 0.009373188018798828, template `Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts`
========================================================================================


Iteration 232
Sample 3 from current logs bucket: ID: 212, Len: 16, Bucket Size: 33, Total Buckets: 239
Sampling from 6 logs, Sim Level: 4, MaxSim to anchor: 0.7778. Anchor: `Lost task 1.0 in stage 5.0 (TID 9, mesos-slave-08): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`, MaxSim Log: `Lost task 1.0 in stage 3.0 (TID 9, mesos-master-2): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`.
	============  Query  ====================
	Log[1]: `Lost task 1.0 in stage 5.0 (TID 9, mesos-slave-08): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	Log[2]: `Lost task 1.0 in stage 3.0 (TID 9, mesos-master-2): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	Log[3]: `Lost task 0.0 in stage 3.0 (TID 8, mesos-slave-06): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, {node}): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): java.lang.OutOfMemoryError: Requested array size exceeds VM limit
[UpdateBucket] Logs: This iter found: 3, total: 16074695/16075117, remain: 422. 
[UpdateBucket] Buckets: Checked 1 ([212]), Parent Bucket size: 33 -> 30, remain buckets: 32
Update Success: Time for one update logs: 0.0053670406341552734, template `Lost task <*> in stage <*> (TID <*> <*>): java.lang.OutOfMemoryError: Requested array size exceeds VM limit`
========================================================================================


Iteration 233
Sample 3 from current logs bucket: ID: 181, Len: 9, Bucket Size: 32, Total Buckets: 239
Sampling from 24 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Resubmitted ShuffleMapTask(11, 1), so marking it as still running`, MaxSim Log: `Resubmitted ShuffleMapTask(11, 21), so marking it as still running`.
	============  Query  ====================
	Log[1]: `Resubmitted ShuffleMapTask(11, 1), so marking it as still running`
	Log[2]: `Resubmitted ShuffleMapTask(11, 50), so marking it as still running`
	Log[3]: `Resubmitted ShuffleMapTask(11, 90), so marking it as still running`
	============ Response ====================
LogTemplate[1]: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
LogTemplate[2]: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
LogTemplate[3]: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
	============ PostProcess ====================
	Post Template: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
	Post Template: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
	Post Template: `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
	============ Aggregate ====================
	Aggregated Template:  Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running
[UpdateBucket] Logs: This iter found: 32, total: 16074727/16075117, remain: 390. 
[UpdateBucket] Buckets: Checked 11 ([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181]), Parent Bucket size: 32 -> 0, remain buckets: 31
Update Success: Time for one update logs: 0.014026880264282227, template `Resubmitted ShuffleMapTask(<*>, <*>), so marking it as still running`
========================================================================================


Iteration 234
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 31, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Ignored failure: java.io.IOException: Connection from mesos-master-1/10.10.34.11:34641 closed`, MaxSim Log: `Ignored failure: java.io.IOException: Connection from mesos-master-1/10.10.34.11:47966 closed`.
	============  Query  ====================
	Log[1]: `Ignored failure: java.io.IOException: Connection from mesos-master-1/10.10.34.11:34641 closed`
	Log[2]: `Ignored failure: java.io.IOException: Connection from mesos-master-1/10.10.34.11:33750 closed`
	Log[3]: `Ignored failure: java.io.IOException: Connection from mesos-master-1/10.10.34.11:47966 closed`
	============ Response ====================
LogTemplate[1]: `Ignored failure: java.io.IOException: Connection from mesos-master-1/{ip_or_url} closed`
	============ PostProcess ====================
	Post Template: `Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed`
	Post Template: `Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed`
	Post Template: `Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed`
	============ Aggregate ====================
	Aggregated Template:  Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed
[UpdateBucket] Logs: This iter found: 15, total: 16074742/16075117, remain: 375. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 31 -> 16, remain buckets: 31
Update Success: Time for one update logs: 0.019484758377075195, template `Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed`
========================================================================================


Iteration 235
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 30, Total Buckets: 239
Sampling from 17 logs, Sim Level: 3, MaxSim to anchor: 0.7778. Anchor: `Uncaught exception in thread Thread[Executor task launch worker-1,5,main]`, MaxSim Log: `Uncaught exception in thread Thread[Executor task launch worker-0,5,main]`.
	============  Query  ====================
	Log[1]: `Uncaught exception in thread Thread[Executor task launch worker-1,5,main]`
	Log[2]: `Uncaught exception in thread Thread[Executor task launch worker-0,5,main]`
	============ Response ====================
LogTemplate[1]: `Uncaught exception in thread Thread[Executor task launch worker-{worker_id},5,main]`
LogTemplate[2]: `Uncaught exception in thread Thread[Executor task launch worker-{worker_id},5,main]`
	============ PostProcess ====================
	Post Template: `Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
	Post Template: `Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
	============ Aggregate ====================
	Aggregated Template:  Uncaught exception in thread Thread[Executor task launch worker-<*>,main]
[UpdateBucket] Logs: This iter found: 7, total: 16074749/16075117, remain: 368. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 30 -> 23, remain buckets: 31
Update Success: Time for one update logs: 0.009768962860107422, template `Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
========================================================================================


Iteration 236
Sample 3 from current logs bucket: ID: 212, Len: 16, Bucket Size: 30, Total Buckets: 239
Sampling from 2 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) and ResultStage 5 (collect at pnmf4.py:377) due to fetch failure`, MaxSim Log: `Resubmitting ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) and ResultStage 3 (collect at pnmf4.py:376) due to fetch failure`.
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) and ResultStage 5 (collect at pnmf4.py:377) due to fetch failure`
	Log[2]: `Resubmitting ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) and ResultStage 3 (collect at pnmf4.py:376) due to fetch failure`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) and ResultStage {result_stage_num} (collect at pnmf4.py:{result_stage_line_num}) due to fetch failure`
LogTemplate[2]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) and ResultStage {result_stage_num} (collect at pnmf4.py:{result_stage_line_num}) due to fetch failure`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) and ResultStage <*> (collect at pnmf4.py:<*>) due to fetch failure`
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) and ResultStage <*> (collect at pnmf4.py:<*>) due to fetch failure`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) and ResultStage <*> (collect at pnmf4.py:<*>) due to fetch failure
[UpdateBucket] Logs: This iter found: 25, total: 16074774/16075117, remain: 343. 
[UpdateBucket] Buckets: Checked 1 ([212]), Parent Bucket size: 30 -> 5, remain buckets: 31
Update Success: Time for one update logs: 0.009114265441894531, template `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) and ResultStage <*> (collect at pnmf4.py:<*>) due to fetch failure`
========================================================================================


Iteration 237
Sample 3 from current logs bucket: ID: 204, Len: 13, Bucket Size: 25, Total Buckets: 239
Sampling from 24 logs, Sim Level: 1, MaxSim to anchor: 0.0870. Anchor: `Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (4) reached)`, MaxSim Log: `Removing executor 8 with no recent heartbeats: 167979 ms exceeds timeout 120000 ms`.
	============  Query  ====================
	Log[1]: `Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (4) reached)`
	============ Response ====================
LogTemplate[1]: `Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (<*> reached)`
	============ PostProcess ====================
	Post Template: `Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (<*> reached)`
	============ Aggregate ====================
	Aggregated Template:  Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (<*> reached)
[UpdateBucket] Logs: This iter found: 1, total: 16074775/16075117, remain: 342. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 25 -> 24, remain buckets: 31
Update Success: Time for one update logs: 0.011039257049560547, template `Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (<*> reached)`
========================================================================================


Iteration 238
Sample 3 from current logs bucket: ID: 145, Len: 6, Bucket Size: 24, Total Buckets: 239
Sampling from 9 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Driver requested to kill executor(s) 8.`, MaxSim Log: `Driver requested to kill executor(s) 1.`.
	============  Query  ====================
	Log[1]: `Driver requested to kill executor(s) 8.`
	Log[2]: `Driver requested to kill executor(s) 2.`
	Log[3]: `Driver requested to kill executor(s) 12.`
	============ Response ====================
LogTemplate[1]: `Driver requested to kill executor(s) {executor_id}.`
	============ PostProcess ====================
	Post Template: `Driver requested to kill executor(s) <*>.`
	Post Template: `Driver requested to kill executor(s) <*>.`
	Post Template: `Driver requested to kill executor(s) <*>.`
	============ Aggregate ====================
	Aggregated Template:  Driver requested to kill executor(s) <*>.
[UpdateBucket] Logs: This iter found: 24, total: 16074799/16075117, remain: 318. 
[UpdateBucket] Buckets: Checked 13 ([133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145]), Parent Bucket size: 24 -> 0, remain buckets: 30
Update Success: Time for one update logs: 0.013797998428344727, template `Driver requested to kill executor(s) <*>.`
========================================================================================


Iteration 239
Sample 3 from current logs bucket: ID: 199, Len: 12, Bucket Size: 24, Total Buckets: 239
Sampling from 23 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Lost executor 8 on mesos-slave-05: Container container_1485248649253_0036_02_000014 exited from explicit termination request.`, MaxSim Log: `Lost executor 4 on mesos-slave-05: Container container_1485248649253_0071_02_000005 exited from explicit termination request.`.
	============  Query  ====================
	Log[1]: `Lost executor 8 on mesos-slave-05: Container container_1485248649253_0036_02_000014 exited from explicit termination request.`
	Log[2]: `Lost executor 3 on mesos-master-2: Container container_1485248649253_0068_02_000004 exited from explicit termination request.`
	Log[3]: `Lost executor 1 on mesos-slave-18: Container container_1485248649253_0071_01_000002 exited from explicit termination request.`
	============ Response ====================
LogTemplate[1]: `Lost executor <*> on {executor_host}: Container {container_id} exited from explicit termination request.`

LogTemplate[2]: `Lost executor <*> on {executor_host}: Container {container_id} exited from explicit termination request.`

LogTemplate[3]: `Lost executor <*> on {executor_host}: Container {container_id} exited from explicit termination request.`
	============ PostProcess ====================
	Post Template: `Lost executor <*> on <*>: Container <*> exited from explicit termination request.`
	Post Template: `Lost executor <*> on <*>: Container <*> exited from explicit termination request.`
	Post Template: `Lost executor <*> on <*>: Container <*> exited from explicit termination request.`
	============ Aggregate ====================
	Aggregated Template:  Lost executor <*> on <*>: Container <*> exited from explicit termination request.
[UpdateBucket] Logs: This iter found: 24, total: 16074823/16075117, remain: 294. 
[UpdateBucket] Buckets: Checked 4 ([196, 197, 198, 199]), Parent Bucket size: 24 -> 0, remain buckets: 29
Update Success: Time for one update logs: 0.01120901107788086, template `Lost executor <*> on <*>: Container <*> exited from explicit termination request.`
========================================================================================


Iteration 240
Sample 3 from current logs bucket: ID: 204, Len: 13, Bucket Size: 24, Total Buckets: 239
Sampling from 23 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Removing executor 8 with no recent heartbeats: 167979 ms exceeds timeout 120000 ms`, MaxSim Log: `Removing executor 1 with no recent heartbeats: 151886 ms exceeds timeout 120000 ms`.
	============  Query  ====================
	Log[1]: `Removing executor 8 with no recent heartbeats: 167979 ms exceeds timeout 120000 ms`
	Log[2]: `Removing executor 13 with no recent heartbeats: 155376 ms exceeds timeout 120000 ms`
	Log[3]: `Removing executor 1 with no recent heartbeats: 165602 ms exceeds timeout 120000 ms`
	============ Response ====================
LogTemplate[1]: `Removing executor {executor_id} with no recent heartbeats: {heartbeat_duration} ms exceeds timeout 120000 ms`
	============ PostProcess ====================
	Post Template: `Removing executor <*> with no recent heartbeats: <*> ms exceeds timeout <*> ms`
	Post Template: `Removing executor <*> with no recent heartbeats: <*> ms exceeds timeout <*> ms`
	Post Template: `Removing executor <*> with no recent heartbeats: <*> ms exceeds timeout <*> ms`
	============ Aggregate ====================
	Aggregated Template:  Removing executor <*> with no recent heartbeats: <*> ms exceeds timeout <*> ms
[UpdateBucket] Logs: This iter found: 24, total: 16074847/16075117, remain: 270. 
[UpdateBucket] Buckets: Checked 5 ([200, 201, 202, 203, 204]), Parent Bucket size: 24 -> 0, remain buckets: 28
Update Success: Time for one update logs: 0.006899118423461914, template `Removing executor <*> with no recent heartbeats: <*> ms exceeds timeout <*> ms`
========================================================================================


Iteration 241
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 23, Total Buckets: 239
Sampling from 15 logs, Sim Level: 1, MaxSim to anchor: 0.0667. Anchor: `Reporter thread fails 1 time(s) in a row.`, MaxSim Log: `Host added was in lost list earlier: mesos-slave-10`.
	============  Query  ====================
	Log[1]: `Reporter thread fails 1 time(s) in a row.`
	============ Response ====================
LogTemplate[1]: `Reporter thread fails {number} time(s) in a row.`
	============ PostProcess ====================
	Post Template: `Reporter thread fails <*> time(s) in a row.`
	============ Aggregate ====================
	Aggregated Template:  Reporter thread fails <*> time(s) in a row.
[UpdateBucket] Logs: This iter found: 1, total: 16074848/16075117, remain: 269. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 23 -> 22, remain buckets: 28
Update Success: Time for one update logs: 0.011561393737792969, template `Reporter thread fails <*> time(s) in a row.`
========================================================================================


Iteration 242
Sample 3 from current logs bucket: ID: 219, Len: 19, Bucket Size: 23, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Marking ResultStage 5 (collect at pnmf4.py:377) as failed due to a fetch failure from ShuffleMapStage 4 (reduceByKey at pnmf4.py:371)`, MaxSim Log: `Marking ResultStage 3 (collect at pnmf4.py:376) as failed due to a fetch failure from ShuffleMapStage 2 (reduceByKey at pnmf4.py:371)`.
	============  Query  ====================
	Log[1]: `Marking ResultStage 5 (collect at pnmf4.py:377) as failed due to a fetch failure from ShuffleMapStage 4 (reduceByKey at pnmf4.py:371)`
	Log[2]: `Marking ResultStage 3 (collect at pnmf4.py:376) as failed due to a fetch failure from ShuffleMapStage 2 (reduceByKey at pnmf4.py:371)`
	============ Response ====================
LogTemplate[1]: `Marking ResultStage {stage_num} (collect at {file}:{line_num}) as failed due to a fetch failure from ShuffleMapStage {shuffle_num} (reduceByKey at {file}:{line_num})`

LogTemplate[2]: `Marking ResultStage {stage_num} (collect at {file}:{line_num}) as failed due to a fetch failure from ShuffleMapStage {shuffle_num} (reduceByKey at {file}:{line_num})`
	============ PostProcess ====================
	Post Template: `Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (reduceByKey at <*>)`
	Post Template: `Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (reduceByKey at <*>)`
	============ Aggregate ====================
	Aggregated Template:  Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (reduceByKey at <*>)
[UpdateBucket] Logs: This iter found: 23, total: 16074871/16075117, remain: 246. 
[UpdateBucket] Buckets: Checked 3 ([217, 218, 219]), Parent Bucket size: 23 -> 0, remain buckets: 27
Update Success: Time for one update logs: 0.008586883544921875, template `Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (reduceByKey at <*>)`
========================================================================================


Iteration 243
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 22, Total Buckets: 239
Sampling from 14 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Host added was in lost list earlier: mesos-slave-10`, MaxSim Log: `Host added was in lost list earlier: mesos-slave-26`.
	============  Query  ====================
	Log[1]: `Host added was in lost list earlier: mesos-slave-10`
	Log[2]: `Host added was in lost list earlier: mesos-slave-25`
	Log[3]: `Host added was in lost list earlier: mesos-slave-26`
	============ Response ====================
LogTemplate[1]: `Host added was in lost list earlier: mesos-slave-{number}`
	============ PostProcess ====================
	Post Template: `Host added was in lost list earlier: mesos-slave-<*>`
	Post Template: `Host added was in lost list earlier: mesos-slave-<*>`
	Post Template: `Host added was in lost list earlier: mesos-slave-<*>`
	============ Aggregate ====================
	Aggregated Template:  Host added was in lost list earlier: mesos-slave-<*>
[UpdateBucket] Logs: This iter found: 18, total: 16074889/16075117, remain: 228. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 22 -> 4, remain buckets: 27
Update Success: Time for one update logs: 0.007929086685180664, template `Host added was in lost list earlier: mesos-slave-<*>`
========================================================================================


Iteration 244
Sample 3 from current logs bucket: ID: 187, Len: 10, Bucket Size: 22, Total Buckets: 239
Sampling from 21 logs, Sim Level: 3, MaxSim to anchor: 0.8182. Anchor: `Retrying connect to server: mesos-master-1/10.10.34.11:8030. Already tried 0 time(s); maxRetries=45`, MaxSim Log: `Retrying connect to server: mesos-master-1/10.10.34.11:8030. Already tried 1 time(s); maxRetries=45`.
	============  Query  ====================
	Log[1]: `Retrying connect to server: mesos-master-1/10.10.34.11:8030. Already tried 0 time(s); maxRetries=45`
	Log[2]: `Retrying connect to server: mesos-master-1/10.10.34.11:8030. Already tried 19 time(s); maxRetries=45`
	Log[3]: `Retrying connect to server: mesos-master-1/10.10.34.11:8030. Already tried 7 time(s); maxRetries=45`
	============ Response ====================
LogTemplate[1]: `Retrying connect to server: mesos-master-1/{ip_or_url}. Already tried <*> time(s); maxRetries=45`
	============ PostProcess ====================
	Post Template: `Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>`
	Post Template: `Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>`
	Post Template: `Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>`
	============ Aggregate ====================
	Aggregated Template:  Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>
[UpdateBucket] Logs: This iter found: 20, total: 16074909/16075117, remain: 208. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 22 -> 2, remain buckets: 27
Update Success: Time for one update logs: 0.01081395149230957, template `Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>`
========================================================================================


Iteration 245
Sample 3 from current logs bucket: ID: 120, Len: 5, Bucket Size: 21, Total Buckets: 239
Sampling from 20 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/blockmgr-c5ee997d-f5a7-4bc1-be51-d90de787c091`, MaxSim Log: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/blockmgr-fd0cece4-fcf5-4808-800f-3d520a9e96b3`.
	============  Query  ====================
	Log[1]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/blockmgr-c5ee997d-f5a7-4bc1-be51-d90de787c091`
	Log[2]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/blockmgr-07eeca2a-a773-4acd-8410-d3de5eef9a27`
	Log[3]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/blockmgr-79e43035-2ae7-4063-a61d-7d8c100ca9f9`
	============ Response ====================
LogTemplate[1]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/{blockmgr_id}`

LogTemplate[2]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/{blockmgr_id}`

LogTemplate[3]: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/{blockmgr_id}`
	============ PostProcess ====================
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>`
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>`
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>`
	============ Aggregate ====================
	Aggregated Template:  Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>
[UpdateBucket] Logs: This iter found: 21, total: 16074930/16075117, remain: 187. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 21 -> 0, remain buckets: 26
[TemplateDB] Try Merge: `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>` | `Created local directory at /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>`
	Post Template: `Created local directory at /opt/hdfs/nodemanager/usercache/<*>`
[TemplateDB] Merged: -> `Created local directory at /opt/hdfs/nodemanager/usercache/<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2353/2353, in child Bucket [119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]
[UpdateBucket] Logs: This iter found: 0, total: 16074930/16075117, remain: 187. 
[UpdateBucket] Buckets: Checked 14 ([119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132]), Parent Bucket size: 0 -> 0, remain buckets: 26
[TemplateDB] Update Indexes: 2353 -> 2353 for `Created local directory at /opt/hdfs/nodemanager/usercache/<*>`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Created local directory at /opt/hdfs/nodemanager/usercache/<*>`
Update Success: Time for one update logs: 0.08142900466918945, template `Created local directory at /opt/hdfs/nodemanager/usercache/yxsu/appcache/application_1440487435730_0039/<*>`
========================================================================================


Iteration 246
Sample 3 from current logs bucket: ID: 209, Len: 14, Bucket Size: 21, Total Buckets: 239
Sampling from 4 logs, Sim Level: 2, MaxSim to anchor: 0.8667. Anchor: `Ignoring response for RPC 6373440704166081624 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`, MaxSim Log: `Ignoring response for RPC 6596629245993899365 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`.
	============  Query  ====================
	Log[1]: `Ignoring response for RPC 6373440704166081624 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`
	Log[2]: `Ignoring response for RPC 8166013870207759075 from mesos-master-1/10.10.34.11:51096 (81 bytes) since it is not outstanding`
	Log[3]: `Ignoring response for RPC 8993307992902035380 from mesos-slave-28/10.10.34.38:43169 (81 bytes) since it is not outstanding`
	============ Response ====================
LogTemplate[1]: `Ignoring response for RPC {rpc_id} from {mesos_node}/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
LogTemplate[2]: `Ignoring response for RPC {rpc_id} from {mesos_node}/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
LogTemplate[3]: `Ignoring response for RPC {rpc_id} from {mesos_node}/{ip_address}:{port} ({bytes} bytes) since it is not outstanding`
	============ PostProcess ====================
	Post Template: `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
	Post Template: `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
	Post Template: `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
	============ Aggregate ====================
	Aggregated Template:  Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding
[UpdateBucket] Logs: This iter found: 5, total: 16074935/16075117, remain: 182. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 38 -> 33, remain buckets: 26
[TemplateDB] Try Merge: `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding` | `Ignoring response for RPC <*> from mesos-master-3/<*> (<*> bytes) since it is not outstanding`
	Post Template: `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
[TemplateDB] Merged: -> `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 71/71, in child Bucket [205, 206, 207, 208, 209]
Update Success: Time for one update logs: 0.017277956008911133, template `Ignoring response for RPC <*> from <*> (<*> bytes) since it is not outstanding`
========================================================================================


Iteration 247
Sample 3 from current logs bucket: ID: 225, Len: 25, Bucket Size: 19, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.9200. Anchor: `Connection to /10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`, MaxSim Log: `Connection to mesos-slave-05/10.10.34.15:38074 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`.
	============  Query  ====================
	Log[1]: `Connection to /10.10.34.11:51096 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Log[2]: `Connection to mesos-slave-05/10.10.34.15:38074 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Log[3]: `Connection to mesos-slave-05/10.10.34.15:49950 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ Response ====================
LogTemplate[1]: `Connection to {host}/{ip_or_url}:{port} has been quiet for {time} ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`

LogTemplate[2]: `Connection to {host}/{ip_or_url}:{port} has been quiet for {time} ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`

LogTemplate[3]: `Connection to {host}/{ip_or_url}:{port} has been quiet for {time} ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ PostProcess ====================
	Post Template: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Post Template: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Post Template: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	============ Aggregate ====================
	Aggregated Template:  Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.
[UpdateBucket] Logs: This iter found: 19, total: 16074954/16075117, remain: 163. 
[UpdateBucket] Buckets: Checked 2 ([225, 226]), Parent Bucket size: 23 -> 4, remain buckets: 25
[TemplateDB] Try Merge: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.` | `Connection to mesos-master-1/<*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
	Post Template: `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
[TemplateDB] Merged: -> `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 103/103, in child Bucket [225, 226]
Update Success: Time for one update logs: 0.019717931747436523, template `Connection to <*> has been quiet for <*> ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.`
========================================================================================


Iteration 248
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 18, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `'float' and 'NoneType'`, MaxSim Log: `'NoneType' and 'NoneType'`.
	============  Query  ====================
	Log[1]: `'float' and 'NoneType'`
	Log[2]: `'NoneType' and 'NoneType'`
	============ Response ====================
LogTemplate[1]: `'<'type>' and '<'type>'`
LogTemplate[2]: `'<'type>' and '<'type>'`
	============ PostProcess ====================
	Post Template: `'<'type>' and '<'type>'`
	Post Template: `'<'type>' and '<'type>'`
	============ Aggregate ====================
	Aggregated Template:  '<'type>' and '<'type>'
[UpdateBucket] Logs: This iter found: 0, total: 16074954/16075117, remain: 163. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 18 -> 18, remain buckets: 25
Update failed: Template can not match logs `'<'type>' and '<'type>'`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 18, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `'float' and 'NoneType'`, MaxSim Log: `'NoneType' and 'NoneType'`.
	============  Query  ====================
	Log[1]: `'float' and 'NoneType'`
	Log[2]: `'NoneType' and 'NoneType'`
	============ Response ====================
LogTemplate[1]: `'<'placeholder>' and '<placeholder>'`

LogTemplate[2]: `'<'placeholder>' and '<placeholder>'`
	============ PostProcess ====================
	Post Template: `'<'placeholder>' and '<placeholder>'`
	Post Template: `'<'placeholder>' and '<placeholder>'`
	============ Aggregate ====================
	Aggregated Template:  '<'placeholder>' and '<placeholder>'
[UpdateBucket] Logs: This iter found: 0, total: 16074954/16075117, remain: 163. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 18 -> 18, remain buckets: 25
Update failed: Template can not match logs `'<'placeholder>' and '<placeholder>'`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 18, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `'float' and 'NoneType'`, MaxSim Log: `'NoneType' and 'NoneType'`.
	============  Query  ====================
	Log[1]: `'float' and 'NoneType'`
	Log[2]: `'NoneType' and 'NoneType'`
	============ Response ====================
LogTemplate[1]: `'<'placeholder>' and '<'placeholder>'`

LogTemplate[2]: `'<'placeholder>' and '<'placeholder>'`
	============ PostProcess ====================
	Post Template: `'<'placeholder>' and '<'placeholder>'`
	Post Template: `'<'placeholder>' and '<'placeholder>'`
	============ Aggregate ====================
	Aggregated Template:  '<'placeholder>' and '<'placeholder>'
[UpdateBucket] Logs: This iter found: 0, total: 16074954/16075117, remain: 163. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 18 -> 18, remain buckets: 25
Update failed: Template can not match logs `'<'placeholder>' and '<'placeholder>'`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `'float' and 'NoneType'`
[UpdateBucket] Logs: This iter found: 2, total: 16074956/16075117, remain: 161. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 18 -> 16, remain buckets: 25
Update Success: Time for one update logs: 0.035305023193359375, template `'float' and 'NoneType'`
========================================================================================


Iteration 249
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 18, Total Buckets: 239
Sampling from 10 logs failed
	============  Query  ====================
	Log[1]: `BlockManager re-registering with master`
	============ Response ====================
LogTemplate[1]: `BlockManager re-registering with master`
	============ PostProcess ====================
	Post Template: `BlockManager re-registering with master`
	============ Aggregate ====================
	Aggregated Template:  BlockManager re-registering with master
[UpdateBucket] Logs: This iter found: 6, total: 16074962/16075117, remain: 155. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 18 -> 12, remain buckets: 25
Update Success: Time for one update logs: 0.023187875747680664, template `BlockManager re-registering with master`
========================================================================================


Iteration 250
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 18, Total Buckets: 239
Sampling from 14 logs, Sim Level: 4, MaxSim to anchor: 0.6923. Anchor: `Error sending result RpcResponse{requestId=9061557018006526513, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-1/10.10.34.11:48846; closing connection`, MaxSim Log: `Error sending result RpcResponse{requestId=4697398182609097508, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-2/10.10.34.12:45218; closing connection`.
	============  Query  ====================
	Log[1]: `Error sending result RpcResponse{requestId=9061557018006526513, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-1/10.10.34.11:48846; closing connection`
	Log[2]: `Error sending result RpcResponse{requestId=7069752773918538095, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-1/10.10.34.11:37826; closing connection`
	Log[3]: `Error sending result RpcResponse{requestId=5431439806705518153, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-2/10.10.34.12:48223; closing connection`
	============ Response ====================
LogTemplate[1]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-<*>/<*>; closing connection`
LogTemplate[2]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-<*>/<*>; closing connection`
LogTemplate[3]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=81]}} to mesos-master-<*>/<*>; closing connection`
	============ PostProcess ====================
	Post Template: `Error sending result <*>} to mesos-master-<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-master-<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-master-<*>; closing connection`
	============ Aggregate ====================
	Aggregated Template:  Error sending result <*>} to mesos-master-<*>; closing connection
[UpdateBucket] Logs: This iter found: 7, total: 16074969/16075117, remain: 148. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 18 -> 11, remain buckets: 25
[TemplateDB] Try Merge: `Error sending result <*>} to mesos-master-<*>; closing connection` | `Error sending result <*>} to mesos-slave-<*>; closing connection`
	Post Template: `Error sending result <*>} to mesos-<*>; closing connection`
[TemplateDB] Merged: -> `Error sending result <*>} to mesos-<*>; closing connection`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 38/38, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
[UpdateBucket] Logs: This iter found: 0, total: 16074969/16075117, remain: 148. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 11 -> 11, remain buckets: 25
[TemplateDB] Update Indexes: 38 -> 38 for `Error sending result <*>} to mesos-<*>; closing connection`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Error sending result <*>} to mesos-<*>; closing connection`
Update Success: Time for one update logs: 0.027286052703857422, template `Error sending result <*>} to mesos-master-<*>; closing connection`
========================================================================================


Iteration 251
Sample 3 from current logs bucket: ID: 208, Len: 14, Bucket Size: 17, Total Buckets: 239
Sampling from 16 logs, Sim Level: 2, MaxSim to anchor: 0.4737. Anchor: `Lost task 2.1 in stage 3.1 (TID 19, mesos-master-1): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=2, message=`, MaxSim Log: `Lost task 30.1 in stage 8.0 (TID 550, mesos-master-1): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=30, message=`.
	============  Query  ====================
	Log[1]: `Lost task 2.1 in stage 3.1 (TID 19, mesos-master-1): FetchFailed(null, shuffleId=0, mapId=-1, reduceId=2, message=`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage_id} (TID {tid}, mesos-master-1): FetchFailed(null, shuffleId=0, mapId=-1, reduceId={reduce_id}, message=`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-master-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-master-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=
[UpdateBucket] Logs: This iter found: 17, total: 16074986/16075117, remain: 131. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 33 -> 16, remain buckets: 24
[TemplateDB] Try Merge: `Lost task <*> in stage <*> (TID <*> mesos-master-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=` | `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
[TemplateDB] Merged: -> `Lost task <*> in stage <*> (TID <*> mesos-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 140/140, in child Bucket [205, 206, 207, 208, 209]
[UpdateBucket] Logs: This iter found: 0, total: 16074986/16075117, remain: 131. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 16 -> 16, remain buckets: 24
[TemplateDB] Update Indexes: 140 -> 140 for `Lost task <*> in stage <*> (TID <*> mesos-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Lost task <*> in stage <*> (TID <*> mesos-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
Update Success: Time for one update logs: 0.02460312843322754, template `Lost task <*> in stage <*> (TID <*> mesos-master-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=`
========================================================================================


Iteration 252
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 16, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `'NoneType' and 'float'`, MaxSim Log: `'NoneType' and 'NoneType'`.
	============  Query  ====================
	Log[1]: `'NoneType' and 'float'`
	Log[2]: `'NoneType' and 'NoneType'`
	============ Response ====================
LogTemplate[1]: `'NoneType' and {datatype}'`

LogTemplate[2]: `'NoneType' and 'NoneType'`
	============ PostProcess ====================
	Post Template: `'NoneType' and <*>'`
	Post Template: `'NoneType' and 'NoneType'`
	============ Aggregate ====================
	Aggregated Template:  'NoneType' and <*>'
[UpdateBucket] Logs: This iter found: 15, total: 16075001/16075117, remain: 116. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 16 -> 1, remain buckets: 24
Update Success: Time for one update logs: 0.05784893035888672, template `'NoneType' and <*>'`
========================================================================================


Iteration 253
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 16, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Lost executor 8 on mesos-master-1: Slave lost`
	============ Response ====================
LogTemplate[1]: `Lost executor <*> on mesos-master-<*>: Slave lost`
	============ PostProcess ====================
	Post Template: `Lost executor <*> on mesos-master-<*>: Slave lost`
	============ Aggregate ====================
	Aggregated Template:  Lost executor <*> on mesos-master-<*>: Slave lost
[UpdateBucket] Logs: This iter found: 1, total: 16075002/16075117, remain: 115. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 16 -> 15, remain buckets: 24
Update Success: Time for one update logs: 0.02225518226623535, template `Lost executor <*> on mesos-master-<*>: Slave lost`
========================================================================================


Iteration 254
Sample 3 from current logs bucket: ID: 209, Len: 14, Bucket Size: 16, Total Buckets: 239
Sampling from 6 logs, Sim Level: 4, MaxSim to anchor: 0.8667. Anchor: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 0`, MaxSim Log: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 1`.
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 0`
	Log[2]: `Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 1`
	Log[3]: `Resubmitting ShuffleMapStage 2 (reduceByKey at pnmf4.py:371) because some of its tasks had failed: 2`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} (reduceByKey at pnmf4.py:371) because some of its tasks had failed: {task_num}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	Post Template: `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 10, total: 16075012/16075117, remain: 105. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 16 -> 6, remain buckets: 24
Update Success: Time for one update logs: 0.006694316864013672, template `Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 255
Sample 3 from current logs bucket: ID: 164, Len: 7, Bucket Size: 15, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `waiting: Set(ResultStage 12, ShuffleMapStage 10, ShuffleMapStage 11)`
	============ Response ====================
LogTemplate[1]: `waiting: Set(ResultStage <*>, ShuffleMapStage <*>, ShuffleMapStage <*>)`
	============ PostProcess ====================
	Post Template: `waiting: Set(ResultStage <*> ShuffleMapStage <*> ShuffleMapStage <*>)`
	============ Aggregate ====================
	Aggregated Template:  waiting: Set(ResultStage <*> ShuffleMapStage <*> ShuffleMapStage <*>)
[UpdateBucket] Logs: This iter found: 15, total: 16075027/16075117, remain: 90. 
[UpdateBucket] Buckets: Checked 19 ([146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164]), Parent Bucket size: 15 -> 0, remain buckets: 23
Update Success: Time for one update logs: 0.022784948348999023, template `waiting: Set(ResultStage <*> ShuffleMapStage <*> ShuffleMapStage <*>)`
========================================================================================


Iteration 256
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 12, Total Buckets: 239
Sampling from 8 logs failed
	============  Query  ====================
	Log[1]: `Putting block broadcast_6 failed`
	============ Response ====================
LogTemplate[1]: `Putting block {block_name} failed`
	============ PostProcess ====================
	Post Template: `Putting block <*> failed`
	============ Aggregate ====================
	Aggregated Template:  Putting block <*> failed
[UpdateBucket] Logs: This iter found: 1, total: 16075028/16075117, remain: 89. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 12 -> 11, remain buckets: 23
Update Success: Time for one update logs: 0.02418208122253418, template `Putting block <*> failed`
========================================================================================


Iteration 257
Sample 3 from current logs bucket: ID: 223, Len: 23, Bucket Size: 12, Total Buckets: 239
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.3529. Anchor: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`, MaxSim Log: `Failed to remove broadcast 8 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`.
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: <exit_code>, (reason: Uncaught exception: <exception>)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <exit_code>, (reason: Uncaught exception: <exception>)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <exit_code>, (reason: Uncaught exception: <exception>)
[UpdateBucket] Logs: This iter found: 0, total: 16075028/16075117, remain: 89. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 12 -> 12, remain buckets: 23
Update failed: Template can not match logs `Final app status: FAILED, exitCode: <exit_code>, (reason: Uncaught exception: <exception>)`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 223, Len: 23, Bucket Size: 12, Total Buckets: 239
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.3529. Anchor: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`, MaxSim Log: `Failed to remove broadcast 8 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`.
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: <*>, (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)
[UpdateBucket] Logs: This iter found: 0, total: 16075028/16075117, remain: 89. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 12 -> 12, remain buckets: 23
Update failed: Template can not match logs `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 223, Len: 23, Bucket Size: 12, Total Buckets: 239
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.3529. Anchor: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`, MaxSim Log: `Failed to remove broadcast 8 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`.
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 10, (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: <*>, (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)
[UpdateBucket] Logs: This iter found: 0, total: 16075028/16075117, remain: 89. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 12 -> 12, remain buckets: 23
Update failed: Template can not match logs `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <api:org.apache.spark.rpc.RpcTimeoutException>: Cannot receive any reply in <time:120> seconds. This timeout is controlled by spark.rpc.askTimeout)`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout)`
[UpdateBucket] Logs: This iter found: 3, total: 16075031/16075117, remain: 86. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 12 -> 9, remain buckets: 23
Update Success: Time for one update logs: 0.004709959030151367, template `Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout)`
========================================================================================


Iteration 258
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 11, Total Buckets: 239
Sampling from 6 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Error cleaning broadcast 8`, MaxSim Log: `Error cleaning broadcast 7`.
	============  Query  ====================
	Log[1]: `Error cleaning broadcast 8`
	Log[2]: `Error cleaning broadcast 9`
	Log[3]: `Error cleaning broadcast 17`
	============ Response ====================
LogTemplate[1]: `Error cleaning broadcast {broadcast_id}`  
LogTemplate[2]: `Error cleaning broadcast {broadcast_id}`  
LogTemplate[3]: `Error cleaning broadcast {broadcast_id}`  
	============ PostProcess ====================
	Post Template: `Error cleaning broadcast <*>`
	Post Template: `Error cleaning broadcast <*>`
	Post Template: `Error cleaning broadcast <*>`
	============ Aggregate ====================
	Aggregated Template:  Error cleaning broadcast <*>
[UpdateBucket] Logs: This iter found: 10, total: 16075041/16075117, remain: 76. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 11 -> 1, remain buckets: 23
Update Success: Time for one update logs: 0.025569677352905273, template `Error cleaning broadcast <*>`
========================================================================================


Iteration 259
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 11, Total Buckets: 239
Sampling from 7 logs, Sim Level: 3, MaxSim to anchor: 0.6923. Anchor: `Error sending result RpcResponse{requestId=6668610426802334028, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /10.10.34.36:39313; closing connection`, MaxSim Log: `Error sending result RpcResponse{requestId=5934169906541463475, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /10.10.34.23:38729; closing connection`.
	============  Query  ====================
	Log[1]: `Error sending result RpcResponse{requestId=6668610426802334028, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /10.10.34.36:39313; closing connection`
	Log[2]: `Error sending result RpcResponse{requestId=5934169906541463475, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /10.10.34.23:38729; closing connection`
	Log[3]: `Error sending result RpcResponse{requestId=6285396386939119267, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /10.10.34.33:56417; closing connection`
	============ Response ====================
LogTemplate[1]: `Error sending result RpcResponse{requestId=<*>, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=13 cap=13]}} to /{ip_address}:{port}; closing connection`
	============ PostProcess ====================
	Post Template: `Error sending result <*>} to /<*>; closing connection`
	Post Template: `Error sending result <*>} to /<*>; closing connection`
	Post Template: `Error sending result <*>} to /<*>; closing connection`
	============ Aggregate ====================
	Aggregated Template:  Error sending result <*>} to /<*>; closing connection
[UpdateBucket] Logs: This iter found: 5, total: 16075046/16075117, remain: 71. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 11 -> 6, remain buckets: 23
[TemplateDB] Try Merge: `Error sending result <*>} to /<*>; closing connection` | `Error sending result <*>} to mesos-<*>; closing connection`
	Post Template: `Error sending result <*>} to <*>; closing connection`
[TemplateDB] Merged: -> `Error sending result <*>} to <*>; closing connection`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 43/43, in child Bucket [188, 189, 190, 191, 192, 193, 194, 195]
[UpdateBucket] Logs: This iter found: 0, total: 16075046/16075117, remain: 71. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 6 -> 6, remain buckets: 23
[TemplateDB] Update Indexes: 43 -> 43 for `Error sending result <*>} to <*>; closing connection`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Error sending result <*>} to <*>; closing connection`
Update Success: Time for one update logs: 0.024999380111694336, template `Error sending result <*>} to /<*>; closing connection`
========================================================================================


Iteration 260
Sample 3 from current logs bucket: ID: 223, Len: 23, Bucket Size: 9, Total Buckets: 239
Sampling from 4 logs, Sim Level: 1, MaxSim to anchor: 0.9167. Anchor: `Failed to remove broadcast 8 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`, MaxSim Log: `Failed to remove broadcast 7 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`.
	============  Query  ====================
	Log[1]: `Failed to remove broadcast 8 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`
	Log[2]: `Failed to remove broadcast 7 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`
	Log[3]: `Failed to remove broadcast 9 with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`
	============ Response ====================
LogTemplate[1]: `Failed to remove broadcast {broadcast_id} with removeFromMaster = true - Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout`
	============ PostProcess ====================
	Post Template: `Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout`
	Post Template: `Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout`
	Post Template: `Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout`
	============ Aggregate ====================
	Aggregated Template:  Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout
[UpdateBucket] Logs: This iter found: 8, total: 16075054/16075117, remain: 63. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 9 -> 1, remain buckets: 23
Update Success: Time for one update logs: 0.0059392452239990234, template `Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout`
========================================================================================


Iteration 261
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 6, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.8182. Anchor: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-2,5,main]`, MaxSim Log: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-0,5,main]`.
	============  Query  ====================
	Log[1]: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-2,5,main]`
	Log[2]: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-1,5,main]`
	Log[3]: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-0,5,main]`
	============ Response ====================
LogTemplate[1]: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-{worker_id},5,main]`
	============ PostProcess ====================
	Post Template: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
	Post Template: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
	Post Template: `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
	============ Aggregate ====================
	Aggregated Template:  [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]
[UpdateBucket] Logs: This iter found: 3, total: 16075057/16075117, remain: 60. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 6 -> 3, remain buckets: 23
Update Success: Time for one update logs: 0.01040506362915039, template `[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]`
========================================================================================


Iteration 262
Sample 3 from current logs bucket: ID: 209, Len: 14, Bucket Size: 6, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8667. Anchor: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (4) reached)`, MaxSim Log: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (32) reached)`.
	============  Query  ====================
	Log[1]: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (4) reached)`
	Log[2]: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (32) reached)`
	============ Response ====================
LogTemplate[1]: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (<*> reached)`
LogTemplate[2]: `Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (<*> reached)`
	============ PostProcess ====================
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Max number of executor failures (<*> reached)`
	Post Template: `Final app status: FAILED, exitCode: <*> (reason: Max number of executor failures (<*> reached)`
	============ Aggregate ====================
	Aggregated Template:  Final app status: FAILED, exitCode: <*> (reason: Max number of executor failures (<*> reached)
[UpdateBucket] Logs: This iter found: 4, total: 16075061/16075117, remain: 56. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 6 -> 2, remain buckets: 23
Update Success: Time for one update logs: 0.011219978332519531, template `Final app status: FAILED, exitCode: <*> (reason: Max number of executor failures (<*> reached)`
========================================================================================


Iteration 263
Sample 3 from current logs bucket: ID: 221, Len: 20, Bucket Size: 6, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.7895. Anchor: `Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`, MaxSim Log: `Container marked as failed: container_1485248649253_0072_02_000005 on host: mesos-master-2. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`.
	============  Query  ====================
	Log[1]: `Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	Log[2]: `Container marked as failed: container_1485248649253_0072_02_000005 on host: mesos-master-2. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	Log[3]: `Container marked as failed: container_1485248649253_0068_01_000003 on host: mesos-slave-06. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	============ Response ====================
LogTemplate[1]: `Container marked as failed: {container_id} on host: {host}. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
LogTemplate[2]: `Container marked as failed: {container_id} on host: {host}. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
LogTemplate[3]: `Container marked as failed: {container_id} on host: {host}. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	============ PostProcess ====================
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	Post Template: `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	============ Aggregate ====================
	Aggregated Template:  Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>
[UpdateBucket] Logs: This iter found: 6, total: 16075067/16075117, remain: 50. 
[UpdateBucket] Buckets: Checked 2 ([220, 221]), Parent Bucket size: 8 -> 2, remain buckets: 22
Update Success: Time for one update logs: 0.004731893539428711, template `Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
========================================================================================


Iteration 264
Sample 3 from current logs bucket: ID: 212, Len: 16, Bucket Size: 5, Total Buckets: 239
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.6875. Anchor: `Total size of serialized results of 4 tasks (4.1 GB) is bigger than spark.driver.maxResultSize (4.0 GB)`, MaxSim Log: `Total size of serialized results of 2 tasks (2.0 GB) is bigger than spark.driver.maxResultSize (2.0 GB)`.
	============  Query  ====================
	Log[1]: `Total size of serialized results of 4 tasks (4.1 GB) is bigger than spark.driver.maxResultSize (4.0 GB)`
	Log[2]: `Total size of serialized results of 2 tasks (2.0 GB) is bigger than spark.driver.maxResultSize (2.0 GB)`
	Log[3]: `Total size of serialized results of 1 tasks (1044.8 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)`
	============ Response ====================
LogTemplate[1]: `Total size of serialized results of {task_count} tasks ({size}) is bigger than spark.driver.maxResultSize ({max_size})`  
LogTemplate[2]: `Total size of serialized results of {task_count} tasks ({size}) is bigger than spark.driver.maxResultSize ({max_size})`  
LogTemplate[3]: `Total size of serialized results of {task_count} tasks ({size}) is bigger than spark.driver.maxResultSize ({max_size})`  
	============ PostProcess ====================
	Post Template: `Total size of serialized results of <*> tasks (<*>) is bigger than spark.driver.maxResultSize (<*>)`
	Post Template: `Total size of serialized results of <*> tasks (<*>) is bigger than spark.driver.maxResultSize (<*>)`
	Post Template: `Total size of serialized results of <*> tasks (<*>) is bigger than spark.driver.maxResultSize (<*>)`
	============ Aggregate ====================
	Aggregated Template:  Total size of serialized results of <*> tasks (<*>) is bigger than spark.driver.maxResultSize (<*>)
[UpdateBucket] Logs: This iter found: 5, total: 16075072/16075117, remain: 45. 
[UpdateBucket] Buckets: Checked 1 ([212]), Parent Bucket size: 5 -> 0, remain buckets: 21
Update Success: Time for one update logs: 0.0050678253173828125, template `Total size of serialized results of <*> tasks (<*>) is bigger than spark.driver.maxResultSize (<*>)`
========================================================================================


Iteration 265
Sample 3 from current logs bucket: ID: 11, Len: 2, Bucket Size: 4, Total Buckets: 239
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Uncaught exception:`
	============ Response ====================
LogTemplate[1]: `Uncaught exception:`
	============ PostProcess ====================
	Post Template: `Uncaught exception:`
	============ Aggregate ====================
	Aggregated Template:  Uncaught exception:
[UpdateBucket] Logs: This iter found: 4, total: 16075076/16075117, remain: 41. 
[UpdateBucket] Buckets: Checked 12 ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]), Parent Bucket size: 4 -> 0, remain buckets: 20
Update Success: Time for one update logs: 0.014163970947265625, template `Uncaught exception:`
========================================================================================


Iteration 266
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 4, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Host added was in lost list earlier: mesos-master-2`, MaxSim Log: `Host added was in lost list earlier: mesos-master-1`.
	============  Query  ====================
	Log[1]: `Host added was in lost list earlier: mesos-master-2`
	Log[2]: `Host added was in lost list earlier: mesos-master-1`
	============ Response ====================
LogTemplate[1]: `Host added was in lost list earlier: {hostname}`
	============ PostProcess ====================
	Post Template: `Host added was in lost list earlier: <*>`
	Post Template: `Host added was in lost list earlier: <*>`
	============ Aggregate ====================
	Aggregated Template:  Host added was in lost list earlier: <*>
[UpdateBucket] Logs: This iter found: 3, total: 16075079/16075117, remain: 38. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 4 -> 1, remain buckets: 20
[TemplateDB] Try Merge: `Host added was in lost list earlier: <*>` | `Host added was in lost list earlier: mesos-slave-<*>`
	Post Template: `Host added was in lost list earlier: <*>`
[TemplateDB] Merged: -> `Host added was in lost list earlier: <*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 21/21, in child Bucket [165, 166, 167, 168, 169, 170]
Update Success: Time for one update logs: 0.014377117156982422, template `Host added was in lost list earlier: <*>`
========================================================================================


Iteration 267
Sample 3 from current logs bucket: ID: 222, Len: 22, Bucket Size: 4, Total Buckets: 239
Sampling from 2 logs failed
	============  Query  ====================
	Log[1]: `Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in 120 seconds. This timeout is controlled by spark.rpc.askTimeout)`
	============ Response ====================
LogTemplate[1]: `Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: {exception_type}: {exception_message})`
	============ PostProcess ====================
	Post Template: `Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: <*>: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: <*>: <*>)
[UpdateBucket] Logs: This iter found: 3, total: 16075082/16075117, remain: 35. 
[UpdateBucket] Buckets: Checked 1 ([222]), Parent Bucket size: 4 -> 1, remain buckets: 20
Update Success: Time for one update logs: 0.0023508071899414062, template `Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: <*>: <*>)`
========================================================================================


Iteration 268
Sample 3 from current logs bucket: ID: 226, Len: 25, Bucket Size: 4, Total Buckets: 239
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.6800. Anchor: `Lost executor 1 on mesos-slave-08: Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`, MaxSim Log: `Lost executor 4 on mesos-master-2: Container marked as failed: container_1485248649253_0072_02_000005 on host: mesos-master-2. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`.
	============  Query  ====================
	Log[1]: `Lost executor 1 on mesos-slave-08: Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	Log[2]: `Lost executor 4 on mesos-master-2: Container marked as failed: container_1485248649253_0072_02_000005 on host: mesos-master-2. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	Log[3]: `Lost executor 2 on mesos-slave-06: Container marked as failed: container_1485248649253_0068_01_000003 on host: mesos-slave-06. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	============ Response ====================
LogTemplate[1]: `Lost executor {executor_id} on {host}: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Container killed on request. Exit code is {exit_code}`

LogTemplate[2]: `Lost executor {executor_id} on {host}: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Container killed on request. Exit code is {exit_code}`

LogTemplate[3]: `Lost executor {executor_id} on {host}: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Container killed on request. Exit code is {exit_code}`
	============ PostProcess ====================
	Post Template: `Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	Post Template: `Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	Post Template: `Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	============ Aggregate ====================
	Aggregated Template:  Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>
[UpdateBucket] Logs: This iter found: 3, total: 16075085/16075117, remain: 32. 
[UpdateBucket] Buckets: Checked 2 ([225, 226]), Parent Bucket size: 4 -> 1, remain buckets: 20
Update Success: Time for one update logs: 0.005218029022216797, template `Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
========================================================================================


Iteration 269
Sample 3 from current logs bucket: ID: 234, Len: 36, Bucket Size: 4, Total Buckets: 239
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Lost task 0.1 in stage 5.1 (TID 17, mesos-master-1): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000004 on host: mesos-master-1. Exit status: 52. Diagnostics: Exception from container-launch.`, MaxSim Log: `Lost task 0.1 in stage 4.0 (TID 12, mesos-slave-21): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_01_000003 on host: mesos-slave-21. Exit status: 52. Diagnostics: Exception from container-launch.`.
	============  Query  ====================
	Log[1]: `Lost task 0.1 in stage 5.1 (TID 17, mesos-master-1): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000004 on host: mesos-master-1. Exit status: 52. Diagnostics: Exception from container-launch.`
	Log[2]: `Lost task 0.0 in stage 4.2 (TID 18, mesos-slave-17): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_01_000006 on host: mesos-slave-17. Exit status: 52. Diagnostics: Exception from container-launch.`
	Log[3]: `Lost task 0.0 in stage 4.3 (TID 24, mesos-slave-27): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000006 on host: mesos-slave-27. Exit status: 52. Diagnostics: Exception from container-launch.`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`

LogTemplate[2]: `Lost task {task_id} in stage {stage} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`

LogTemplate[3]: `Lost task {task_id} in stage {stage} (TID {tid}, {executor}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: {host}. Exit status: {exit_status}. Diagnostics: Exception from container-launch.`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	Post Template: `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.
[UpdateBucket] Logs: This iter found: 4, total: 16075089/16075117, remain: 28. 
[UpdateBucket] Buckets: Checked 1 ([234]), Parent Bucket size: 4 -> 0, remain buckets: 19
Update Success: Time for one update logs: 0.005194902420043945, template `Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.`
========================================================================================


Iteration 270
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 3, Total Buckets: 239
Sampling from 2 logs, Sim Level: 2, MaxSim to anchor: 0.8333. Anchor: `Failed to fetch block shuffle_3_52_6, and will not retry (0 retries)`, MaxSim Log: `Failed to fetch block shuffle_3_56_6, and will not retry (0 retries)`.
	============  Query  ====================
	Log[1]: `Failed to fetch block shuffle_3_52_6, and will not retry (0 retries)`
	Log[2]: `Failed to fetch block shuffle_3_56_6, and will not retry (0 retries)`
	============ Response ====================
LogTemplate[1]: `Failed to fetch block shuffle_<*>_<*>_<*>, and will not retry (<*> retries)`
LogTemplate[2]: `Failed to fetch block shuffle_<*>_<*>_<*>, and will not retry (<*> retries)`
	============ PostProcess ====================
	Post Template: `Failed to fetch block <*> and will not retry (<*> retries)`
	Post Template: `Failed to fetch block <*> and will not retry (<*> retries)`
	============ Aggregate ====================
	Aggregated Template:  Failed to fetch block <*> and will not retry (<*> retries)
[UpdateBucket] Logs: This iter found: 2, total: 16075091/16075117, remain: 26. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 3 -> 1, remain buckets: 19
Update Success: Time for one update logs: 0.015437841415405273, template `Failed to fetch block <*> and will not retry (<*> retries)`
========================================================================================


Iteration 271
Sample 3 from current logs bucket: ID: 231, Len: 31, Bucket Size: 3, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.9286. Anchor: `Task 1662 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`, MaxSim Log: `Task 1661 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`.
	============  Query  ====================
	Log[1]: `Task 1662 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Log[2]: `Task 1661 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Log[3]: `Task 1660 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ Response ====================
LogTemplate[1]: `Task {task_id} failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ PostProcess ====================
	Post Template: `Task <*> failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Post Template: `Task <*> failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Post Template: `Task <*> failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ Aggregate ====================
	Aggregated Template:  Task <*> failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
[UpdateBucket] Logs: This iter found: 0, total: 16075091/16075117, remain: 26. 
[UpdateBucket] Buckets: Checked 1 ([231]), Parent Bucket size: 3 -> 3, remain buckets: 19
Update failed: Template can not match logs `Task <*> failed because while it was being computed, its executor exited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 231, Len: 31, Bucket Size: 3, Total Buckets: 239
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.9286. Anchor: `Task 1662 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`, MaxSim Log: `Task 1661 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`.
	============  Query  ====================
	Log[1]: `Task 1662 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Log[2]: `Task 1661 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Log[3]: `Task 1660 failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ Response ====================
LogTemplate[1]: `Task {task_id} failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ PostProcess ====================
	Post Template: `Task <*> failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Post Template: `Task <*> failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	Post Template: `Task <*> failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
	============ Aggregate ====================
	Aggregated Template:  Task <*> failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.
[UpdateBucket] Logs: This iter found: 3, total: 16075094/16075117, remain: 23. 
[UpdateBucket] Buckets: Checked 1 ([231]), Parent Bucket size: 3 -> 0, remain buckets: 18
Update Success: Time for one update logs: 0.00538182258605957, template `Task <*> failed because while it was being computed, its executorexited for a reason unrelated to the task. Not counting this failure towards the maximum number of failures for the task.`
========================================================================================


Iteration 272
Sample 3 from current logs bucket: ID: 187, Len: 10, Bucket Size: 2, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.0556. Anchor: `Another thread is loading rdd_27_39, waiting for it to finish...`, MaxSim Log: `Failed to send RPC 5171733260621106751 to mesos-slave-23/10.10.34.33:48825: java.io.IOException: Broken pipe`.
	============  Query  ====================
	Log[1]: `Another thread is loading rdd_27_39, waiting for it to finish...`
	============ Response ====================
LogTemplate[1]: `Another thread is loading {rdd_id}, waiting for it to finish...`
	============ PostProcess ====================
	Post Template: `Another thread is loading <*> waiting for it to finish...`
	============ Aggregate ====================
	Aggregated Template:  Another thread is loading <*> waiting for it to finish...
[UpdateBucket] Logs: This iter found: 1, total: 16075095/16075117, remain: 22. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 2 -> 1, remain buckets: 18
Update Success: Time for one update logs: 0.010417938232421875, template `Another thread is loading <*> waiting for it to finish...`
========================================================================================


Iteration 273
Sample 3 from current logs bucket: ID: 209, Len: 14, Bucket Size: 2, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8667. Anchor: `Failed to remove broadcast 20 with removeFromMaster = true - Connection reset by peer`, MaxSim Log: `Failed to remove broadcast 17 with removeFromMaster = true - Connection reset by peer`.
	============  Query  ====================
	Log[1]: `Failed to remove broadcast 20 with removeFromMaster = true - Connection reset by peer`
	Log[2]: `Failed to remove broadcast 17 with removeFromMaster = true - Connection reset by peer`
	============ Response ====================
LogTemplate[1]: `Failed to remove broadcast {number} with removeFromMaster = true - Connection reset by peer`
LogTemplate[2]: `Failed to remove broadcast {number} with removeFromMaster = true - Connection reset by peer`
	============ PostProcess ====================
	Post Template: `Failed to remove broadcast <*> with removeFromMaster = true - Connection reset by peer`
	Post Template: `Failed to remove broadcast <*> with removeFromMaster = true - Connection reset by peer`
	============ Aggregate ====================
	Aggregated Template:  Failed to remove broadcast <*> with removeFromMaster = true - Connection reset by peer
[UpdateBucket] Logs: This iter found: 2, total: 16075097/16075117, remain: 20. 
[UpdateBucket] Buckets: Checked 5 ([205, 206, 207, 208, 209]), Parent Bucket size: 2 -> 0, remain buckets: 17
Update Success: Time for one update logs: 0.01128387451171875, template `Failed to remove broadcast <*> with removeFromMaster = true - Connection reset by peer`
========================================================================================


Iteration 274
Sample 3 from current logs bucket: ID: 220, Len: 20, Bucket Size: 2, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7391. Anchor: `Finished task 2.0 in stage 3.0 (TID 12). Result is larger than maxResultSize (1044.8 MB > 1024.0 MB), dropping it.`, MaxSim Log: `Finished task 1.0 in stage 3.0 (TID 11). Result is larger than maxResultSize (1044.5 MB > 1024.0 MB), dropping it.`.
	============  Query  ====================
	Log[1]: `Finished task 2.0 in stage 3.0 (TID 12). Result is larger than maxResultSize (1044.8 MB > 1024.0 MB), dropping it.`
	Log[2]: `Finished task 1.0 in stage 3.0 (TID 11). Result is larger than maxResultSize (1044.5 MB > 1024.0 MB), dropping it.`
	============ Response ====================
LogTemplate[1]: `Finished task {task_id} in stage {stage_id} (TID {task_id}). Result is larger than maxResultSize ({result_size} MB > 1024.0 MB), dropping it.`

LogTemplate[2]: `Finished task {task_id} in stage {stage_id} (TID {task_id}). Result is larger than maxResultSize ({result_size} MB > 1024.0 MB), dropping it.`
	============ PostProcess ====================
	Post Template: `Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> MB > <*> MB), dropping it.`
	Post Template: `Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> MB > <*> MB), dropping it.`
	============ Aggregate ====================
	Aggregated Template:  Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> MB > <*> MB), dropping it.
[UpdateBucket] Logs: This iter found: 2, total: 16075099/16075117, remain: 18. 
[UpdateBucket] Buckets: Checked 2 ([220, 221]), Parent Bucket size: 2 -> 0, remain buckets: 16
Update Success: Time for one update logs: 0.008397102355957031, template `Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> MB > <*> MB), dropping it.`
========================================================================================


Iteration 275
Sample 3 from current logs bucket: ID: 232, Len: 34, Bucket Size: 2, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.3077. Anchor: `Resubmitting ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 6, 9, 17, 20, 21, 22, 24, 25, 27, 32, 33, 34, 42, 53, 61, 65, 69, 71, 77, 79`, MaxSim Log: `Resubmitting ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 4, 7, 10, 13, 16, 24, 25, 26, 27, 28, 29, 39, 40, 43, 46, 49, 52, 54, 57, 65`.
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 6, 9, 17, 20, 21, 22, 24, 25, 27, 32, 33, 34, 42, 53, 61, 65, 69, 71, 77, 79`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_id} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 2, total: 16075101/16075117, remain: 16. 
[UpdateBucket] Buckets: Checked 1 ([232]), Parent Bucket size: 2 -> 0, remain buckets: 15
Update Success: Time for one update logs: 0.006484270095825195, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 276
Sample 3 from current logs bucket: ID: 236, Len: 41, Bucket Size: 2, Total Buckets: 239
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7273. Anchor: `Lost task 0.1 in stage 4.0 (TID 12, mesos-slave-08): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`, MaxSim Log: `Lost task 0.0 in stage 2.1 (TID 12, mesos-slave-06): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0068_01_000003 on host: mesos-slave-06. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`.
	============  Query  ====================
	Log[1]: `Lost task 0.1 in stage 4.0 (TID 12, mesos-slave-08): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0076_02_000002 on host: mesos-slave-08. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	Log[2]: `Lost task 0.0 in stage 2.1 (TID 12, mesos-slave-06): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container marked as failed: container_1485248649253_0068_01_000003 on host: mesos-slave-06. Exit status: 143. Diagnostics: Container killed on request. Exit code is 143`
	============ Response ====================
LogTemplate[1]: `Lost task {task_id} in stage {stage} (TID {tid}, mesos-slave-{slave_id}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: mesos-slave-{slave_id}. Exit status: {exit_status}. Diagnostics: Container killed on request. Exit code is {exit_code}`

LogTemplate[2]: `Lost task {task_id} in stage {stage} (TID {tid}, mesos-slave-{slave_id}): ExecutorLostFailure (executor {executor_id} exited caused by one of the running tasks) Reason: Container marked as failed: {container_id} on host: mesos-slave-{slave_id}. Exit status: {exit_status}. Diagnostics: Container killed on request. Exit code is {exit_code}`
	============ PostProcess ====================
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	Post Template: `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
	============ Aggregate ====================
	Aggregated Template:  Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>
[UpdateBucket] Logs: This iter found: 2, total: 16075103/16075117, remain: 14. 
[UpdateBucket] Buckets: Checked 1 ([236]), Parent Bucket size: 2 -> 0, remain buckets: 14
Update Success: Time for one update logs: 0.009414911270141602, template `Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>`
========================================================================================


Iteration 277
Sample 3 from current logs bucket: ID: 98, Len: 3, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `java.io.IOException: Broken pipe`
	============ Response ====================
LogTemplate[1]: `{error_message}`: Broken pipe
	============ PostProcess ====================
	Post Template: `<*>: Broken pipe`
	============ Aggregate ====================
	Aggregated Template:  <*>: Broken pipe
[UpdateBucket] Logs: This iter found: 1, total: 16075104/16075117, remain: 13. 
[UpdateBucket] Buckets: Checked 87 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98]), Parent Bucket size: 1 -> 0, remain buckets: 13
Update Success: Time for one update logs: 0.05487203598022461, template `<*>: Broken pipe`
========================================================================================


Iteration 278
Sample 3 from current logs bucket: ID: 118, Len: 4, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Finished waiting for rdd_27_39`
	============ Response ====================
LogTemplate[1]: `Finished waiting for {rdd_id}`
	============ PostProcess ====================
	Post Template: `Finished waiting for <*>`
	============ Aggregate ====================
	Aggregated Template:  Finished waiting for <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075105/16075117, remain: 12. 
[UpdateBucket] Buckets: Checked 20 ([99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]), Parent Bucket size: 1 -> 0, remain buckets: 12
Update Success: Time for one update logs: 0.012028217315673828, template `Finished waiting for <*>`
========================================================================================


Iteration 279
Sample 3 from current logs bucket: ID: 170, Len: 8, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Error while invoking RpcHandler#receive() on RPC id 8192611242310115905`
	============ Response ====================
LogTemplate[1]: `Error while invoking RpcHandler#receive() on RPC id {rpc_id}`
	============ PostProcess ====================
	Post Template: `Error while invoking RpcHandler#receive() on RPC id <*>`
	============ Aggregate ====================
	Aggregated Template:  Error while invoking RpcHandler#receive() on RPC id <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075106/16075117, remain: 11. 
[UpdateBucket] Buckets: Checked 6 ([165, 166, 167, 168, 169, 170]), Parent Bucket size: 1 -> 0, remain buckets: 11
Update Success: Time for one update logs: 0.014260053634643555, template `Error while invoking RpcHandler#receive() on RPC id <*>`
========================================================================================


Iteration 280
Sample 3 from current logs bucket: ID: 187, Len: 10, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Failed to send RPC 5171733260621106751 to mesos-slave-23/10.10.34.33:48825: java.io.IOException: Broken pipe`
	============ Response ====================
LogTemplate[1]: `Failed to send RPC {rpc_id} to {mesos_slave_host}/{ip_address}:{port}: java.io.IOException: Broken pipe`
	============ PostProcess ====================
	Post Template: `Failed to send RPC <*> to <*>: java.io.IOException: Broken pipe`
	============ Aggregate ====================
	Aggregated Template:  Failed to send RPC <*> to <*>: java.io.IOException: Broken pipe
[UpdateBucket] Logs: This iter found: 1, total: 16075107/16075117, remain: 10. 
[UpdateBucket] Buckets: Checked 6 ([182, 183, 184, 185, 186, 187]), Parent Bucket size: 1 -> 0, remain buckets: 10
Update Success: Time for one update logs: 0.010744094848632812, template `Failed to send RPC <*> to <*>: java.io.IOException: Broken pipe`
========================================================================================


Iteration 281
Sample 3 from current logs bucket: ID: 195, Len: 11, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Ignored failure: java.io.IOException: Failed to send RPC 8212686680769530402 to mesos-slave-05/10.10.34.15:59498: java.nio.channels.ClosedChannelException`
	============ Response ====================
LogTemplate[1] Ignored failure: java.io.IOException: Failed to send RPC <*> to mesos-slave-05/<ip_address>:<port>: java.nio.channels.ClosedChannelException
	============ PostProcess ====================
	Post Template: `Ignored failure: java.io.IOException: Failed to send RPC <*> to mesos-slave-05/10.<*>: java.nio.channels.ClosedChannelException`
	============ Aggregate ====================
	Aggregated Template:  Ignored failure: java.io.IOException: Failed to send RPC <*> to mesos-slave-05/10.<*>: java.nio.channels.ClosedChannelException
[UpdateBucket] Logs: This iter found: 1, total: 16075108/16075117, remain: 9. 
[UpdateBucket] Buckets: Checked 8 ([188, 189, 190, 191, 192, 193, 194, 195]), Parent Bucket size: 1 -> 0, remain buckets: 9
Update Success: Time for one update logs: 0.006170749664306641, template `Ignored failure: java.io.IOException: Failed to send RPC <*> to mesos-slave-05/10.<*>: java.nio.channels.ClosedChannelException`
========================================================================================


Iteration 282
Sample 3 from current logs bucket: ID: 222, Len: 22, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Attempted to get executor loss reason for executor id 8 at RPC address mesos-master-1:58336, but got no response. Marking as slave lost.`
	============ Response ====================
LogTemplate[1]: `Attempted to get executor loss reason for executor id {executor_id} at RPC address {rpc_address}, but got no response. Marking as slave lost.`
	============ PostProcess ====================
	Post Template: `Attempted to get executor loss reason for executor id <*> at RPC address <*> but got no response. Marking as slave lost.`
	============ Aggregate ====================
	Aggregated Template:  Attempted to get executor loss reason for executor id <*> at RPC address <*> but got no response. Marking as slave lost.
[UpdateBucket] Logs: This iter found: 1, total: 16075109/16075117, remain: 8. 
[UpdateBucket] Buckets: Checked 1 ([222]), Parent Bucket size: 1 -> 0, remain buckets: 8
Update Success: Time for one update logs: 0.004194021224975586, template `Attempted to get executor loss reason for executor id <*> at RPC address <*> but got no response. Marking as slave lost.`
========================================================================================


Iteration 283
Sample 3 from current logs bucket: ID: 223, Len: 23, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 11, 14, 30, 40, 52, 67, 71, 75, 77, 79`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_id} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075110/16075117, remain: 7. 
[UpdateBucket] Buckets: Checked 1 ([223]), Parent Bucket size: 1 -> 0, remain buckets: 7
Update Success: Time for one update logs: 0.002257823944091797, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 284
Sample 3 from current logs bucket: ID: 226, Len: 25, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote=mesos-master-1/10.10.34.11:8030]. 20000 millis timeout left.; Host Details : local host is: "mesos-slave-08/10.10.34.18"; destination host is: "mesos-master-1":8030;`
	============ Response ====================
LogTemplate[1]: `java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote={hostname}/{ip_address}:{port}]. {timeout} millis timeout left.; Host Details : local host is: "{local_host}/{local_ip}"; destination host is: "{dest_host}":{dest_port};`
	============ PostProcess ====================
	Post Template: `java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote=<*>]. <*> millis timeout left.; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
	============ Aggregate ====================
	Aggregated Template:  java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote=<*>]. <*> millis timeout left.; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;
[UpdateBucket] Logs: This iter found: 1, total: 16075111/16075117, remain: 6. 
[UpdateBucket] Buckets: Checked 2 ([225, 226]), Parent Bucket size: 1 -> 0, remain buckets: 6
Update Success: Time for one update logs: 0.0078887939453125, template `java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote=<*>]. <*> millis timeout left.; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
========================================================================================


Iteration 285
Sample 3 from current logs bucket: ID: 227, Len: 26, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 6, 8, 9, 10, 11, 12, 33, 34, 35, 36, 37, 38, 73`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_id} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075112/16075117, remain: 5. 
[UpdateBucket] Buckets: Checked 1 ([227]), Parent Bucket size: 1 -> 0, remain buckets: 5
Update Success: Time for one update logs: 0.005204916000366211, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 286
Sample 3 from current logs bucket: ID: 228, Len: 27, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 9 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 3, 5, 6, 7, 16, 29, 31, 34, 35, 36, 43, 54, 57`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_id} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075113/16075117, remain: 4. 
[UpdateBucket] Buckets: Checked 1 ([228]), Parent Bucket size: 1 -> 0, remain buckets: 4
Update Success: Time for one update logs: 0.003278970718383789, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 287
Sample 3 from current logs bucket: ID: 229, Len: 28, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 4, 9, 14, 19, 24, 29, 65, 67, 68, 69, 70, 71, 75, 76, 77`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075114/16075117, remain: 3. 
[UpdateBucket] Buckets: Checked 1 ([229]), Parent Bucket size: 1 -> 0, remain buckets: 3
Update Success: Time for one update logs: 0.003818035125732422, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 288
Sample 3 from current logs bucket: ID: 230, Len: 30, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 6, 11, 16, 21, 26, 30, 31, 32, 39, 40, 41, 42, 51, 52, 60, 79`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} ({operation} at {file}:{line_num}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075115/16075117, remain: 2. 
[UpdateBucket] Buckets: Checked 1 ([230]), Parent Bucket size: 1 -> 0, remain buckets: 2
Update Success: Time for one update logs: 0.003632068634033203, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 289
Sample 3 from current logs bucket: ID: 233, Len: 35, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 6 (reduceByKey at pnmf_dblp.py:418) because some of its tasks had failed: 1, 6, 11, 16, 21, 26, 49, 50, 51, 52, 53, 54, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} ({operation} at {file}:{line}) because some of its tasks had failed: {task_ids}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075116/16075117, remain: 1. 
[UpdateBucket] Buckets: Checked 1 ([233]), Parent Bucket size: 1 -> 0, remain buckets: 1
Update Success: Time for one update logs: 0.004889011383056641, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Iteration 290
Sample 3 from current logs bucket: ID: 237, Len: 51, Bucket Size: 1, Total Buckets: 239
	============  Query  ====================
	Log[1]: `Resubmitting ShuffleMapStage 10 (reduceByKey at pnmf_dblp.py:423) because some of its tasks had failed: 1, 2, 5, 6, 9, 10, 13, 14, 17, 18, 21, 22, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 54, 56, 57, 66, 67`
	============ Response ====================
LogTemplate[1]: `Resubmitting ShuffleMapStage {stage_num} ({action} at {file}:{line}) because some of its tasks had failed: {task_list}`
	============ PostProcess ====================
	Post Template: `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
	============ Aggregate ====================
	Aggregated Template:  Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>
[UpdateBucket] Logs: This iter found: 1, total: 16075117/16075117, remain: 0. 
[UpdateBucket] Buckets: Checked 1 ([237]), Parent Bucket size: 1 -> 0, remain buckets: 0
Update Success: Time for one update logs: 0.0035309791564941406, template `Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>`
========================================================================================


Original df_logs: (16075117, 4), Clustering df_logs: (16075117, 6)
Saved Spark_log_structured.csv to ./saved_results/LUNAR-single/Spark/Spark_full.log_structured.csv
Saved Spark_log_templates.csv to ./saved_results/LUNAR-single/Spark/Spark_full.log_templates.csv
Total parsingg time: 2148.9360699653625 seconds
Total query time: 420.4280517101288 seconds, 310 queries
Avg. query time: 1.3562194778965615 seconds
Total pure match time: 1728.5080182552338 seconds

=== Evaluation on Spark ===
Evaluate parsing result: ./saved_results/LUNAR-single/Spark/Spark_full.log_structured.csv
Start compute grouping accuracy
  0%|          | 0/236 [00:00<?, ?it/s]  0%|          | 1/236 [00:00<02:16,  1.72it/s]  1%|          | 2/236 [00:00<01:45,  2.21it/s]  1%|         | 3/236 [00:01<01:34,  2.47it/s]  2%|         | 4/236 [00:01<01:26,  2.69it/s]  2%|         | 5/236 [00:01<01:21,  2.83it/s]  3%|         | 6/236 [00:02<01:19,  2.89it/s]  3%|         | 7/236 [00:02<01:17,  2.95it/s]  3%|         | 8/236 [00:02<01:15,  3.01it/s]  4%|         | 9/236 [00:03<01:14,  3.05it/s]  4%|         | 10/236 [00:03<01:13,  3.06it/s]  5%|         | 11/236 [00:03<01:14,  3.01it/s]  5%|         | 12/236 [00:04<01:13,  3.05it/s]  6%|         | 13/236 [00:04<01:12,  3.06it/s]  6%|         | 14/236 [00:04<01:12,  3.08it/s]  6%|         | 15/236 [00:05<01:11,  3.09it/s]  7%|         | 16/236 [00:05<01:10,  3.11it/s]  7%|         | 17/236 [00:05<01:14,  2.95it/s]  8%|         | 18/236 [00:06<01:14,  2.93it/s]  8%|         | 19/236 [00:06<01:13,  2.94it/s]  8%|         | 20/236 [00:06<01:14,  2.91it/s]  9%|         | 21/236 [00:07<01:12,  2.96it/s]  9%|         | 22/236 [00:07<01:11,  3.00it/s] 10%|         | 23/236 [00:07<01:10,  3.04it/s] 10%|         | 24/236 [00:08<01:09,  3.06it/s] 11%|         | 25/236 [00:08<01:08,  3.08it/s] 11%|         | 26/236 [00:08<01:08,  3.06it/s] 11%|        | 27/236 [00:09<01:07,  3.08it/s] 12%|        | 28/236 [00:09<01:07,  3.10it/s] 12%|        | 29/236 [00:09<01:06,  3.11it/s] 13%|        | 30/236 [00:10<01:06,  3.11it/s] 13%|        | 31/236 [00:10<01:05,  3.12it/s] 14%|        | 32/236 [00:10<01:05,  3.12it/s] 14%|        | 33/236 [00:11<01:05,  3.12it/s] 14%|        | 34/236 [00:11<01:04,  3.12it/s] 15%|        | 35/236 [00:11<01:04,  3.12it/s] 15%|        | 36/236 [00:12<01:04,  3.12it/s] 16%|        | 37/236 [00:12<01:04,  3.09it/s] 16%|        | 38/236 [00:12<01:03,  3.10it/s] 17%|        | 39/236 [00:13<01:03,  3.11it/s] 17%|        | 40/236 [00:13<01:02,  3.11it/s] 17%|        | 41/236 [00:13<01:03,  3.08it/s] 18%|        | 42/236 [00:13<01:02,  3.10it/s] 18%|        | 43/236 [00:14<01:02,  3.11it/s] 19%|        | 44/236 [00:14<01:01,  3.11it/s] 19%|        | 45/236 [00:14<01:01,  3.11it/s] 19%|        | 46/236 [00:15<01:01,  3.11it/s] 20%|        | 47/236 [00:15<01:00,  3.12it/s] 20%|        | 48/236 [00:15<01:00,  3.09it/s] 21%|        | 49/236 [00:16<01:00,  3.09it/s] 21%|        | 50/236 [00:16<01:00,  3.10it/s] 22%|       | 52/236 [00:16<00:45,  4.03it/s] 22%|       | 53/236 [00:17<00:48,  3.76it/s] 23%|       | 54/236 [00:17<00:51,  3.57it/s] 23%|       | 55/236 [00:17<00:52,  3.44it/s] 24%|       | 56/236 [00:18<00:53,  3.35it/s] 24%|       | 57/236 [00:18<00:54,  3.28it/s] 25%|       | 58/236 [00:18<00:55,  3.23it/s] 25%|       | 59/236 [00:19<00:55,  3.20it/s] 25%|       | 60/236 [00:19<00:55,  3.18it/s] 26%|       | 61/236 [00:19<00:55,  3.17it/s] 26%|       | 62/236 [00:20<00:55,  3.16it/s] 27%|       | 63/236 [00:20<00:54,  3.15it/s] 27%|       | 64/236 [00:20<00:54,  3.14it/s] 28%|       | 65/236 [00:21<00:54,  3.14it/s] 28%|       | 66/236 [00:21<00:54,  3.13it/s] 28%|       | 67/236 [00:21<00:53,  3.13it/s] 29%|       | 68/236 [00:22<00:53,  3.13it/s] 29%|       | 69/236 [00:22<00:53,  3.12it/s] 30%|       | 70/236 [00:22<00:53,  3.13it/s] 30%|       | 71/236 [00:22<00:52,  3.12it/s] 31%|       | 73/236 [00:23<00:40,  4.06it/s] 31%|      | 74/236 [00:23<00:44,  3.68it/s] 32%|      | 76/236 [00:23<00:36,  4.44it/s] 33%|      | 77/236 [00:24<00:39,  4.05it/s] 33%|      | 78/236 [00:24<00:46,  3.38it/s] 33%|      | 79/236 [00:25<00:47,  3.30it/s] 34%|      | 80/236 [00:25<00:47,  3.26it/s] 34%|      | 81/236 [00:25<00:52,  2.98it/s] 35%|      | 82/236 [00:26<00:51,  3.01it/s] 35%|      | 83/236 [00:26<00:50,  3.00it/s] 36%|      | 84/236 [00:26<00:55,  2.75it/s] 36%|      | 85/236 [00:27<00:52,  2.85it/s] 36%|      | 86/236 [00:27<00:51,  2.93it/s] 37%|      | 87/236 [00:27<00:50,  2.98it/s] 37%|      | 88/236 [00:28<00:49,  3.02it/s] 38%|      | 89/236 [00:28<00:48,  3.05it/s] 38%|      | 90/236 [00:28<00:47,  3.07it/s] 39%|      | 91/236 [00:29<00:47,  3.08it/s] 39%|      | 92/236 [00:29<00:46,  3.10it/s] 39%|      | 93/236 [00:29<00:46,  3.10it/s] 40%|      | 94/236 [00:30<00:45,  3.11it/s] 40%|      | 95/236 [00:30<00:45,  3.08it/s] 41%|      | 96/236 [00:30<00:45,  3.09it/s] 41%|      | 97/236 [00:31<00:45,  3.09it/s] 42%|     | 99/236 [00:31<00:34,  4.03it/s] 42%|     | 100/236 [00:31<00:36,  3.76it/s] 43%|     | 101/236 [00:32<00:37,  3.57it/s] 43%|     | 102/236 [00:32<00:39,  3.40it/s] 44%|     | 103/236 [00:32<00:41,  3.24it/s] 44%|     | 104/236 [00:33<00:41,  3.20it/s] 44%|     | 105/236 [00:33<00:41,  3.18it/s] 45%|     | 106/236 [00:33<00:41,  3.17it/s] 45%|     | 107/236 [00:33<00:40,  3.16it/s] 46%|     | 109/236 [00:34<00:31,  4.08it/s] 47%|     | 110/236 [00:34<00:33,  3.80it/s] 47%|     | 111/236 [00:34<00:34,  3.59it/s] 47%|     | 112/236 [00:35<00:35,  3.44it/s] 48%|     | 114/236 [00:35<00:28,  4.29it/s] 49%|     | 115/236 [00:35<00:30,  3.94it/s] 49%|     | 116/236 [00:36<00:32,  3.70it/s] 50%|     | 117/236 [00:36<00:33,  3.53it/s] 50%|     | 118/236 [00:36<00:34,  3.41it/s] 50%|     | 119/236 [00:37<00:35,  3.27it/s] 51%|     | 120/236 [00:37<00:35,  3.23it/s] 51%|    | 121/236 [00:37<00:35,  3.20it/s] 52%|    | 122/236 [00:38<00:35,  3.17it/s] 52%|    | 123/236 [00:38<00:35,  3.15it/s] 53%|    | 124/236 [00:38<00:35,  3.14it/s] 53%|    | 126/236 [00:39<00:27,  4.06it/s] 54%|    | 127/236 [00:39<00:28,  3.79it/s] 54%|    | 128/236 [00:39<00:30,  3.58it/s] 55%|    | 129/236 [00:40<00:31,  3.36it/s] 55%|    | 130/236 [00:40<00:32,  3.30it/s] 56%|    | 131/236 [00:40<00:32,  3.25it/s] 56%|    | 132/236 [00:41<00:32,  3.22it/s] 56%|    | 133/236 [00:41<00:32,  3.17it/s] 57%|    | 134/236 [00:41<00:32,  3.15it/s] 57%|    | 135/236 [00:42<00:32,  3.08it/s] 58%|    | 136/236 [00:42<00:32,  3.09it/s] 58%|    | 137/236 [00:42<00:31,  3.10it/s] 58%|    | 138/236 [00:43<00:31,  3.09it/s] 59%|    | 139/236 [00:43<00:31,  3.09it/s] 59%|    | 140/236 [00:43<00:30,  3.10it/s] 60%|    | 141/236 [00:43<00:30,  3.11it/s] 60%|    | 142/236 [00:44<00:30,  3.11it/s] 61%|    | 143/236 [00:44<00:29,  3.12it/s] 61%|    | 144/236 [00:44<00:29,  3.12it/s] 61%|   | 145/236 [00:45<00:29,  3.12it/s] 62%|   | 146/236 [00:45<00:28,  3.12it/s] 62%|   | 147/236 [00:45<00:28,  3.13it/s] 63%|   | 148/236 [00:46<00:28,  3.13it/s] 63%|   | 149/236 [00:46<00:27,  3.13it/s] 64%|   | 150/236 [00:46<00:27,  3.12it/s] 64%|   | 151/236 [00:47<00:27,  3.12it/s] 65%|   | 153/236 [00:47<00:20,  4.02it/s] 65%|   | 154/236 [00:47<00:21,  3.76it/s] 66%|   | 155/236 [00:48<00:22,  3.58it/s] 66%|   | 156/236 [00:48<00:23,  3.45it/s] 67%|   | 157/236 [00:48<00:23,  3.35it/s] 67%|   | 158/236 [00:49<00:23,  3.29it/s] 67%|   | 159/236 [00:49<00:23,  3.23it/s] 68%|   | 161/236 [00:49<00:18,  4.14it/s] 69%|   | 162/236 [00:50<00:19,  3.83it/s] 69%|   | 163/236 [00:50<00:20,  3.63it/s] 69%|   | 164/236 [00:50<00:20,  3.48it/s] 70%|   | 165/236 [00:51<00:21,  3.37it/s] 70%|   | 166/236 [00:51<00:21,  3.29it/s] 71%|   | 167/236 [00:51<00:21,  3.24it/s] 71%|   | 168/236 [00:52<00:23,  2.89it/s] 72%|  | 169/236 [00:52<00:23,  2.89it/s] 72%|  | 170/236 [00:52<00:22,  2.96it/s] 72%|  | 171/236 [00:53<00:21,  3.01it/s] 73%|  | 172/236 [00:53<00:21,  3.00it/s] 73%|  | 173/236 [00:53<00:20,  3.04it/s] 74%|  | 174/236 [00:54<00:20,  3.07it/s] 75%|  | 176/236 [00:54<00:14,  4.01it/s] 75%|  | 177/236 [00:54<00:15,  3.75it/s] 75%|  | 178/236 [00:55<00:16,  3.57it/s] 76%|  | 179/236 [00:55<00:16,  3.44it/s] 76%|  | 180/236 [00:55<00:16,  3.33it/s] 77%|  | 181/236 [00:55<00:16,  3.27it/s] 77%|  | 182/236 [00:56<00:16,  3.22it/s] 78%|  | 183/236 [00:56<00:16,  3.17it/s] 78%|  | 184/236 [00:56<00:16,  3.11it/s] 78%|  | 185/236 [00:57<00:16,  3.12it/s] 79%|  | 186/236 [00:57<00:16,  3.12it/s] 79%|  | 187/236 [00:57<00:15,  3.12it/s] 80%|  | 188/236 [00:58<00:15,  3.06it/s] 80%|  | 189/236 [00:58<00:15,  3.08it/s] 81%|  | 190/236 [00:58<00:14,  3.08it/s] 81%|  | 191/236 [00:59<00:14,  3.09it/s] 81%| | 192/236 [00:59<00:14,  3.10it/s] 82%| | 193/236 [00:59<00:13,  3.11it/s] 82%| | 194/236 [01:00<00:13,  3.11it/s] 83%| | 196/236 [01:00<00:09,  4.05it/s] 83%| | 197/236 [01:00<00:10,  3.74it/s] 84%| | 198/236 [01:01<00:10,  3.56it/s] 85%| | 200/236 [01:01<00:08,  4.37it/s] 85%| | 201/236 [01:01<00:08,  3.99it/s] 86%| | 202/236 [01:02<00:09,  3.73it/s] 86%| | 203/236 [01:02<00:09,  3.55it/s] 86%| | 204/236 [01:02<00:09,  3.42it/s] 87%| | 205/236 [01:03<00:09,  3.34it/s] 87%| | 206/236 [01:03<00:09,  3.27it/s] 88%| | 207/236 [01:03<00:10,  2.85it/s] 88%| | 208/236 [01:04<00:09,  2.93it/s] 89%| | 209/236 [01:04<00:09,  2.93it/s] 89%| | 210/236 [01:04<00:08,  2.99it/s] 89%| | 211/236 [01:05<00:08,  3.02it/s] 90%| | 212/236 [01:05<00:07,  3.06it/s] 90%| | 213/236 [01:05<00:07,  3.04it/s] 91%| | 214/236 [01:06<00:07,  3.06it/s] 92%|| 216/236 [01:06<00:04,  4.00it/s] 92%|| 217/236 [01:06<00:05,  3.70it/s] 92%|| 218/236 [01:07<00:05,  3.53it/s] 93%|| 219/236 [01:07<00:04,  3.41it/s] 93%|| 220/236 [01:07<00:04,  3.32it/s] 94%|| 221/236 [01:08<00:04,  3.27it/s] 94%|| 222/236 [01:08<00:04,  3.23it/s] 94%|| 223/236 [01:08<00:04,  3.20it/s] 95%|| 224/236 [01:09<00:03,  3.14it/s] 95%|| 225/236 [01:09<00:03,  3.14it/s] 96%|| 226/236 [01:09<00:03,  3.14it/s] 96%|| 227/236 [01:09<00:02,  3.12it/s] 97%|| 228/236 [01:10<00:02,  3.12it/s] 97%|| 229/236 [01:10<00:02,  3.12it/s] 97%|| 230/236 [01:10<00:01,  3.13it/s] 98%|| 231/236 [01:11<00:01,  3.13it/s] 98%|| 232/236 [01:11<00:01,  3.13it/s] 99%|| 233/236 [01:11<00:00,  3.12it/s] 99%|| 234/236 [01:12<00:00,  3.12it/s]100%|| 236/236 [01:12<00:00,  4.06it/s]100%|| 236/236 [01:12<00:00,  3.25it/s]
Grouping_Accuracy (GA): 0.9739, FGA: 0.8798,
Grouping Accuracy calculation done. [Time taken: 84.791]
Parsing_Accuracy (PA): 0.9964
Parsing Accuracy calculation done. [Time taken: 1.134]
  0%|          | 0/255 [00:00<?, ?it/s]  0%|          | 1/255 [00:00<02:18,  1.84it/s]  7%|         | 18/255 [00:00<00:06, 35.09it/s] 33%|      | 85/255 [00:00<00:01, 139.98it/s] 41%|      | 104/255 [00:01<00:01, 112.76it/s] 64%|   | 162/255 [00:01<00:00, 195.40it/s] 75%|  | 192/255 [00:01<00:00, 190.42it/s] 87%| | 222/255 [00:01<00:00, 178.10it/s]100%|| 255/255 [00:01<00:00, 157.78it/s]
1-num-15, {"'<*> and <*>'"} | {"'NoneType' and <*>'"}
2-num-2, {"'<*> and <*>'"} | {"'float' and 'NoneType'"}
3-num-1, {'java.io.IOException: Broken pipe'} | {'<*>: Broken pipe'}
4-num-60, {'Abandoning <*>'} | {'Abandoning BP-<*>'}
5-num-78, {'Add WebUI Filter. AddWebUIFilter(<*>,Map(PROXY_HOSTS -> <*> PROXY_URI_BASES -> <*>),<*>)'} | {'Add WebUI Filter. AddWebUIFilter(org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter,Map(PROXY_HOSTS -> mesos-master-<*>, PROXY_URI_BASES -> http://mesos-master-<*>:8088/proxy/application_<*>),/proxy/application_<*>)'}
6-num-1886, {'An unknown (<*>) driver disconnected.'} | {'An unknown <*> driver disconnected.'}
7-num-64, {'ApplicationMaster registered as NettyRpcEndpointRef(spark://<*>)'} | {'ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@<*>)'}
8-num-4963, {'Changing modify acls to: <*>'} | {'Changing modify acls to: yarn,<*>'}
9-num-4963, {'Changing view acls to: <*>'} | {'Changing view acls to: yarn,<*>'}
10-num-142, {'Connecting to ResourceManager at <*>'} | {'Connecting to ResourceManager at mesos-master-1/<*>'}
11-num-2268, {'Connecting to driver: spark://<*>'} | {'Connecting to driver: spark://CoarseGrainedScheduler@<*>'}
12-num-378, {'Container killed by YARN for exceeding memory limits. <*> of <*> virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.'} | {'Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.'}
13-num-107, {'Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container expired since it was unused'} | {'Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: -<*>. Diagnostics: Container expired since it was unused'}
14-num-2623, {'Container request (host: <*> capability: <memory:<*>, vCores:<*>)'} | {'Container request (host: Any, capability: <memory:<*>, vCores:<*>)'}
15-num-64, {'Created broadcast <*> from textFile at <*>'} | {'Created broadcast <*> from textFile at NativeMethodAccessorImpl.java:-<*>'}
16-num-2353, {'Created local directory at <*>'} | {'Created local directory at /opt/hdfs/nodemanager/usercache/<*>'}
17-num-777, {'Deleting directory <*>'} | {'Deleting directory /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/spark-<*>'}
18-num-115, {'Deleting staging directory <*>'} | {'Deleting staging directory .sparkStaging/application_<*>'}
19-num-2682, {'Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://<*>)'} | {'Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@<*>)'}
20-num-244, {'Error sending message [message = <*>] in <*> attempts'} | {'Error sending message [message = Heartbeat(<*>,[Lscala.Tuple2;@<*>,BlockManagerId(<*>, mesos-<*>, <*>))] in <*> attempts'}
21-num-34, {'Error sending message [message = <*>] in <*> attempts'} | {'Error sending message [message = UpdateBlockInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>)] in <*> attempts'}
22-num-22, {'Error sending result ChunkFetchSuccess{streamChunkId=<*>, buffer=<*>} to <*>; closing connection'} | {'Error sending result <*> buffer=<*>} to /<*>; closing connection'}
23-num-43, {'Error sending result RpcResponse{requestId=<*>, body=<*>} to <*>; closing connection'} | {'Error sending result <*>} to <*>; closing connection'}
24-num-8, {'Exception while deleting local spark dir: <*>'} | {'Exception while deleting local spark dir: /opt/hdfs/nodemanager/usercache/curi/appcache/application_<*>/blockmgr-<*>'}
25-num-8, {'Failed to remove broadcast <*> with removeFromMaster = <*> - Cannot receive any reply in <*> seconds. This timeout is controlled by <*>'} | {'Failed to remove broadcast <*> with removeFromMaster = true - Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout'}
26-num-2, {'Failed to remove broadcast <*> with removeFromMaster = <*> - Connection reset by peer'} | {'Failed to remove broadcast <*> with removeFromMaster = true - Connection reset by peer'}
27-num-1, {'Failed to send RPC <*> to <*>: <*>'} | {'Failed to send RPC <*> to <*>: java.io.IOException: Broken pipe'}
28-num-126, {'Failed to send RPC <*> to <*>: <*>'} | {'Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException'}
29-num-4, {'Final app status: <*> exitCode: <*> (reason: <*>)'} | {'Final app status: FAILED, exitCode: <*> (reason: Max number of executor failures (<*> reached)'}
30-num-1, {'Final app status: <*> exitCode: <*> (reason: <*>)'} | {'Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: <*>)'}
31-num-3, {'Final app status: <*> exitCode: <*> (reason: <*>)'} | {'Final app status: FAILED, exitCode: <*> (reason: Uncaught exception: org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply in <*> seconds. This timeout is controlled by spark.rpc.askTimeout)'}
32-num-57, {'Final app status: <*> exitCode: <*> (reason: <*>)'} | {'Final app status: FAILED, exitCode: <*> (reason: User application exited with status <*>)'}
33-num-2, {'Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> > <*>), dropping it.'} | {'Finished task <*> in stage <*> (TID <*>). Result is larger than maxResultSize (<*> MB > <*> MB), dropping it.'}
34-num-2610, {'Found inactive connection to <*> creating a new one.'} | {'Found inactive connection to mesos-<*>, creating a new one.'}
35-num-15, {'Ignored failure: java.io.IOException: Connection from <*> closed'} | {'Ignored failure: java.io.IOException: Connection from mesos-master-1/<*> closed'}
36-num-1, {'Ignored failure: java.io.IOException: Failed to send RPC <*> to <*>: java.nio.channels.ClosedChannelException'} | {'Ignored failure: java.io.IOException: Failed to send RPC <*> to mesos-slave-05/10.<*>: java.nio.channels.ClosedChannelException'}
37-num-4, {'Job <*> failed: count at <*> took <*> s'} | {'Job <*> failed: count at <*> s'}
38-num-11, {'Job <*> failed: count at <*> took <*> s'} | {'Job <*> failed: count at pnmf4.py:<*>, took <*> s'}
39-num-2561, {'Launching ExecutorRunnable. driverUrl: <*> executorHostname: <*>'} | {'Launching ExecutorRunnable. driverUrl: spark://CoarseGrainedScheduler@<*>, executorHostname: <*>'}
40-num-2561, {'Launching container <*> for on host <*>'} | {'Launching container <*> for on host mesos-<*>'}
41-num-189, {'Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> of <*> virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.'} | {'Lost executor <*> on <*>: Container killed by YARN for exceeding memory limits. <*> GB of <*> GB virtual memory used. Consider boosting spark.yarn.executor.memoryOverhead.'}
42-num-3, {'Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: <*> Exit code is <*>'} | {'Lost executor <*> on <*>: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>'}
43-num-1, {'Lost executor <*> on <*>: Slave lost'} | {'Lost executor <*> on mesos-master-<*>: Slave lost'}
44-num-14, {'Lost task <*> in stage <*> (TID <*> <*>): TaskKilled (killed intentionally)'} | {'Lost task <*> in stage <*> (TID <*> <*>): <*>'}
45-num-1590, {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by <*> for exceeding memory limits. <*> of <*> memory used. Consider boosting <*>.'} | {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> memory used. Consider boosting spark.yarn.executor.memoryOverhead.'}
46-num-4, {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: <*>.'} | {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: Exception from container-launch.'}
47-num-108, {'Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program <*>: error=<*>, No such file or directory'} | {'Lost task <*> in stage <*> (TID <*> <*>): java.io.IOException: Cannot run program "<*>": error=<*>, No such file or directory'}
48-num-140, {'Lost task <*> in stage <*> (TID <*> <*>): FetchFailed(<*>, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message=<*>'} | {'Lost task <*> in stage <*> (TID <*> mesos-<*>): FetchFailed(null, shuffleId=<*>, mapId=-<*>, reduceId=<*>, message='}
49-num-35, {'Lost task <*> in stage <*> (TID <*> <*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):'} | {'Lost task <*> in stage <*> (TID <*> mesos-<*>): org.apache.spark.api.python.PythonException: Traceback (most recent call last):'}
50-num-389, {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by <*> for exceeding memory limits. <*> of <*> memory used. Consider boosting <*>.'} | {'Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. <*> of <*> physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.'}
51-num-2, {'Lost task <*> in stage <*> (TID <*> <*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: <*> Exit status: <*> Diagnostics: <*> Exit code is <*>'} | {'Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): ExecutorLostFailure (executor <*> exited caused by one of the running tasks) Reason: Container marked as failed: <*> on host: mesos-slave-<*>. Exit status: <*> Diagnostics: Container killed on request. Exit code is <*>'}
52-num-178, {'Lost task <*> in stage <*> (TID <*> <*>): TaskKilled (killed intentionally)'} | {'Lost task <*> in stage <*> (TID <*> mesos-slave-<*>): TaskKilled (killed intentionally)'}
53-num-23, {'Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (<*> at <*>)'} | {'Marking ResultStage <*> (collect at <*>) as failed due to a fetch failure from ShuffleMapStage <*> (reduceByKey at <*>)'}
54-num-330, {'Missing parents: List(<*>)'} | {'Missing parents: List()'}
55-num-138, {'Missing parents: List(<*>)'} | {'Missing parents: List(ShuffleMapStage <*>)'}
56-num-2561, {'Prepared Local resources Map(__spark__.jar -> resource { scheme: <*> host: <*> port: <*> file: <*> } size: <*> timestamp: <*> type: <*> visibility: <*> pyspark.zip -> resource { scheme: <*> host: <*> port: <*> file: <*> } size: <*> timestamp: <*> type: <*> visibility: <*> py4j-<*>-src.zip -> resource { scheme: <*> host: <*> port: <*> file: <*> } size: <*> timestamp: <*> type: <*> visibility: <*>)'} | {'Prepared Local resources Map(__spark__.jar -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, pyspark.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE, py4j-<*>-src.zip -> resource <*>" port: <*> file: <*> } size: <*> timestamp: <*> type: FILE visibility: PRIVATE)'}
57-num-693, {'Registered executor NettyRpcEndpointRef(<*>) (<*>) with ID <*>'} | {'Registered executor NettyRpcEndpointRef(null) (<*>) with ID <*>'}
58-num-2606, {'Registered signal handlers for <*>'} | {'Registered signal handlers for [TERM, HUP, INT]'}
59-num-763, {'Registering block manager <*> with <*> RAM, BlockManagerId(driver, <*> <*>)', 'Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)'} | {'Registering block manager <*> with <*> RAM, BlockManagerId(<*>, <*> <*>)'}
60-num-142, {'Registering the ApplicationMaster'} | {'Registering the <*>'}
61-num-2378, {'Remoting started; listening on addresses :[<*>]'} | {'Remoting started; listening on addresses :[akka.tcp://<*>]'}
62-num-291, {'Removing RDD <*>'} | {'Removing RDD <*> from persistence list'}
63-num-324, {'Removing block manager BlockManagerId(<*>, <*> <*>)'} | {'Removing block manager BlockManagerId(<*>, mesos-<*>, <*>)'}
64-num-9, {'Resubmitting ShuffleMapStage <*> (reduceByKey at <*>) because some of its tasks had failed: <*>'} | {'Resubmitting ShuffleMapStage <*> (<*> at <*>) because some of its tasks had failed: <*>'}
65-num-25, {'Resubmitting ShuffleMapStage <*> (reduceByKey at <*>) and ResultStage <*> (collect at <*>) due to fetch failure'} | {'Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) and ResultStage <*> (collect at pnmf4.py:<*>) due to fetch failure'}
66-num-13, {'Resubmitting ShuffleMapStage <*> (reduceByKey at <*>) because some of its tasks had failed: <*>'} | {'Resubmitting ShuffleMapStage <*> (reduceByKey at pnmf4.py:<*>) because some of its tasks had failed: <*>'}
67-num-39, {'ResultStage <*> (collect at <*>) failed in <*> s', 'ResultStage <*> (count at <*>) failed in <*> s'} | {'ResultStage <*> (<*> at <*>) failed in <*> s'}
68-num-20, {'Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>'} | {'Retrying connect to server: mesos-master-1/<*>. Already tried <*> time(s); maxRetries=<*>'}
69-num-4963, {'SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(<*>, <*>); users with modify permissions: Set(<*>, <*>)'} | {'SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, <*>); users with modify permissions: Set(yarn, <*>)'}
70-num-58, {'ShuffleMapStage <*> (<*> at <*>) finished in <*> s'} | {'ShuffleMapStage <*> (<*> at IPLoM.py:<*>) finished in <*> s'}
71-num-38, {'ShuffleMapStage <*> (<*> at <*>) failed in <*> s'} | {'ShuffleMapStage <*> (reduceByKey at <*>) failed in <*> s'}
72-num-146, {'ShuffleMapStage <*> (<*> at <*>) finished in <*> s'} | {'ShuffleMapStage <*> (reduceByKey at <*>.py:<*>) finished in <*> s'}
73-num-164, {'ShuffleMapStage <*> is now unavailable on executor <*> (<*>, <*>)'} | {'ShuffleMapStage <*> is now unavailable on executor <*> (<*>, false)'}
74-num-10, {'SparkListenerBus has already stopped! Dropping event <*>'} | {'SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(<*>, <*> <*>),<*>,StorageLevel(<*>, <*> <*>),<*>))'}
75-num-64, {'Started SparkUI at <*>'} | {'Started SparkUI at http://<*>'}
76-num-2931, {'Starting task <*> in stage <*> (TID <*> partition <*>, <*> bytes)'} | {'Starting task <*> in stage <*> (TID <*> mesos-master-<*>, partition <*>, <*> bytes)'}
77-num-64, {'Stopped Spark web UI at <*>'} | {'Stopped Spark web UI at http://<*>'}
78-num-433, {'Submitting <*> missing tasks from ResultStage <*> (<*> at <*>)'} | {'Submitting <*> missing tasks from ResultStage <*> (<*> at <*> at <*>)'}
79-num-28, {'Submitting <*> missing tasks from ResultStage <*> (<*> at <*>)'} | {'Submitting <*> missing tasks from ResultStage <*> (<*>[<*>] at count at pnmf4.py:<*>)'}
80-num-10, {'Submitting <*> missing tasks from ResultStage <*> (<*> at <*>)'} | {'Submitting <*> missing tasks from ResultStage <*> (PythonRDD[<*>] at RDD at PythonRDD.scala:<*>)'}
81-num-471, {'Submitting ResultStage <*> (<*> at <*>), which has no missing parents'} | {'Submitting ResultStage <*> (<*>[<*>] at <*>), which has no missing parents'}
82-num-7, {'Uncaught exception in thread Thread[Executor task launch <*>]'} | {'Uncaught exception in thread Thread[Executor task launch worker-<*>,main]'}
83-num-1, {'Unregistering ApplicationMaster with <*>'} | {'Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (<*> reached)'}
84-num-3, {'Unregistering ApplicationMaster with <*>'} | {'Unregistering ApplicationMaster with FAILED (diag message: Uncaught exception: <*>: <*>)'}
85-num-30, {'Unregistering ApplicationMaster with <*>'} | {'Unregistering ApplicationMaster with FAILED (diag message: User application exited with status <*>)'}
86-num-21, {'Using REPL class URI: <*>'} | {'Using REPL class URI: http://<*>'}
87-num-3, {'[Container in shutdown] Uncaught exception in thread Thread[Executor task launch <*>]'} | {'[Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker-<*>,main]'}
88-num-84, {'ensureFreeSpace(<*>) called with curMem=<*>, maxMem=<*>'} | {'ensureFreeSpace(<*>) called with curMem=<*> maxMem=<*>'}
89-num-1, {'java.io.InterruptedIOException: Interrupted while waiting for IO on channel <*> millis timeout left.; Host Details : local host is: <*>; destination host is: <*>;'} | {'java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connection-pending remote=<*>]. <*> millis timeout left.; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;'}
90-num-2000, {'<*> is deprecated. Instead, use <*>'} | {'mapred.<*> is deprecated. Instead, use mapreduce.<*>'}
91-num-277, {'org.apache.spark.SparkException: Exception while starting container <*> on host <*>'} | {'org.apache.spark.SparkException: Exception while starting container <*> on host mesos-slave-<*>'}
92-num-1600, {'stopped o.s.j.s.ServletContextHandler{<*>}'} | {'stopped o.s.j.s.<*>'}
93-num-35, {'waiting: Set(ResultStage <*>)', 'waiting: Set(ShuffleMapStage <*> ResultStage <*>)'} | {'waiting: Set(<*>, <*>)'}
94-num-15, {'waiting: Set(ResultStage <*>)'} | {'waiting: Set(ResultStage <*> ShuffleMapStage <*> ShuffleMapStage <*>)'}
PTA: 0.6314, RTA: 0.6822 FTA: 0.6558
Identify : 255, Groundtruth : 236
Template-level accuracy calculation done. [Time taken: 10.180]
Finish parsing logs: Spark
Output dir: ./saved_results/LUNAR-single
