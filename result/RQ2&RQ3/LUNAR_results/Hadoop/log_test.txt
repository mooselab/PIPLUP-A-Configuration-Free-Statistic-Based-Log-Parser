Start to parse logs
[PARAM]: pad_query: False
[PARAM]: add_skip_sim: False
[PARAM]: cluster_method: TopKToken
[PARAM]: cluster_topk: 3
[PARAM]: sample_method: lcu_sampling
[PARAM]: lcu_sample_size: 3
[PARAM]: lcu_lamb: 0.6
Save dir: ./saved_results/LUNAR-single
Input dir: ././datasets/Hadoop
Output dir: ./saved_results/LUNAR-single/Hadoop
# Variable Examples: 
- `/var/www/html/xxx` -> `{directory}`
- `/var/lib/zookeeper/log.000000001` -> `{file}`
- `blk_-1234567832142354978` -> `{blk_id}`
- `com.huawei.health.manager.Service@32a6bf8` -> `{api}`
- `2017-07-02 15:46:40.536` -> `{time}`
- `192.168.0.1:8008` -> `{ip_or_url}`

======================== Prompt ========================
VarExam
# Basic Requirements:
- I will provide multiple log messages, each delimited by backticks.
- You must identify and extract all dynamic variables in each log with {placeholder} and output static log templates.
- Identify the semantics of variables and compare the differences between logs to identify potential dynamic variables if they belong to the same template.
- Preserve any dynamic variables already marked by `<*>` or `{placeholder}`.
- Pay attention to the slightly different strings among logs, which have high possibility to be dynamic variable.
- Do not convert non-variables, especially when only one log is presented in the group.
# Advices on variables:
- Common variables: numbers, IP addresses, URLs, file paths, directories, hex values, usernames, etc.
- Full directory with filename, complex url with server address or domain should be recognize as one variable.
# Advices on non-variables:
- Error messages/types, java exceptions, detailed commands or interrupted messages are NOT dynamic variables as they contain important information.
- Specific actions or status words are NOT dynamic variables.
# Variable Examples: 
- `/var/www/html/xxx` -> `{directory}`
- `/var/lib/zookeeper/log.000000001` -> `{file}`
- `blk_-1234567832142354978` -> `{blk_id}`
- `com.huawei.health.manager.Service@32a6bf8` -> `{api}`
- `2017-07-02 15:46:40.536` -> `{time}`
- `192.168.0.1:8008` -> `{ip_or_url}`
# Output Constraints: 
- For each log line, output corresponding log template starting with LogTemplate[idx], no other line break. 
- Each input log's template is delimited by backticks. 

======================== Prompt ========================
Parsing file: ././datasets/Hadoop/Hadoop_full.log_structured.csv
Clustering load data
Clustering add regex before preprocess
Clustering by log length: 29
Clustering by log length: [138, 3805, 13613, 25705, 5144, 7958, 67303, 23768, 14569, 5240, 1748, 687, 7475, 1376, 1050, 2, 3, 83, 11, 217, 1, 8, 54, 2, 9, 6, 12, 5, 1]
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 138/138/138 Logs. Last cluster logs: 138
--- Finished 2nd Level Clustering by top-3 tokens: 5 clusters, Total/Min/Max: 3805/309/906 Logs. Last cluster logs: 309
--- Finished 2nd Level Clustering by top-3 tokens: 6 clusters, Total/Min/Max: 13613/616/5339 Logs. Last cluster logs: 642
--- Finished 2nd Level Clustering by top-3 tokens: 37 clusters, Total/Min/Max: 25705/100/4708 Logs. Last cluster logs: 637
--- Finished 2nd Level Clustering by top-3 tokens: 11 clusters, Total/Min/Max: 5144/100/962 Logs. Last cluster logs: 647
--- Finished 2nd Level Clustering by top-3 tokens: 19 clusters, Total/Min/Max: 7958/100/978 Logs. Last cluster logs: 381
--- Finished 2nd Level Clustering by top-3 tokens: 137 clusters, Total/Min/Max: 67303/101/20205 Logs. Last cluster logs: 366
--- Finished 2nd Level Clustering by top-3 tokens: 9 clusters, Total/Min/Max: 23768/100/18140 Logs. Last cluster logs: 171
--- Finished 2nd Level Clustering by top-3 tokens: 9 clusters, Total/Min/Max: 14569/118/5339 Logs. Last cluster logs: 185
--- Finished 2nd Level Clustering by top-3 tokens: 5 clusters, Total/Min/Max: 5240/158/2517 Logs. Last cluster logs: 196
--- Finished 2nd Level Clustering by top-3 tokens: 4 clusters, Total/Min/Max: 1748/82/899 Logs. Last cluster logs: 82
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 687/158/529 Logs. Last cluster logs: 158
--- Finished 2nd Level Clustering by top-3 tokens: 5 clusters, Total/Min/Max: 7475/100/5300 Logs. Last cluster logs: 129
--- Finished 2nd Level Clustering by top-3 tokens: 3 clusters, Total/Min/Max: 1376/34/678 Logs. Last cluster logs: 34
--- Finished 2nd Level Clustering by top-3 tokens: 2 clusters, Total/Min/Max: 1050/2/1048 Logs. Last cluster logs: 2
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 2/2/2 Logs. Last cluster logs: 2
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 3/3/3 Logs. Last cluster logs: 3
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 83/83/83 Logs. Last cluster logs: 83
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 11/11/11 Logs. Last cluster logs: 11
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 217/217/217 Logs. Last cluster logs: 217
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 8/8/8 Logs. Last cluster logs: 8
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 54/54/54 Logs. Last cluster logs: 54
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 2/2/2 Logs. Last cluster logs: 2
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 9/9/9 Logs. Last cluster logs: 9
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 6/6/6 Logs. Last cluster logs: 6
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 12/12/12 Logs. Last cluster logs: 12
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 5/5/5 Logs. Last cluster logs: 5
--- Finished 2nd Level Clustering by top-3 tokens: 1 clusters, Total/Min/Max: 1/1/1 Logs. Last cluster logs: 1
Clustering (min_cluster_size=100) by length and 1st 3 tokens: 269 clusters
Clustering results: [138, 834, 906, 905, 851, 309, 978, 5339, 5204, 834, 616, 642, 977, 1140, 907, 122, 834, 834, 678, 140, 226, 138, 138, 138, 268, 1377, 1072, 373, 207, 606, 161, 296, 605, 701, 826, 216, 100, 302, 157, 275, 3416, 480, 246, 153, 4708, 626, 724, 901, 637, 644, 414, 962, 701, 141, 317, 100, 906, 122, 190, 647, 978, 909, 963, 834, 834, 834, 117, 105, 621, 186, 255, 182, 100, 204, 100, 101, 112, 142, 381, 905, 4579, 469, 138, 138, 796, 4843, 1278, 901, 2290, 140, 795, 255, 194, 198, 183, 121, 649, 357, 222, 227, 221, 199, 252, 196, 284, 193, 157, 1443, 152, 411, 1085, 136, 103, 223, 195, 224, 199, 191, 188, 171, 178, 172, 174, 220, 170, 151, 150, 183, 164, 210, 141, 141, 218, 143, 162, 143, 203, 197, 184, 177, 175, 175, 205, 187, 145, 178, 190, 171, 137, 157, 155, 101, 164, 151, 111, 145, 132, 123, 153, 134, 128, 103, 121, 125, 113, 147, 132, 132, 119, 284, 5795, 158, 111, 110, 134, 168, 144, 105, 113, 121, 109, 141, 160, 109, 133, 135, 123, 106, 153, 117, 128, 120, 103, 105, 357, 187, 362, 105, 176, 146, 164, 136, 119, 127, 387, 147, 148, 335, 273, 108, 125, 519, 120, 20205, 115, 366, 3841, 1033, 18140, 100, 105, 117, 104, 157, 171, 909, 5339, 5339, 138, 906, 902, 733, 118, 185, 625, 1744, 2517, 158, 196, 667, 899, 100, 82, 529, 158, 1742, 204, 5300, 100, 129, 678, 664, 34, 1048, 2, 2, 3, 83, 11, 217, 1, 8, 54, 2, 9, 6, 12, 5, 1]
Iteration 0
Sample 3 from current logs bucket: ID: 213, Len: 7, Bucket Size: 20205, Total Buckets: 269
Sampling from 16136 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Progress of TaskAttempt attempt_1445087491445_0005_m_000000_0 is : 0.12453667`, MaxSim Log: `Progress of TaskAttempt attempt_1445087491445_0005_m_000000_0 is : 0.12780756`.
	============  Query  ====================
	Log[1]: `Progress of TaskAttempt attempt_1445087491445_0005_m_000000_0 is : 0.12453667`
	Log[2]: `Progress of TaskAttempt attempt_1445182159119_0018_m_000000_1000 is : 0.06350645`
	Log[3]: `Progress of TaskAttempt attempt_1445144423722_0024_m_000000_0 is : 0.26158828`
	============ Response ====================
LogTemplate[1]: `Progress of TaskAttempt attempt_<*> is : <*>`
LogTemplate[2]: `Progress of TaskAttempt attempt_<*> is : <*>`
LogTemplate[3]: `Progress of TaskAttempt attempt_<*> is : <*>`
	============ PostProcess ====================
	Post Template: `Progress of TaskAttempt <*> is : <*>`
	Post Template: `Progress of TaskAttempt <*> is : <*>`
	Post Template: `Progress of TaskAttempt <*> is : <*>`
	============ Aggregate ====================
	Aggregated Template:  Progress of TaskAttempt <*> is : <*>
[UpdateBucket] Logs: This iter found: 45882, total: 45882/179993, remain: 134111. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 67303 -> 21421, remain buckets: 147
Update Success: Time for one update logs: 0.8794040679931641, template `Progress of TaskAttempt <*> is : <*>`
========================================================================================


Iteration 1
Sample 3 from current logs bucket: ID: 218, Len: 8, Bucket Size: 18140, Total Buckets: 269
Sampling from 489 logs, Sim Level: 2, MaxSim to anchor: 0.7778. Anchor: `MapCompletionEvents request from attempt_1445087491445_0005_r_000000_0. startIndex 0 maxEvents 10000`, MaxSim Log: `MapCompletionEvents request from attempt_1445087491445_0005_r_000000_0. startIndex 3 maxEvents 10000`.
	============  Query  ====================
	Log[1]: `MapCompletionEvents request from attempt_1445087491445_0005_r_000000_0. startIndex 0 maxEvents 10000`
	Log[2]: `MapCompletionEvents request from attempt_1445087491445_0001_r_000000_0. startIndex 10 maxEvents 10000`
	Log[3]: `MapCompletionEvents request from attempt_1445144423722_0020_r_000000_1000. startIndex 8 maxEvents 10000`
	============ Response ====================
LogTemplate[1]: `MapCompletionEvents request from attempt_<*>_r_<*>_<*>. startIndex <*> maxEvents 10000`
	============ PostProcess ====================
	Post Template: `MapCompletionEvents request from <*> startIndex <*> maxEvents <*>`
	Post Template: `MapCompletionEvents request from <*> startIndex <*> maxEvents <*>`
	Post Template: `MapCompletionEvents request from <*> startIndex <*> maxEvents <*>`
	============ Aggregate ====================
	Aggregated Template:  MapCompletionEvents request from <*> startIndex <*> maxEvents <*>
[UpdateBucket] Logs: This iter found: 18140, total: 64022/179993, remain: 115971. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 23768 -> 5628, remain buckets: 146
Update Success: Time for one update logs: 0.3657829761505127, template `MapCompletionEvents request from <*> startIndex <*> maxEvents <*>`
========================================================================================


Iteration 2
Sample 3 from current logs bucket: ID: 170, Len: 7, Bucket Size: 5795, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000`, MaxSim Log: `Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030`.
	============  Query  ====================
	Log[1]: `Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000`
	Log[2]: `Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030`
	============ Response ====================
LogTemplate[1]: `Address change detected. Old: msra-sa-41/{ip_or_url}:9000 New: msra-sa-41:9000`
LogTemplate[2]: `Address change detected. Old: msra-sa-41/{ip_or_url}:8030 New: msra-sa-41:8030`
	============ PostProcess ====================
	Post Template: `Address change detected. Old: msra-sa-41/<*> New: msra-sa-<*>`
	Post Template: `Address change detected. Old: msra-sa-41/<*> New: msra-sa-<*>`
	============ Aggregate ====================
	Aggregated Template:  Address change detected. Old: msra-sa-41/<*> New: msra-sa-<*>
[UpdateBucket] Logs: This iter found: 5795, total: 69817/179993, remain: 110176. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 21421 -> 15626, remain buckets: 145
Update Success: Time for one update logs: 0.21825098991394043, template `Address change detected. Old: msra-sa-41/<*> New: msra-sa-<*>`
========================================================================================


Iteration 3
Sample 3 from current logs bucket: ID: 7, Len: 3, Bucket Size: 5339, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Spilling map output`
	============ Response ====================
LogTemplate[1]: `Spilling map output`
	============ PostProcess ====================
	Post Template: `Spilling map output`
	============ Aggregate ====================
	Aggregated Template:  Spilling map output
[UpdateBucket] Logs: This iter found: 5339, total: 75156/179993, remain: 104837. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 13613 -> 8274, remain buckets: 144
Update Success: Time for one update logs: 0.055229902267456055, template `Spilling map output`
========================================================================================


Iteration 4
Sample 1 from current logs bucket: ID: 226, Len: 9, Bucket Size: 5339, Total Buckets: 269
Sampling from 236 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `bufstart = 0; bufend = 34171787; bufvoid = 104857600`, MaxSim Log: `bufstart = 0; bufend = 34173924; bufvoid = 104857600`.
	============  Query  ====================
	Log[1]: `bufstart = 0; bufend = 34171787; bufvoid = 104857600`
	Log[2]: `bufstart = 86554835; bufend = 19548620; bufvoid = 104857600`
	Log[3]: `bufstart = 19512771; bufend = 67736095; bufvoid = 104857600`
	============ Response ====================
LogTemplate[1]: `bufstart = {num1}; bufend = {num2}; bufvoid = 104857600`
LogTemplate[2]: `bufstart = {num1}; bufend = {num2}; bufvoid = 104857600`
LogTemplate[3]: `bufstart = {num1}; bufend = {num2}; bufvoid = 104857600`
	============ PostProcess ====================
	Post Template: `bufstart = <*>; bufend = <*>; bufvoid = <*>`
	Post Template: `bufstart = <*>; bufend = <*>; bufvoid = <*>`
	Post Template: `bufstart = <*>; bufend = <*>; bufvoid = <*>`
	============ Aggregate ====================
	Aggregated Template:  bufstart = <*>; bufend = <*>; bufvoid = <*>
[UpdateBucket] Logs: This iter found: 5339, total: 80495/179993, remain: 99498. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 14569 -> 9230, remain buckets: 143
Update Success: Time for one update logs: 0.14268279075622559, template `bufstart = <*>; bufend = <*>; bufvoid = <*>`
========================================================================================


Iteration 5
Sample 3 from current logs bucket: ID: 227, Len: 9, Bucket Size: 5339, Total Buckets: 269
Sampling from 236 logs, Sim Level: 2, MaxSim to anchor: 0.5556. Anchor: `kvstart = 26214396(104857584); kvend = 13785828(55143312); length = 12428569/6553600`, MaxSim Log: `kvstart = 26214396(104857584); kvend = 13786364(55145456); length = 12428033/6553600`.
	============  Query  ====================
	Log[1]: `kvstart = 26214396(104857584); kvend = 13785828(55143312); length = 12428569/6553600`
	Log[2]: `kvstart = 26214396(104857584); kvend = 13786460(55145840); length = 12427937/6553600`
	Log[3]: `kvstart = 26214396(104857584); kvend = 13786364(55145456); length = 12428033/6553600`
	============ Response ====================
LogTemplate[1]: `kvstart = {number}({number}); kvend = {number}({number}); length = {number}/{number}`
LogTemplate[2]: `kvstart = {number}({number}); kvend = {number}({number}); length = {number}/{number}`
LogTemplate[3]: `kvstart = {number}({number}); kvend = {number}({number}); length = {number}/{number}`
	============ PostProcess ====================
	Post Template: `kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>`
	Post Template: `kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>`
	Post Template: `kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>`
	============ Aggregate ====================
	Aggregated Template:  kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>
[UpdateBucket] Logs: This iter found: 5339, total: 85834/179993, remain: 94159. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 9230 -> 3891, remain buckets: 142
Update Success: Time for one update logs: 0.1362922191619873, template `kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>`
========================================================================================


Iteration 6
Sample 3 from current logs bucket: ID: 247, Len: 13, Bucket Size: 5300, Total Buckets: 269
Sampling from 5299 logs, Sim Level: 2, MaxSim to anchor: 0.8462. Anchor: `Failed to renew lease for [DFSClient_NONMAPREDUCE_483047941_1] for 46 seconds. Will retry shortly ...`, MaxSim Log: `Failed to renew lease for [DFSClient_NONMAPREDUCE_483047941_1] for 47 seconds. Will retry shortly ...`.
	============  Query  ====================
	Log[1]: `Failed to renew lease for [DFSClient_NONMAPREDUCE_483047941_1] for 46 seconds. Will retry shortly ...`
	Log[2]: `Failed to renew lease for [DFSClient_NONMAPREDUCE_-1547462655_1] for 1317 seconds. Will retry shortly ...`
	Log[3]: `Failed to renew lease for [DFSClient_NONMAPREDUCE_-274751412_1] for 1330 seconds. Will retry shortly ...`
	============ Response ====================
LogTemplate[1]: `Failed to renew lease for [DFSClient_NONMAPREDUCE_{dynamic}_1] for {seconds} seconds. Will retry shortly ...`
	============ PostProcess ====================
	Post Template: `Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...`
	Post Template: `Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...`
	Post Template: `Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...`
	============ Aggregate ====================
	Aggregated Template:  Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...
[UpdateBucket] Logs: This iter found: 5300, total: 91134/179993, remain: 88859. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 7475 -> 2175, remain buckets: 141
Update Success: Time for one update logs: 0.14589905738830566, template `Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...`
========================================================================================


Iteration 7
Sample 3 from current logs bucket: ID: 8, Len: 3, Bucket Size: 5204, Total Buckets: 269
Sampling from 7 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Finished spill 0`, MaxSim Log: `Finished spill 1`.
	============  Query  ====================
	Log[1]: `Finished spill 0`
	Log[2]: `Finished spill 1`
	Log[3]: `Finished spill 4`
	============ Response ====================
LogTemplate[1]: `Finished spill {number}`  
LogTemplate[2]: `Finished spill {number}`  
LogTemplate[3]: `Finished spill {number}`  
	============ PostProcess ====================
	Post Template: `Finished spill <*>`
	Post Template: `Finished spill <*>`
	Post Template: `Finished spill <*>`
	============ Aggregate ====================
	Aggregated Template:  Finished spill <*>
[UpdateBucket] Logs: This iter found: 5204, total: 96338/179993, remain: 83655. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 8274 -> 3070, remain buckets: 140
Update Success: Time for one update logs: 0.09852290153503418, template `Finished spill <*>`
========================================================================================


Iteration 8
Sample 3 from current logs bucket: ID: 85, Len: 7, Bucket Size: 4843, Total Buckets: 269
Sampling from 4842 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `attempt_1445087491445_0005_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED`, MaxSim Log: `attempt_1445087491445_0005_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED`
	Log[2]: `attempt_1445175094696_0003_m_000007_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Log[3]: `attempt_1445087491445_0002_m_000000_0 TaskAttempt Transitioned from NEW to SUCCEEDED`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_m_{task_id}_{attempt_id} TaskAttempt Transitioned from NEW to UNASSIGNED`
LogTemplate[2]: `attempt_{job_id}_m_{task_id}_{attempt_id} TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
LogTemplate[3]: `attempt_{job_id}_m_{task_id}_{attempt_id} TaskAttempt Transitioned from NEW to SUCCEEDED`
	============ PostProcess ====================
	Post Template: `<*> TaskAttempt Transitioned from NEW to UNASSIGNED`
	Post Template: `<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Post Template: `<*> TaskAttempt Transitioned from NEW to SUCCEEDED`
	============ Aggregate ====================
	Aggregated Template:  <*> TaskAttempt Transitioned from NEW to UNASSIGNED
[UpdateBucket] Logs: This iter found: 951, total: 97289/179993, remain: 82704. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 15626 -> 14675, remain buckets: 140
Update Success: Time for one update logs: 0.12633299827575684, template `<*> TaskAttempt Transitioned from NEW to UNASSIGNED`
========================================================================================


Iteration 9
Sample 3 from current logs bucket: ID: 44, Len: 4, Bucket Size: 4708, Total Buckets: 269
Sampling from 200 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `(EQUATOR) 44657541 kvi 11164380(44657520)`, MaxSim Log: `(EQUATOR) 89317210 kvi 22329296(89317184)`.
	============  Query  ====================
	Log[1]: `(EQUATOR) 44657541 kvi 11164380(44657520)`
	============ Response ====================
LogTemplate[1]: `(EQUATOR) {number} kvi {number}({number})`
	============ PostProcess ====================
	Post Template: `(EQUATOR) <*> kvi <*>(<*>)`
	============ Aggregate ====================
	Aggregated Template:  (EQUATOR) <*> kvi <*>(<*>)
[UpdateBucket] Logs: This iter found: 5542, total: 102831/179993, remain: 77162. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 25705 -> 20163, remain buckets: 138
Update Success: Time for one update logs: 0.16897296905517578, template `(EQUATOR) <*> kvi <*>(<*>)`
========================================================================================


Iteration 10
Sample 3 from current logs bucket: ID: 80, Len: 7, Bucket Size: 4579, Total Buckets: 269
Sampling from 208 logs, Sim Level: 1, MaxSim to anchor: 0.4000. Anchor: `(RESET) equator 44657541 kv 11164380(44657520) kvi 8542952(34171808)`, MaxSim Log: `(RESET) equator 89317210 kv 22329296(89317184) kvi 19707872(78831488)`.
	============  Query  ====================
	Log[1]: `(RESET) equator 44657541 kv 11164380(44657520) kvi 8542952(34171808)`
	============ Response ====================
LogTemplate[1]: `(RESET) equator {num1} kv {num2}({num3}) kvi {num4}({num5})`
	============ PostProcess ====================
	Post Template: `(RESET) equator <*> kv <*>(<*>) kvi <*>(<*>)`
	============ Aggregate ====================
	Aggregated Template:  (RESET) equator <*> kv <*>(<*>) kvi <*>(<*>)
[UpdateBucket] Logs: This iter found: 4579, total: 107410/179993, remain: 72583. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 14675 -> 10096, remain buckets: 137
Update Success: Time for one update logs: 0.17571711540222168, template `(RESET) equator <*> kv <*>(<*>) kvi <*>(<*>)`
========================================================================================


Iteration 11
Sample 3 from current logs bucket: ID: 85, Len: 7, Bucket Size: 3892, Total Buckets: 269
Sampling from 3891 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `attempt_1445087491445_0005_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`, MaxSim Log: `attempt_1445087491445_0005_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Log[2]: `attempt_1445094324383_0003_m_000000_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Log[3]: `attempt_1445182159119_0014_m_000005_0 TaskAttempt Transitioned from ASSIGNED to RUNNING`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_{task_id}_m_{attempt_id}_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
LogTemplate[2]: `attempt_{job_id}_{task_id}_m_{attempt_id}_1 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
LogTemplate[3]: `attempt_{job_id}_{task_id}_m_{attempt_id}_0 TaskAttempt Transitioned from ASSIGNED to RUNNING`
	============ PostProcess ====================
	Post Template: `<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Post Template: `<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
	Post Template: `<*> TaskAttempt Transitioned from ASSIGNED to RUNNING`
	============ Aggregate ====================
	Aggregated Template:  <*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
[UpdateBucket] Logs: This iter found: 906, total: 108316/179993, remain: 71677. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 10096 -> 9190, remain buckets: 137
Update Success: Time for one update logs: 0.10680079460144043, template `<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED`
========================================================================================


Iteration 12
Sample 3 from current logs bucket: ID: 216, Len: 8, Bucket Size: 3841, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Reduce slow start threshold not met. completedMapsForReduceSlowstart 1`
	============ Response ====================
LogTemplate[1]: `Reduce slow start threshold not met. completedMapsForReduceSlowstart {placeholder}`
	============ PostProcess ====================
	Post Template: `Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>`
	============ Aggregate ====================
	Aggregated Template:  Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
[UpdateBucket] Logs: This iter found: 3841, total: 112157/179993, remain: 67836. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 5628 -> 1787, remain buckets: 136
Update Success: Time for one update logs: 0.10404396057128906, template `Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>`
========================================================================================


Iteration 13
Sample 3 from current logs bucket: ID: 40, Len: 4, Bucket Size: 3416, Total Buckets: 269
Sampling from 4 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Recalculating schedule, headroom=<memory:0, vCores:-35>`, MaxSim Log: `Recalculating schedule, headroom=<memory:0, vCores:-20>`.
	============  Query  ====================
	Log[1]: `Recalculating schedule, headroom=<memory:0, vCores:-35>`
	Log[2]: `Recalculating schedule, headroom=<memory:0, vCores:-20>`
	Log[3]: `Recalculating schedule, headroom=<memory:0, vCores:-27>`
	============ Response ====================
LogTemplate[1]: `Recalculating schedule, headroom=<memory:0, vCores:{vCores}>`
	============ PostProcess ====================
	Post Template: `Recalculating schedule, headroom=<memory:<*>, vCores:<*>`
	Post Template: `Recalculating schedule, headroom=<memory:<*>, vCores:<*>`
	Post Template: `Recalculating schedule, headroom=<memory:<*>, vCores:<*>`
	============ Aggregate ====================
	Aggregated Template:  Recalculating schedule, headroom=<memory:<*>, vCores:<*>
[UpdateBucket] Logs: This iter found: 4415, total: 116572/179993, remain: 63421. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 20163 -> 15748, remain buckets: 133
Update Success: Time for one update logs: 0.14956021308898926, template `Recalculating schedule, headroom=<memory:<*>, vCores:<*>`
========================================================================================


Iteration 14
Sample 3 from current logs bucket: ID: 85, Len: 7, Bucket Size: 2986, Total Buckets: 269
Sampling from 2985 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `attempt_1445087491445_0005_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING`, MaxSim Log: `attempt_1445087491445_0005_m_000010_0 TaskAttempt Transitioned from ASSIGNED to RUNNING`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING`
	Log[2]: `attempt_1445144423722_0021_m_000005_0 TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP`
	Log[3]: `attempt_1445094324383_0004_m_000003_2 TaskAttempt Transitioned from RUNNING to KILL_CONTAINER_CLEANUP`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_{task_id}_m_{attempt_id}_{attempt_type} TaskAttempt Transitioned from {from_state} to {to_state}`
	============ PostProcess ====================
	Post Template: `<*> TaskAttempt Transitioned from <*> to <*>`
	Post Template: `<*> TaskAttempt Transitioned from <*> to <*>`
	Post Template: `<*> TaskAttempt Transitioned from <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  <*> TaskAttempt Transitioned from <*> to <*>
[UpdateBucket] Logs: This iter found: 2986, total: 119558/179993, remain: 60435. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 9190 -> 6204, remain buckets: 132
Update Success: Time for one update logs: 0.2341020107269287, template `<*> TaskAttempt Transitioned from <*> to <*>`
========================================================================================


Iteration 15
Sample 3 from current logs bucket: ID: 236, Len: 10, Bucket Size: 2517, Total Buckets: 269
Sampling from 569 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 0 time(s); maxRetries=45`, MaxSim Log: `Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 1 time(s); maxRetries=45`.
	============  Query  ====================
	Log[1]: `Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 0 time(s); maxRetries=45`
	Log[2]: `Retrying connect to server: MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:52368. Already tried 32 time(s); maxRetries=45`
	Log[3]: `Retrying connect to server: MININT-FNANLI5.fareast.corp.microsoft.com/10.86.169.121:55135. Already tried 4 time(s); maxRetries=45`
	============ Response ====================
LogTemplate[1]: `Retrying connect to server: {server}/{ip_or_url}. Already tried {retry_count} time(s); maxRetries={max_retries}`
	============ PostProcess ====================
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>`
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>`
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>`
	============ Aggregate ====================
	Aggregated Template:  Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>
[UpdateBucket] Logs: This iter found: 2517, total: 122075/179993, remain: 57918. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 5240 -> 2723, remain buckets: 131
Update Success: Time for one update logs: 0.07852816581726074, template `Retrying connect to server: <*> Already tried <*> time(s); maxRetries=<*>`
========================================================================================


Iteration 16
Sample 3 from current logs bucket: ID: 235, Len: 10, Bucket Size: 1744, Total Buckets: 269
Sampling from 1743 logs, Sim Level: 3, MaxSim to anchor: 0.8182. Anchor: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1445087491445_0005_01_000002 taskAttempt attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445087491445_0005_01_000002 taskAttempt attempt_1445087491445_0005_m_000000_0`.
	============  Query  ====================
	Log[1]: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1445087491445_0005_01_000002 taskAttempt attempt_1445087491445_0005_m_000000_0`
	Log[2]: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1445182159119_0002_02_000002 taskAttempt attempt_1445182159119_0002_r_000000_1000`
	Log[3]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445062781478_0016_01_000005 taskAttempt attempt_1445062781478_0016_m_000003_0`
	============ Response ====================
LogTemplate[1]: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container {container_id} taskAttempt {task_attempt_id}`

LogTemplate[2]: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container {container_id} taskAttempt {task_attempt_id}`

LogTemplate[3]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container {container_id} taskAttempt {task_attempt_id}`
	============ PostProcess ====================
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>`
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>`
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
	============ Aggregate ====================
	Aggregated Template:  Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>
[UpdateBucket] Logs: This iter found: 906, total: 122981/179993, remain: 57012. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 2723 -> 1817, remain buckets: 131
Update Success: Time for one update logs: 0.0579829216003418, template `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>`
========================================================================================


Iteration 17
Sample 3 from current logs bucket: ID: 245, Len: 13, Bucket Size: 1742, Total Buckets: 269
Sampling from 1379 logs, Sim Level: 9, MaxSim to anchor: 0.8571. Anchor: `Before Scheduling: PendingReds:1 ScheduledMaps:13 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0`, MaxSim Log: `Before Scheduling: PendingReds:1 ScheduledMaps:10 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0`.
	============  Query  ====================
	Log[1]: `Before Scheduling: PendingReds:1 ScheduledMaps:13 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0`
	Log[2]: `Before Scheduling: PendingReds:1 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:9 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0`
	Log[3]: `Before Scheduling: PendingReds:1 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:10 CompletedReds:0 ContAlloc:11 ContRel:0 HostLocal:10 RackLocal:0`
	============ Response ====================
LogTemplate[1]: `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	============ PostProcess ====================
	Post Template: `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	============ Aggregate ====================
	Aggregated Template:  Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
[UpdateBucket] Logs: This iter found: 797, total: 123778/179993, remain: 56215. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 2175 -> 1378, remain buckets: 131
Update Success: Time for one update logs: 0.050865888595581055, template `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
========================================================================================


Iteration 18
Sample 3 from current logs bucket: ID: 25, Len: 4, Bucket Size: 1377, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Resolved MSRA-SA-41.fareast.corp.microsoft.com to /default-rack`
	============ Response ====================
LogTemplate[1]: `Resolved {hostname} to {directory}`
	============ PostProcess ====================
	Post Template: `Resolved <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  Resolved <*> to <*>
[UpdateBucket] Logs: This iter found: 3297, total: 127075/179993, remain: 52918. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 15748 -> 12451, remain buckets: 126
Update Success: Time for one update logs: 0.12749314308166504, template `Resolved <*> to <*>`
========================================================================================


Iteration 19
Sample 3 from current logs bucket: ID: 86, Len: 7, Bucket Size: 1278, Total Buckets: 269
Sampling from 1197 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `task_1445087491445_0005_m_000002 Task Transitioned from SCHEDULED to RUNNING`, MaxSim Log: `task_1445087491445_0005_m_000010 Task Transitioned from SCHEDULED to RUNNING`.
	============  Query  ====================
	Log[1]: `task_1445087491445_0005_m_000002 Task Transitioned from SCHEDULED to RUNNING`
	Log[2]: `task_1445182159119_0001_m_000008 Task Transitioned from SCHEDULED to RUNNING`
	Log[3]: `task_1445144423722_0020_m_000007 Task Transitioned from RUNNING to SUCCEEDED`
	============ Response ====================
LogTemplate[1]: `task_{job_id}_m_{task_id} Task Transitioned from {status_from} to {status_to}`
	============ PostProcess ====================
	Post Template: `<*> Task Transitioned from <*> to <*>`
	Post Template: `<*> Task Transitioned from <*> to <*>`
	Post Template: `<*> Task Transitioned from <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  <*> Task Transitioned from <*> to <*>
[UpdateBucket] Logs: This iter found: 2074, total: 129149/179993, remain: 50844. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 6204 -> 4130, remain buckets: 124
[TemplateDB] Try Merge: `<*> Task Transitioned from <*> to <*>` | `<*> TaskAttempt Transitioned from <*> to <*>`
[TemplateDB] Reject Merge, Remain Template: `<*> Task Transitioned from <*> to <*>`
Update Success: Time for one update logs: 0.18372797966003418, template `<*> Task Transitioned from <*> to <*>`
========================================================================================


Iteration 20
Sample 3 from current logs bucket: ID: 13, Len: 4, Bucket Size: 1140, Total Buckets: 269
	============  Query  ====================
	Log[1]: `MapTask metrics system started`
	============ Response ====================
LogTemplate[1]: `MapTask metrics system started`
	============ PostProcess ====================
	Post Template: `MapTask metrics system started`
	============ Aggregate ====================
	Aggregated Template:  MapTask metrics system started
[UpdateBucket] Logs: This iter found: 838, total: 129987/179993, remain: 50006. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 12451 -> 11613, remain buckets: 124
Update Success: Time for one update logs: 0.07193708419799805, template `MapTask metrics system started`
========================================================================================


Iteration 21
Sample 1 from current logs bucket: ID: 245, Len: 13, Bucket Size: 1068, Total Buckets: 269
Sampling from 818 logs, Sim Level: 9, MaxSim to anchor: 0.8571. Anchor: `After Scheduling: PendingReds:1 ScheduledMaps:9 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:3 RackLocal:1`, MaxSim Log: `After Scheduling: PendingReds:1 ScheduledMaps:6 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:3 RackLocal:1`.
	============  Query  ====================
	Log[1]: `After Scheduling: PendingReds:1 ScheduledMaps:9 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:3 RackLocal:1`
	Log[2]: `After Scheduling: PendingReds:1 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:13 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:13 ContRel:0 HostLocal:12 RackLocal:1`
	Log[3]: `After Scheduling: PendingReds:1 ScheduledMaps:5 ScheduledReds:0 AssignedMaps:5 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:5 ContRel:0 HostLocal:4 RackLocal:1`
	============ Response ====================
LogTemplate[1]: `After Scheduling: PendingReds:{pending_reds} ScheduledMaps:{scheduled_maps} ScheduledReds:{scheduled_reds} AssignedMaps:{assigned_maps} AssignedReds:{assigned_reds} CompletedMaps:{completed_maps} CompletedReds:{completed_reds} ContAlloc:{cont_alloc} ContRel:{cont_rel} HostLocal:{host_local} RackLocal:{rack_local}`
LogTemplate[2]: `After Scheduling: PendingReds:{pending_reds} ScheduledMaps:{scheduled_maps} ScheduledReds:{scheduled_reds} AssignedMaps:{assigned_maps} AssignedReds:{assigned_reds} CompletedMaps:{completed_maps} CompletedReds:{completed_reds} ContAlloc:{cont_alloc} ContRel:{cont_rel} HostLocal:{host_local} RackLocal:{rack_local}`
LogTemplate[3]: `After Scheduling: PendingReds:{pending_reds} ScheduledMaps:{scheduled_maps} ScheduledReds:{scheduled_reds} AssignedMaps:{assigned_maps} AssignedReds:{assigned_reds} CompletedMaps:{completed_maps} CompletedReds:{completed_reds} ContAlloc:{cont_alloc} ContRel:{cont_rel} HostLocal:{host_local} RackLocal:{rack_local}`
	============ PostProcess ====================
	Post Template: `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	============ Aggregate ====================
	Aggregated Template:  After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
[UpdateBucket] Logs: This iter found: 1249, total: 131236/179993, remain: 48757. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 1378 -> 129, remain buckets: 121
[TemplateDB] Try Merge: `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>` | `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
[TemplateDB] Reject Merge, Remain Template: `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
Update Success: Time for one update logs: 0.06408500671386719, template `After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
========================================================================================


Iteration 22
Sample 3 from current logs bucket: ID: 253, Len: 15, Bucket Size: 1048, Total Buckets: 269
Sampling from 94 logs, Sim Level: 2, MaxSim to anchor: 0.8750. Anchor: `Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`, MaxSim Log: `Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`.
	============  Query  ====================
	Log[1]: `Retrying connect to server: minint-75dgdam1.fareast.corp.microsoft.com/10.86.165.66:53419. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`
	Log[2]: `Retrying connect to server: MININT-75DGDAM1.fareast.corp.microsoft.com/10.86.165.66:58081. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`
	Log[3]: `Retrying connect to server: 10.190.173.170/10.190.173.170:29630. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`
	============ Response ====================
LogTemplate[1]: `Retrying connect to server: {server_address}/{ip_or_url}. Already tried {retry_count} time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`

LogTemplate[2]: `Retrying connect to server: {server_address}/{ip_or_url}. Already tried {retry_count} time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`

LogTemplate[3]: `Retrying connect to server: {ip_or_url}/{ip_or_url}. Already tried {retry_count} time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)`
	============ PostProcess ====================
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)`
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)`
	Post Template: `Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)`
	============ Aggregate ====================
	Aggregated Template:  Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)
[UpdateBucket] Logs: This iter found: 1048, total: 132284/179993, remain: 47709. 
[UpdateBucket] Buckets: Checked 2 ([253, 254]), Parent Bucket size: 1050 -> 2, remain buckets: 120
Update Success: Time for one update logs: 0.05346989631652832, template `Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=<*>, sleepTime=<*> MILLISECONDS)`
========================================================================================


Iteration 23
Sample 3 from current logs bucket: ID: 217, Len: 8, Bucket Size: 1033, Total Buckets: 269
Sampling from 904 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `TaskAttempt: [attempt_1445087491445_0005_m_000002_0] using containerId: [container_1445087491445_0005_01_000005 on NM: [MSRA-SA-39.fareast.corp.microsoft.com:49130]`, MaxSim Log: `TaskAttempt: [attempt_1445087491445_0005_m_000010_0] using containerId: [container_1445087491445_0005_01_000004 on NM: [MSRA-SA-39.fareast.corp.microsoft.com:49130]`.
	============  Query  ====================
	Log[1]: `TaskAttempt: [attempt_1445087491445_0005_m_000002_0] using containerId: [container_1445087491445_0005_01_000005 on NM: [MSRA-SA-39.fareast.corp.microsoft.com:49130]`
	Log[2]: `TaskAttempt: [attempt_1445087491445_0003_m_000009_2] using containerId: [container_1445087491445_0003_01_000023 on NM: [MSRA-SA-39.fareast.corp.microsoft.com:49130]`
	Log[3]: `TaskAttempt: [attempt_1445087491445_0004_m_000010_0] using containerId: [container_1445087491445_0004_01_000003 on NM: [MSRA-SA-39.fareast.corp.microsoft.com:49130]`
	============ Response ====================
LogTemplate[1]: `TaskAttempt: [attempt_<*>] using containerId: [container_<*> on NM: [<*>:<*>]`
LogTemplate[2]: `TaskAttempt: [attempt_<*>] using containerId: [container_<*> on NM: [<*>:<*>]`
LogTemplate[3]: `TaskAttempt: [attempt_<*>] using containerId: [container_<*> on NM: [<*>:<*>]`
	============ PostProcess ====================
	Post Template: `TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]`
	Post Template: `TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]`
	Post Template: `TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]`
	============ Aggregate ====================
	Aggregated Template:  TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]
[UpdateBucket] Logs: This iter found: 1033, total: 133317/179993, remain: 46676. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 1787 -> 754, remain buckets: 119
Update Success: Time for one update logs: 0.04744696617126465, template `TaskAttempt: [<*>] using containerId: [<*> on NM: [<*>]`
========================================================================================


Iteration 24
Sample 3 from current logs bucket: ID: 6, Len: 3, Bucket Size: 978, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Executing with tokens:`
	============ Response ====================
LogTemplate[1]: `Executing with tokens:`
	============ PostProcess ====================
	Post Template: `Executing with tokens:`
	============ Aggregate ====================
	Aggregated Template:  Executing with tokens:
[UpdateBucket] Logs: This iter found: 978, total: 134295/179993, remain: 45698. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 3070 -> 2092, remain buckets: 118
Update Success: Time for one update logs: 0.023847103118896484, template `Executing with tokens:`
========================================================================================


Iteration 25
Sample 3 from current logs bucket: ID: 60, Len: 6, Bucket Size: 978, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Scheduled snapshot period at 10 second(s).`
	============ Response ====================
LogTemplate[1]: `Scheduled snapshot period at {number} second(s).`
	============ PostProcess ====================
	Post Template: `Scheduled snapshot period at <*> second(s).`
	============ Aggregate ====================
	Aggregated Template:  Scheduled snapshot period at <*> second(s).
[UpdateBucket] Logs: This iter found: 978, total: 135273/179993, remain: 44720. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 7958 -> 6980, remain buckets: 117
Update Success: Time for one update logs: 0.0656287670135498, template `Scheduled snapshot period at <*> second(s).`
========================================================================================


Iteration 26
Sample 3 from current logs bucket: ID: 12, Len: 4, Bucket Size: 977, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `loaded properties from hadoop-metrics2.properties`
	============ Response ====================
LogTemplate[1]: `loaded properties from {file}`
	============ PostProcess ====================
	Post Template: `loaded properties from <*>`
	============ Aggregate ====================
	Aggregated Template:  loaded properties from <*>
[UpdateBucket] Logs: This iter found: 977, total: 136250/179993, remain: 43743. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 11613 -> 10636, remain buckets: 116
Update Success: Time for one update logs: 0.07917213439941406, template `loaded properties from <*>`
========================================================================================


Iteration 27
Sample 3 from current logs bucket: ID: 62, Len: 6, Bucket Size: 963, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `session.id is deprecated. Instead, use dfs.metrics.session-id`, MaxSim Log: `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`.
	============  Query  ====================
	Log[1]: `session.id is deprecated. Instead, use dfs.metrics.session-id`
	Log[2]: `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`
	============ Response ====================
LogTemplate[1]: `session.id is deprecated. Instead, use {placeholder}`  
LogTemplate[2]: `mapred.skip.on is deprecated. Instead, use {placeholder}`  
	============ PostProcess ====================
	Post Template: `session.id is deprecated. Instead, use <*>`
	Post Template: `mapred.skip.on is deprecated. Instead, use <*>`
	============ Aggregate ====================
	Aggregated Template:  session.id is deprecated. Instead, use <*>
[UpdateBucket] Logs: This iter found: 907, total: 137157/179993, remain: 42836. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 6980 -> 6073, remain buckets: 116
Update Success: Time for one update logs: 0.05823922157287598, template `session.id is deprecated. Instead, use <*>`
========================================================================================


Iteration 28
Sample 3 from current logs bucket: ID: 51, Len: 5, Bucket Size: 962, Total Buckets: 269
Sampling from 53 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Auth successful for job_1445087491445_0005 (auth:SIMPLE)`, MaxSim Log: `Auth successful for job_1445062781478_0018 (auth:SIMPLE)`.
	============  Query  ====================
	Log[1]: `Auth successful for job_1445087491445_0005 (auth:SIMPLE)`
	Log[2]: `Auth successful for job_1445182159119_0020 (auth:SIMPLE)`
	Log[3]: `Auth successful for job_1445062781478_0018 (auth:SIMPLE)`
	============ Response ====================
LogTemplate[1]: `Auth successful for job_<*> (auth:SIMPLE)`
	============ PostProcess ====================
	Post Template: `Auth successful for <*> (auth:SIMPLE)`
	Post Template: `Auth successful for <*> (auth:SIMPLE)`
	Post Template: `Auth successful for <*> (auth:SIMPLE)`
	============ Aggregate ====================
	Aggregated Template:  Auth successful for <*> (auth:SIMPLE)
[UpdateBucket] Logs: This iter found: 962, total: 138119/179993, remain: 41874. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 5144 -> 4182, remain buckets: 115
Update Success: Time for one update logs: 0.04974794387817383, template `Auth successful for <*> (auth:SIMPLE)`
========================================================================================


Iteration 29
Sample 3 from current logs bucket: ID: 61, Len: 6, Bucket Size: 909, Total Buckets: 269
Sampling from 564 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Kind: mapreduce.job, Service: job_1445087491445_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@7f0eb4b4)`, MaxSim Log: `Kind: mapreduce.job, Service: job_1445087491445_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@67b65d47)`.
	============  Query  ====================
	Log[1]: `Kind: mapreduce.job, Service: job_1445087491445_0005, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@7f0eb4b4)`
	Log[2]: `Kind: mapreduce.job, Service: job_1445182159119_0013, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@666adef3)`
	Log[3]: `Kind: mapreduce.job, Service: job_1445076437777_0002, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1623b78d)`
	============ Response ====================
LogTemplate[1]: `Kind: mapreduce.job, Service: {service_id}, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@{token_id})`
LogTemplate[2]: `Kind: mapreduce.job, Service: {service_id}, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@{token_id})`
LogTemplate[3]: `Kind: mapreduce.job, Service: {service_id}, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@{token_id})`
	============ PostProcess ====================
	Post Template: `Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)`
	Post Template: `Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)`
	Post Template: `Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)`
	============ Aggregate ====================
	Aggregated Template:  Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)
[UpdateBucket] Logs: This iter found: 909, total: 139028/179993, remain: 40965. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 6073 -> 5164, remain buckets: 114
Update Success: Time for one update logs: 0.06019306182861328, template `Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)`
========================================================================================


Iteration 30
Sample 3 from current logs bucket: ID: 225, Len: 9, Bucket Size: 909, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Sleeping for 0ms before retrying again. Got null now.`
	============ Response ====================
LogTemplate[1]: `Sleeping for {time}ms before retrying again. Got {value} now.`
	============ PostProcess ====================
	Post Template: `Sleeping for <*> before retrying again. Got <*> now.`
	============ Aggregate ====================
	Aggregated Template:  Sleeping for <*> before retrying again. Got <*> now.
[UpdateBucket] Logs: This iter found: 909, total: 139937/179993, remain: 40056. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 3891 -> 2982, remain buckets: 113
Update Success: Time for one update logs: 0.050707101821899414, template `Sleeping for <*> before retrying again. Got <*> now.`
========================================================================================


Iteration 31
Sample 3 from current logs bucket: ID: 14, Len: 4, Bucket Size: 907, Total Buckets: 269
Sampling from 54 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445087491445_0005`, MaxSim Log: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445062781478_0018`.
	============  Query  ====================
	Log[1]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445087491445_0005`
	Log[2]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445062781478_0017`
	Log[3]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_1445094324383_0001`
	============ Response ====================
LogTemplate[1]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_{app_id}`

LogTemplate[2]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_{app_id}`

LogTemplate[3]: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_{app_id}`
	============ PostProcess ====================
	Post Template: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>`
	Post Template: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>`
	Post Template: `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>`
	============ Aggregate ====================
	Aggregated Template:  mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>
[UpdateBucket] Logs: This iter found: 907, total: 140844/179993, remain: 39149. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 10636 -> 9729, remain buckets: 112
Update Success: Time for one update logs: 0.08057379722595215, template `mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>`
========================================================================================


Iteration 32
Sample 3 from current logs bucket: ID: 2, Len: 2, Bucket Size: 906, Total Buckets: 269
Sampling from 905 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Launching attempt_1445087491445_0005_m_000001_0`, MaxSim Log: `Launching attempt_1445087491445_0005_m_000010_0`.
	============  Query  ====================
	Log[1]: `Launching attempt_1445087491445_0005_m_000001_0`
	============ Response ====================
LogTemplate[1]: `Launching attempt_<*>`
	============ PostProcess ====================
	Post Template: `Launching <*>`
	============ Aggregate ====================
	Aggregated Template:  Launching <*>
[UpdateBucket] Logs: This iter found: 906, total: 141750/179993, remain: 38243. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 3805 -> 2899, remain buckets: 111
Update Success: Time for one update logs: 0.045478105545043945, template `Launching <*>`
========================================================================================


Iteration 33
Sample 3 from current logs bucket: ID: 56, Len: 5, Bucket Size: 906, Total Buckets: 269
Sampling from 905 logs, Sim Level: 1, MaxSim to anchor: 0.4286. Anchor: `Assigned container container_1445087491445_0005_01_000002 to attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Assigned container container_1445087491445_0005_01_000003 to attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `Assigned container container_1445087491445_0005_01_000002 to attempt_1445087491445_0005_m_000000_0`
	============ Response ====================
LogTemplate[1]: `Assigned container container_<*> to attempt_<*>_<*>_<*>_<*>`
	============ PostProcess ====================
	Post Template: `Assigned container <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  Assigned container <*> to <*>
[UpdateBucket] Logs: This iter found: 906, total: 142656/179993, remain: 37337. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 4182 -> 3276, remain buckets: 110
Update Success: Time for one update logs: 0.04904508590698242, template `Assigned container <*> to <*>`
========================================================================================


Iteration 34
Sample 3 from current logs bucket: ID: 229, Len: 9, Bucket Size: 906, Total Buckets: 269
Sampling from 905 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Shuffle port returned by ContainerManager for attempt_1445087491445_0005_m_000001_0 : 13562`, MaxSim Log: `Shuffle port returned by ContainerManager for attempt_1445087491445_0005_m_000000_0 : 13562`.
	============  Query  ====================
	Log[1]: `Shuffle port returned by ContainerManager for attempt_1445087491445_0005_m_000001_0 : 13562`
	Log[2]: `Shuffle port returned by ContainerManager for attempt_1445062781478_0015_m_000006_0 : 13562`
	Log[3]: `Shuffle port returned by ContainerManager for attempt_1445087491445_0001_m_000002_0 : 13562`
	============ Response ====================
LogTemplate[1]: `Shuffle port returned by ContainerManager for attempt_{job_id}_m_{task_id}_0 : {port}`
	============ PostProcess ====================
	Post Template: `Shuffle port returned by ContainerManager for <*> : <*>`
	Post Template: `Shuffle port returned by ContainerManager for <*> : <*>`
	Post Template: `Shuffle port returned by ContainerManager for <*> : <*>`
	============ Aggregate ====================
	Aggregated Template:  Shuffle port returned by ContainerManager for <*> : <*>
[UpdateBucket] Logs: This iter found: 906, total: 143562/179993, remain: 36431. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 2982 -> 2076, remain buckets: 109
Update Success: Time for one update logs: 0.04768729209899902, template `Shuffle port returned by ContainerManager for <*> : <*>`
========================================================================================


Iteration 35
Sample 3 from current logs bucket: ID: 3, Len: 2, Bucket Size: 905, Total Buckets: 269
Sampling from 608 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `ATTEMPT_START task_1445087491445_0005_m_000002`, MaxSim Log: `ATTEMPT_START task_1445087491445_0005_m_000010`.
	============  Query  ====================
	Log[1]: `ATTEMPT_START task_1445087491445_0005_m_000002`
	============ Response ====================
LogTemplate[1]: `ATTEMPT_START task_<*>`
	============ PostProcess ====================
	Post Template: `ATTEMPT_START <*>`
	============ Aggregate ====================
	Aggregated Template:  ATTEMPT_START <*>
[UpdateBucket] Logs: This iter found: 905, total: 144467/179993, remain: 35526. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 2899 -> 1994, remain buckets: 108
[TemplateDB] Try Merge: `ATTEMPT_START <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `ATTEMPT_START <*>`
Update Success: Time for one update logs: 0.039665937423706055, template `ATTEMPT_START <*>`
========================================================================================


Iteration 36
Sample 3 from current logs bucket: ID: 79, Len: 7, Bucket Size: 905, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `ProcfsBasedProcessTree currently is supported only on Linux.`
	============ Response ====================
LogTemplate[1]: `ProcfsBasedProcessTree currently is supported only on Linux.`
	============ PostProcess ====================
	Post Template: `ProcfsBasedProcessTree currently is supported only on Linux.`
	============ Aggregate ====================
	Aggregated Template:  ProcfsBasedProcessTree currently is supported only on Linux.
[UpdateBucket] Logs: This iter found: 905, total: 145372/179993, remain: 34621. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 4130 -> 3225, remain buckets: 107
Update Success: Time for one update logs: 0.0814051628112793, template `ProcfsBasedProcessTree currently is supported only on Linux.`
========================================================================================


Iteration 37
Sample 3 from current logs bucket: ID: 230, Len: 9, Bucket Size: 902, Total Buckets: 269
Sampling from 849 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `JVM with ID : jvm_1445087491445_0005_m_000002 asked for a task`, MaxSim Log: `JVM with ID : jvm_1445087491445_0005_m_000003 asked for a task`.
	============  Query  ====================
	Log[1]: `JVM with ID : jvm_1445087491445_0005_m_000002 asked for a task`
	Log[2]: `JVM with ID : jvm_1445087491445_0006_m_000009 asked for a task`
	Log[3]: `JVM with ID : jvm_1445087491445_0009_m_000018 asked for a task`
	============ Response ====================
LogTemplate[1]: `JVM with ID : {jvm_id} asked for a task`
LogTemplate[2]: `JVM with ID : {jvm_id} asked for a task`
LogTemplate[3]: `JVM with ID : {jvm_id} asked for a task`
	============ PostProcess ====================
	Post Template: `JVM with ID : <*> asked for a task`
	Post Template: `JVM with ID : <*> asked for a task`
	Post Template: `JVM with ID : <*> asked for a task`
	============ Aggregate ====================
	Aggregated Template:  JVM with ID : <*> asked for a task
[UpdateBucket] Logs: This iter found: 902, total: 146274/179993, remain: 33719. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 2076 -> 1174, remain buckets: 106
Update Success: Time for one update logs: 0.04713797569274902, template `JVM with ID : <*> asked for a task`
========================================================================================


Iteration 38
Sample 3 from current logs bucket: ID: 47, Len: 4, Bucket Size: 901, Total Buckets: 269
Sampling from 19 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:55452`, MaxSim Log: `Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:52150`.
	============  Query  ====================
	Log[1]: `Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:55452`
	Log[2]: `Opening proxy : 04DN8IQ.fareast.corp.microsoft.com:54883`
	Log[3]: `Opening proxy : MININT-75DGDAM1.fareast.corp.microsoft.com:57365`
	============ Response ====================
LogTemplate[1]: `Opening proxy : {proxy_host}:{port}`
	============ PostProcess ====================
	Post Template: `Opening proxy : <*>`
	Post Template: `Opening proxy : <*>`
	Post Template: `Opening proxy : <*>`
	============ Aggregate ====================
	Aggregated Template:  Opening proxy : <*>
[UpdateBucket] Logs: This iter found: 1757, total: 148031/179993, remain: 31962. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 9729 -> 7972, remain buckets: 101
Update Success: Time for one update logs: 0.08982396125793457, template `Opening proxy : <*>`
========================================================================================


Iteration 39
Sample 3 from current logs bucket: ID: 87, Len: 7, Bucket Size: 901, Total Buckets: 269
Sampling from 900 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `JVM with ID: jvm_1445087491445_0005_m_000002 given task: attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `JVM with ID: jvm_1445087491445_0005_m_000003 given task: attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `JVM with ID: jvm_1445087491445_0005_m_000002 given task: attempt_1445087491445_0005_m_000000_0`
	Log[2]: `JVM with ID: jvm_1445076437777_0001_m_000002 given task: attempt_1445076437777_0001_m_000000_1000`
	Log[3]: `JVM with ID: jvm_1445094324383_0004_m_000014 given task: attempt_1445094324383_0004_m_000006_1`
	============ Response ====================
LogTemplate[1]: `JVM with ID: jvm_<*> given task: attempt_<*>_<*>`  
LogTemplate[2]: `JVM with ID: jvm_<*> given task: attempt_<*>_<*>_<*>`  
LogTemplate[3]: `JVM with ID: jvm_<*> given task: attempt_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `JVM with ID: <*> given task: <*>`
	Post Template: `JVM with ID: <*> given task: <*>`
	Post Template: `JVM with ID: <*> given task: <*>`
	============ Aggregate ====================
	Aggregated Template:  JVM with ID: <*> given task: <*>
[UpdateBucket] Logs: This iter found: 902, total: 148933/179993, remain: 31060. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 3225 -> 2323, remain buckets: 100
Update Success: Time for one update logs: 0.10495901107788086, template `JVM with ID: <*> given task: <*>`
========================================================================================


Iteration 40
Sample 3 from current logs bucket: ID: 240, Len: 11, Bucket Size: 899, Total Buckets: 269
Sampling from 615 logs, Sim Level: 7, MaxSim to anchor: 0.6923. Anchor: `getResources() for application_1445087491445_0005: ask=7 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:13312, vCores:-7> knownNMs=3`, MaxSim Log: `getResources() for application_1445087491445_0003: ask=4 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:13312, vCores:-7> knownNMs=3`.
	============  Query  ====================
	Log[1]: `getResources() for application_1445087491445_0005: ask=7 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:13312, vCores:-7> knownNMs=3`
	Log[2]: `getResources() for application_1445087491445_0005: ask=4 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:6144, vCores:-14> knownNMs=3`
	Log[3]: `getResources() for application_1445094324383_0002: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:13312, vCores:-7> knownNMs=3`
	============ Response ====================
LogTemplate[1]: `getResources() for application_{app_id}: ask={ask} release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:{memory}, vCores:{vCores}> knownNMs=3`

LogTemplate[2]: `getResources() for application_{app_id}: ask={ask} release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:{memory}, vCores:{vCores}> knownNMs=3`

LogTemplate[3]: `getResources() for application_{app_id}: ask={ask} release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:{memory}, vCores:{vCores}> knownNMs=3`
	============ PostProcess ====================
	Post Template: `getResources() for <*>: ask=<*> release=<*> <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>`
	Post Template: `getResources() for <*>: ask=<*> release=<*> <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>`
	Post Template: `getResources() for <*>: ask=<*> release=<*> <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>`
	============ Aggregate ====================
	Aggregated Template:  getResources() for <*>: ask=<*> release=<*> <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>
[UpdateBucket] Logs: This iter found: 899, total: 149832/179993, remain: 30161. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 1748 -> 849, remain buckets: 99
Update Success: Time for one update logs: 0.04861807823181152, template `getResources() for <*>: ask=<*> release=<*> <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:<*> knownNMs=<*>`
========================================================================================


Iteration 41
Sample 3 from current logs bucket: ID: 4, Len: 2, Bucket Size: 851, Total Buckets: 269
Sampling from 850 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `KILLING attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `KILLING attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `KILLING attempt_1445087491445_0005_m_000000_0`
	============ Response ====================
LogTemplate[1]: `KILLING attempt_<*>`
	============ PostProcess ====================
	Post Template: `KILLING <*>`
	============ Aggregate ====================
	Aggregated Template:  KILLING <*>
[UpdateBucket] Logs: This iter found: 851, total: 150683/179993, remain: 29310. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 1994 -> 1143, remain buckets: 98
[TemplateDB] Try Merge: `KILLING <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `KILLING <*>`
Update Success: Time for one update logs: 0.03330802917480469, template `KILLING <*>`
========================================================================================


Iteration 42
Sample 3 from current logs bucket: ID: 235, Len: 10, Bucket Size: 838, Total Buckets: 269
Sampling from 837 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445087491445_0005_01_000002 taskAttempt attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445087491445_0005_01_000003 taskAttempt attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445087491445_0005_01_000002 taskAttempt attempt_1445087491445_0005_m_000000_0`
	Log[2]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445182159119_0017_01_000004 taskAttempt attempt_1445182159119_0017_m_000002_0`
	Log[3]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1445062781478_0012_01_000004 taskAttempt attempt_1445062781478_0012_m_000002_0`
	============ Response ====================
LogTemplate[1]: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container {container} taskAttempt {taskAttempt}`
	============ PostProcess ====================
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
	Post Template: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
	============ Aggregate ====================
	Aggregated Template:  Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>
[UpdateBucket] Logs: This iter found: 838, total: 151521/179993, remain: 28472. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 1817 -> 979, remain buckets: 97
[TemplateDB] Try Merge: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>` | `Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>`
[TemplateDB] Reject Merge, Remain Template: `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
Update Success: Time for one update logs: 0.03885793685913086, template `Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>`
========================================================================================


Iteration 43
Sample 3 from current logs bucket: ID: 1, Len: 2, Bucket Size: 834, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `mapreduce.task.io.sort.mb: 100`
	============ Response ====================
LogTemplate[1]: `mapreduce.task.io.sort.mb: {number}`
	============ PostProcess ====================
	Post Template: `mapreduce.task.io.sort.mb: <*>`
	============ Aggregate ====================
	Aggregated Template:  mapreduce.task.io.sort.mb: <*>
[UpdateBucket] Logs: This iter found: 834, total: 152355/179993, remain: 27638. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 1143 -> 309, remain buckets: 96
[TemplateDB] Try Merge: `mapreduce.task.io.sort.mb: <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `mapreduce.task.io.sort.mb: <*>`
Update Success: Time for one update logs: 0.035057783126831055, template `mapreduce.task.io.sort.mb: <*>`
========================================================================================


Iteration 44
Sample 3 from current logs bucket: ID: 9, Len: 3, Bucket Size: 834, Total Buckets: 269
Sampling from 23 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Processing split: hdfs://msra-sa-41:9000/wordcount2.txt:402653184+134217728`, MaxSim Log: `Processing split: hdfs://msra-sa-41:9000/wordcount2.txt:939524096+134217728`.
	============  Query  ====================
	Log[1]: `Processing split: hdfs://msra-sa-41:9000/wordcount2.txt:402653184+134217728`
	Log[2]: `Processing split: hdfs://msra-sa-41:9000/pageinput2.txt:536870912+134217728`
	Log[3]: `Processing split: hdfs://msra-sa-41:9000/wordcount2.txt:1342177280+134217728`
	============ Response ====================
LogTemplate[1]: `Processing split: hdfs://{ip_or_url}/{file}:{*}+134217728`  
LogTemplate[2]: `Processing split: hdfs://{ip_or_url}/{file}:{*}+134217728`  
LogTemplate[3]: `Processing split: hdfs://{ip_or_url}/{file}:{*}+134217728`  
	============ PostProcess ====================
	Post Template: `Processing split: hdfs://<*>`
	Post Template: `Processing split: hdfs://<*>`
	Post Template: `Processing split: hdfs://<*>`
	============ Aggregate ====================
	Aggregated Template:  Processing split: hdfs://<*>
[UpdateBucket] Logs: This iter found: 834, total: 153189/179993, remain: 26804. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 2092 -> 1258, remain buckets: 95
Update Success: Time for one update logs: 0.04242300987243652, template `Processing split: hdfs://<*>`
========================================================================================


Iteration 45
Sample 3 from current logs bucket: ID: 17, Len: 4, Bucket Size: 834, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `soft limit at 83886080`
	============ Response ====================
LogTemplate[1]: `soft limit at {number}`
	============ PostProcess ====================
	Post Template: `soft limit at <*>`
	============ Aggregate ====================
	Aggregated Template:  soft limit at <*>
[UpdateBucket] Logs: This iter found: 834, total: 154023/179993, remain: 25970. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 7972 -> 7138, remain buckets: 94
Update Success: Time for one update logs: 0.06930398941040039, template `soft limit at <*>`
========================================================================================


Iteration 46
Sample 3 from current logs bucket: ID: 63, Len: 6, Bucket Size: 834, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `bufstart = 0; bufvoid = 104857600`
	============ Response ====================
LogTemplate[1]: `bufstart = {number}; bufvoid = {number}`
	============ PostProcess ====================
	Post Template: `bufstart = <*>; bufvoid = <*>`
	============ Aggregate ====================
	Aggregated Template:  bufstart = <*>; bufvoid = <*>
[UpdateBucket] Logs: This iter found: 834, total: 154857/179993, remain: 25136. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 5164 -> 4330, remain buckets: 93
Update Success: Time for one update logs: 0.05820608139038086, template `bufstart = <*>; bufvoid = <*>`
========================================================================================


Iteration 47
Sample 3 from current logs bucket: ID: 64, Len: 6, Bucket Size: 834, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `kvstart = 26214396; length = 6553600`
	============ Response ====================
LogTemplate[1]: `kvstart = {number}; length = {number}`
	============ PostProcess ====================
	Post Template: `kvstart = <*>; length = <*>`
	============ Aggregate ====================
	Aggregated Template:  kvstart = <*>; length = <*>
[UpdateBucket] Logs: This iter found: 834, total: 155691/179993, remain: 24302. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 4330 -> 3496, remain buckets: 92
Update Success: Time for one update logs: 0.055989980697631836, template `kvstart = <*>; length = <*>`
========================================================================================


Iteration 48
Sample 3 from current logs bucket: ID: 65, Len: 6, Bucket Size: 834, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer`
	============ Response ====================
LogTemplate[1]: `Map output collector class = {api}`
	============ PostProcess ====================
	Post Template: `Map output collector class = <*>`
	============ Aggregate ====================
	Aggregated Template:  Map output collector class = <*>
[UpdateBucket] Logs: This iter found: 834, total: 156525/179993, remain: 23468. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 3496 -> 2662, remain buckets: 91
Update Success: Time for one update logs: 0.04843592643737793, template `Map output collector class = <*>`
========================================================================================


Iteration 49
Sample 3 from current logs bucket: ID: 34, Len: 4, Bucket Size: 826, Total Buckets: 269
Sampling from 825 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Received completed container container_1445087491445_0005_01_000002`, MaxSim Log: `Received completed container container_1445087491445_0005_01_000003`.
	============  Query  ====================
	Log[1]: `Received completed container container_1445087491445_0005_01_000002`
	Log[2]: `Received completed container container_1445094324383_0001_01_000003`
	Log[3]: `Received completed container container_1445062781478_0019_01_000007`
	============ Response ====================
LogTemplate[1]: `Received completed container container_<*>_<*>_<*>_<*>`  
LogTemplate[2]: `Received completed container container_<*>_<*>_<*>_<*>`  
LogTemplate[3]: `Received completed container container_<*>_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Received completed container <*>`
	Post Template: `Received completed container <*>`
	Post Template: `Received completed container <*>`
	============ Aggregate ====================
	Aggregated Template:  Received completed container <*>
[UpdateBucket] Logs: This iter found: 826, total: 157351/179993, remain: 22642. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 7138 -> 6312, remain buckets: 90
Update Success: Time for one update logs: 0.07166600227355957, template `Received completed container <*>`
========================================================================================


Iteration 50
Sample 3 from current logs bucket: ID: 231, Len: 9, Bucket Size: 733, Total Buckets: 269
Sampling from 732 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Diagnostics report from attempt_1445087491445_0005_m_000000_0: Container killed by the ApplicationMaster.`, MaxSim Log: `Diagnostics report from attempt_1445087491445_0005_m_000001_0: Container killed by the ApplicationMaster.`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445087491445_0005_m_000000_0: Container killed by the ApplicationMaster.`
	Log[2]: `Diagnostics report from attempt_1445087491445_0002_m_000004_0: Container killed by the ApplicationMaster.`
	Log[3]: `Diagnostics report from attempt_1445144423722_0021_m_000002_0: Container killed by the ApplicationMaster.`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>: Container killed by the ApplicationMaster.`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Container killed by the ApplicationMaster.`
	Post Template: `Diagnostics report from <*>: Container killed by the ApplicationMaster.`
	Post Template: `Diagnostics report from <*>: Container killed by the ApplicationMaster.`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Container killed by the ApplicationMaster.
[UpdateBucket] Logs: This iter found: 733, total: 158084/179993, remain: 21909. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 1174 -> 441, remain buckets: 89
Update Success: Time for one update logs: 0.04162001609802246, template `Diagnostics report from <*>: Container killed by the ApplicationMaster.`
========================================================================================


Iteration 51
Sample 3 from current logs bucket: ID: 33, Len: 4, Bucket Size: 701, Total Buckets: 269
Sampling from 13 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Num completed Tasks: 1`, MaxSim Log: `Num completed Tasks: 2`.
	============  Query  ====================
	Log[1]: `Num completed Tasks: 1`
	Log[2]: `Num completed Tasks: 10`
	Log[3]: `Num completed Tasks: 13`
	============ Response ====================
LogTemplate[1]: `Num completed Tasks: {num}`  
LogTemplate[2]: `Num completed Tasks: {num}`  
LogTemplate[3]: `Num completed Tasks: {num}`  
	============ PostProcess ====================
	Post Template: `Num completed Tasks: <*>`
	Post Template: `Num completed Tasks: <*>`
	Post Template: `Num completed Tasks: <*>`
	============ Aggregate ====================
	Aggregated Template:  Num completed Tasks: <*>
[UpdateBucket] Logs: This iter found: 701, total: 158785/179993, remain: 21208. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 6312 -> 5611, remain buckets: 88
Update Success: Time for one update logs: 0.06729388236999512, template `Num completed Tasks: <*>`
========================================================================================


Iteration 52
Sample 3 from current logs bucket: ID: 52, Len: 5, Bucket Size: 701, Total Buckets: 269
Sampling from 604 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Task succeeded with attempt attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Task succeeded with attempt attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `Task succeeded with attempt attempt_1445087491445_0005_m_000000_0`
	Log[2]: `Task succeeded with attempt attempt_1445094324383_0004_m_000008_0`
	Log[3]: `Task succeeded with attempt attempt_1445062781478_0015_m_000003_0`
	============ Response ====================
LogTemplate[1]: `Task succeeded with attempt attempt_<*>_<*>_<*>_<*>_<*>`  
LogTemplate[2]: `Task succeeded with attempt attempt_<*>_<*>_<*>_<*>_<*>`  
LogTemplate[3]: `Task succeeded with attempt attempt_<*>_<*>_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Task succeeded with attempt <*>`
	Post Template: `Task succeeded with attempt <*>`
	Post Template: `Task succeeded with attempt <*>`
	============ Aggregate ====================
	Aggregated Template:  Task succeeded with attempt <*>
[UpdateBucket] Logs: This iter found: 701, total: 159486/179993, remain: 20507. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 3276 -> 2575, remain buckets: 87
Update Success: Time for one update logs: 0.0476229190826416, template `Task succeeded with attempt <*>`
========================================================================================


Iteration 53
Sample 3 from current logs bucket: ID: 18, Len: 4, Bucket Size: 678, Total Buckets: 269
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Merging 7 sorted segments`, MaxSim Log: `Merging 13 sorted segments`.
	============  Query  ====================
	Log[1]: `Merging 7 sorted segments`
	Log[2]: `Merging 13 sorted segments`
	Log[3]: `Merging 8 sorted segments`
	============ Response ====================
LogTemplate[1]: `Merging {number} sorted segments`
LogTemplate[2]: `Merging {number} sorted segments`
LogTemplate[3]: `Merging {number} sorted segments`
	============ PostProcess ====================
	Post Template: `Merging <*> sorted segments`
	Post Template: `Merging <*> sorted segments`
	Post Template: `Merging <*> sorted segments`
	============ Aggregate ====================
	Aggregated Template:  Merging <*> sorted segments
[UpdateBucket] Logs: This iter found: 678, total: 160164/179993, remain: 19829. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 5611 -> 4933, remain buckets: 86
Update Success: Time for one update logs: 0.055974721908569336, template `Merging <*> sorted segments`
========================================================================================


Iteration 54
Sample 3 from current logs bucket: ID: 250, Len: 14, Bucket Size: 678, Total Buckets: 269
Sampling from 38 logs, Sim Level: 2, MaxSim to anchor: 0.8667. Anchor: `Down to the last merge-pass, with 7 segments left of total size: 228411640 bytes`, MaxSim Log: `Down to the last merge-pass, with 7 segments left of total size: 228411996 bytes`.
	============  Query  ====================
	Log[1]: `Down to the last merge-pass, with 7 segments left of total size: 228411640 bytes`
	Log[2]: `Down to the last merge-pass, with 5 segments left of total size: 180080717 bytes`
	Log[3]: `Down to the last merge-pass, with 8 segments left of total size: 288330442 bytes`
	============ Response ====================
LogTemplate[1]: `Down to the last merge-pass, with {segments} segments left of total size: {bytes} bytes`
	============ PostProcess ====================
	Post Template: `Down to the last merge-pass, with <*> segments left of total size: <*> bytes`
	Post Template: `Down to the last merge-pass, with <*> segments left of total size: <*> bytes`
	Post Template: `Down to the last merge-pass, with <*> segments left of total size: <*> bytes`
	============ Aggregate ====================
	Aggregated Template:  Down to the last merge-pass, with <*> segments left of total size: <*> bytes
[UpdateBucket] Logs: This iter found: 678, total: 160842/179993, remain: 19151. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 1376 -> 698, remain buckets: 85
Update Success: Time for one update logs: 0.029886960983276367, template `Down to the last merge-pass, with <*> segments left of total size: <*> bytes`
========================================================================================


Iteration 55
Sample 3 from current logs bucket: ID: 239, Len: 11, Bucket Size: 667, Total Buckets: 269
Sampling from 584 logs, Sim Level: 3, MaxSim to anchor: 0.8333. Anchor: `attempt_1445087491445_0005_m_000000_0: Shuffling to disk since 227948846 is greater than maxSingleShuffleLimit (32663142)`, MaxSim Log: `attempt_1445087491445_0002_m_000000_0: Shuffling to disk since 227948846 is greater than maxSingleShuffleLimit (32663142)`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_m_000000_0: Shuffling to disk since 227948846 is greater than maxSingleShuffleLimit (32663142)`
	Log[2]: `attempt_1445182159119_0004_m_000002_0: Shuffling to disk since 216991624 is greater than maxSingleShuffleLimit (32663142)`
	Log[3]: `attempt_1445094324383_0001_m_000005_0: Shuffling to disk since 216990140 is greater than maxSingleShuffleLimit (35232152)`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_m_{task_id}_0: Shuffling to disk since {value} is greater than maxSingleShuffleLimit ({limit})`
	============ PostProcess ====================
	Post Template: `<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)`
	Post Template: `<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)`
	Post Template: `<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)`
	============ Aggregate ====================
	Aggregated Template:  <*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)
[UpdateBucket] Logs: This iter found: 667, total: 161509/179993, remain: 18484. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 849 -> 182, remain buckets: 84
Update Success: Time for one update logs: 0.03870511054992676, template `<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)`
========================================================================================


Iteration 56
Sample 3 from current logs bucket: ID: 251, Len: 14, Bucket Size: 664, Total Buckets: 269
Sampling from 616 logs, Sim Level: 4, MaxSim to anchor: 0.8571. Anchor: `fetcher#2 about to shuffle output of map attempt_1445087491445_0005_m_000000_0 decomp: 227948846 len: 227948850 to DISK`, MaxSim Log: `fetcher#4 about to shuffle output of map attempt_1445087491445_0005_m_000000_0 decomp: 227948846 len: 227948850 to DISK`.
	============  Query  ====================
	Log[1]: `fetcher#2 about to shuffle output of map attempt_1445087491445_0005_m_000000_0 decomp: 227948846 len: 227948850 to DISK`
	Log[2]: `fetcher#3 about to shuffle output of map attempt_1445087491445_0002_m_000007_1 decomp: 216987422 len: 216987426 to DISK`
	Log[3]: `fetcher#5 about to shuffle output of map attempt_1445076437777_0005_m_000009_0 decomp: 56695786 len: 56695790 to DISK`
	============ Response ====================
LogTemplate[1]: `fetcher#<*> about to shuffle output of map attempt_<*>_<*>_m_<*>_<*> decomp: <*> len: <*> to DISK`
LogTemplate[2]: `fetcher#<*> about to shuffle output of map attempt_<*>_<*>_m_<*>_<*> decomp: <*> len: <*> to DISK`
LogTemplate[3]: `fetcher#<*> about to shuffle output of map attempt_<*>_<*>_m_<*>_<*> decomp: <*> len: <*> to DISK`
	============ PostProcess ====================
	Post Template: `fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK`
	Post Template: `fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK`
	Post Template: `fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK`
	============ Aggregate ====================
	Aggregated Template:  fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK
[UpdateBucket] Logs: This iter found: 664, total: 162173/179993, remain: 17820. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 698 -> 34, remain buckets: 83
Update Success: Time for one update logs: 0.028016090393066406, template `fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK`
========================================================================================


Iteration 57
Sample 3 from current logs bucket: ID: 96, Len: 7, Bucket Size: 649, Total Buckets: 269
Sampling from 525 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Read 227948850 bytes from map-output for attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Read 227948850 bytes from map-output for attempt_1445087491445_0002_m_000000_0`.
	============  Query  ====================
	Log[1]: `Read 227948850 bytes from map-output for attempt_1445087491445_0005_m_000000_0`
	Log[2]: `Read 60515791 bytes from map-output for attempt_1445062781478_0018_m_000003_1`
	Log[3]: `Read 60514810 bytes from map-output for attempt_1445182159119_0012_m_000005_0`
	============ Response ====================
LogTemplate[1]: `Read {bytes} bytes from map-output for {attempt_id}_m_{task_id}_{attempt_num}`

LogTemplate[2]: `Read {bytes} bytes from map-output for {attempt_id}_m_{task_id}_{attempt_num}`

LogTemplate[3]: `Read {bytes} bytes from map-output for {attempt_id}_m_{task_id}_{attempt_num}`
	============ PostProcess ====================
	Post Template: `Read <*> bytes from map-output for <*>`
	Post Template: `Read <*> bytes from map-output for <*>`
	Post Template: `Read <*> bytes from map-output for <*>`
	============ Aggregate ====================
	Aggregated Template:  Read <*> bytes from map-output for <*>
[UpdateBucket] Logs: This iter found: 649, total: 162822/179993, remain: 17171. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 2323 -> 1674, remain buckets: 82
Update Success: Time for one update logs: 0.09768390655517578, template `Read <*> bytes from map-output for <*>`
========================================================================================


Iteration 58
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 647, Total Buckets: 269
	============  Query  ====================
	Log[1]: `OutputCommitter set in config null`
	============ Response ====================
LogTemplate[1]: `OutputCommitter set in config {placeholder}`
	============ PostProcess ====================
	Post Template: `OutputCommitter set in config <*>`
	============ Aggregate ====================
	Aggregated Template:  OutputCommitter set in config <*>
[UpdateBucket] Logs: This iter found: 69, total: 162891/179993, remain: 17102. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 2575 -> 2506, remain buckets: 82
Update Success: Time for one update logs: 0.029568910598754883, template `OutputCommitter set in config <*>`
========================================================================================


Iteration 59
Sample 1 from current logs bucket: ID: 49, Len: 5, Bucket Size: 644, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Starting flush of map output`
	============ Response ====================
LogTemplate[1]: `Starting flush of map output`
	============ PostProcess ====================
	Post Template: `Starting flush of map output`
	============ Aggregate ====================
	Aggregated Template:  Starting flush of map output
[UpdateBucket] Logs: This iter found: 644, total: 163535/179993, remain: 16458. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 2506 -> 1862, remain buckets: 81
Update Success: Time for one update logs: 0.022655010223388672, template `Starting flush of map output`
========================================================================================


Iteration 60
Sample 1 from current logs bucket: ID: 11, Len: 3, Bucket Size: 642, Total Buckets: 269
Sampling from 41 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c185bfb`, MaxSim Log: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fad9bb2`.
	============  Query  ====================
	Log[1]: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c185bfb`
	Log[2]: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b904247`
	Log[3]: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@309134f7`
	============ Response ====================
LogTemplate[1]: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@{api}`
	============ PostProcess ====================
	Post Template: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>`
	Post Template: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>`
	Post Template: `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>`
	============ Aggregate ====================
	Aggregated Template:  Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>
[UpdateBucket] Logs: This iter found: 71, total: 163606/179993, remain: 16387. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 1258 -> 1187, remain buckets: 81
Update Success: Time for one update logs: 0.019588947296142578, template `Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>`
========================================================================================


Iteration 61
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 637, Total Buckets: 269
Sampling from 68 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Instantiated MRClientService at MSRA-SA-41.fareast.corp.microsoft.com/10.190.173.170:32060`, MaxSim Log: `Instantiated MRClientService at MSRA-SA-41.fareast.corp.microsoft.com/10.190.173.170:19900`.
	============  Query  ====================
	Log[1]: `Instantiated MRClientService at MSRA-SA-41.fareast.corp.microsoft.com/10.190.173.170:32060`
	Log[2]: `Instantiated MRClientService at MSRA-SA-39.fareast.corp.microsoft.com/172.22.149.145:39663`
	Log[3]: `Instantiated MRClientService at MSRA-SA-39.fareast.corp.microsoft.com/172.22.149.145:25270`
	============ Response ====================
LogTemplate[1]: `Instantiated MRClientService at {server_address}/{ip_or_url}:{port}`  
LogTemplate[2]: `Instantiated MRClientService at {server_address}/{ip_or_url}:{port}`  
LogTemplate[3]: `Instantiated MRClientService at {server_address}/{ip_or_url}:{port}`  
	============ PostProcess ====================
	Post Template: `Instantiated MRClientService at <*>`
	Post Template: `Instantiated MRClientService at <*>`
	Post Template: `Instantiated MRClientService at <*>`
	============ Aggregate ====================
	Aggregated Template:  Instantiated MRClientService at <*>
[UpdateBucket] Logs: This iter found: 69, total: 163675/179993, remain: 16318. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 4933 -> 4864, remain buckets: 81
Update Success: Time for one update logs: 0.05384087562561035, template `Instantiated MRClientService at <*>`
========================================================================================


Iteration 62
Sample 3 from current logs bucket: ID: 45, Len: 4, Bucket Size: 626, Total Buckets: 269
Sampling from 227 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@14c86ad8`, MaxSim Log: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@49a29f92`.
	============  Query  ====================
	Log[1]: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@14c86ad8`
	Log[2]: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4dfd671f`
	Log[3]: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@24207655`
	============ Response ====================
LogTemplate[1]: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@{api}`
	============ PostProcess ====================
	Post Template: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>`
	Post Template: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>`
	Post Template: `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>`
	============ Aggregate ====================
	Aggregated Template:  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>
[UpdateBucket] Logs: This iter found: 905, total: 164580/179993, remain: 15413. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 4864 -> 3959, remain buckets: 78
Update Success: Time for one update logs: 0.06985282897949219, template `Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>`
========================================================================================


Iteration 63
Sample 3 from current logs bucket: ID: 234, Len: 10, Bucket Size: 625, Total Buckets: 269
Sampling from 624 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Task:attempt_1445087491445_0005_m_000004_0 is done. And is in the process of committing`, MaxSim Log: `Task:attempt_1445087491445_0005_m_000003_0 is done. And is in the process of committing`.
	============  Query  ====================
	Log[1]: `Task:attempt_1445087491445_0005_m_000004_0 is done. And is in the process of committing`
	Log[2]: `Task:attempt_1445094324383_0003_m_000003_0 is done. And is in the process of committing`
	Log[3]: `Task:attempt_1445094324383_0002_m_000005_0 is done. And is in the process of committing`
	============ Response ====================
LogTemplate[1]: `Task:attempt_{attempt_id}_m_{task_id}_{status} is done. And is in the process of committing`  
LogTemplate[2]: `Task:attempt_{attempt_id}_m_{task_id}_{status} is done. And is in the process of committing`  
LogTemplate[3]: `Task:attempt_{attempt_id}_m_{task_id}_{status} is done. And is in the process of committing`  
	============ PostProcess ====================
	Post Template: `Task:<*> is done. And is in the process of committing`
	Post Template: `Task:<*> is done. And is in the process of committing`
	Post Template: `Task:<*> is done. And is in the process of committing`
	============ Aggregate ====================
	Aggregated Template:  Task:<*> is done. And is in the process of committing
[UpdateBucket] Logs: This iter found: 625, total: 165205/179993, remain: 14788. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 979 -> 354, remain buckets: 77
Update Success: Time for one update logs: 0.028749942779541016, template `Task:<*> is done. And is in the process of committing`
========================================================================================


Iteration 64
Sample 3 from current logs bucket: ID: 68, Len: 6, Bucket Size: 621, Total Buckets: 269
Sampling from 8 logs, Sim Level: 1, MaxSim to anchor: 0.4286. Anchor: `Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler`, MaxSim Log: `Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher`.
	============  Query  ====================
	Log[1]: `Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler`
	============ Response ====================
LogTemplate[1]: `Registering class {class} for class {class}`
	============ PostProcess ====================
	Post Template: `Registering class <*> for class <*>`
	============ Aggregate ====================
	Aggregated Template:  Registering class <*> for class <*>
[UpdateBucket] Logs: This iter found: 621, total: 165826/179993, remain: 14167. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 2662 -> 2041, remain buckets: 76
Update Success: Time for one update logs: 0.042150259017944336, template `Registering class <*> for class <*>`
========================================================================================


Iteration 65
Sample 3 from current logs bucket: ID: 10, Len: 3, Bucket Size: 616, Total Buckets: 269
Sampling from 615 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Task 'attempt_1445087491445_0005_m_000004_0' done.`, MaxSim Log: `Task 'attempt_1445087491445_0005_m_000003_0' done.`.
	============  Query  ====================
	Log[1]: `Task 'attempt_1445087491445_0005_m_000004_0' done.`
	Log[2]: `Task 'attempt_1445062781478_0020_m_000009_0' done.`
	Log[3]: `Task 'attempt_1445076437777_0005_m_000009_0' done.`
	============ Response ====================
LogTemplate[1]: `Task '{task_id}' done.`  
LogTemplate[2]: `Task '{task_id}' done.`  
LogTemplate[3]: `Task '{task_id}' done.`  
	============ PostProcess ====================
	Post Template: `Task <*> done.`
	Post Template: `Task <*> done.`
	Post Template: `Task <*> done.`
	============ Aggregate ====================
	Aggregated Template:  Task <*> done.
[UpdateBucket] Logs: This iter found: 616, total: 166442/179993, remain: 13551. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 1187 -> 571, remain buckets: 75
Update Success: Time for one update logs: 0.031173229217529297, template `Task <*> done.`
========================================================================================


Iteration 66
Sample 3 from current logs bucket: ID: 29, Len: 4, Bucket Size: 606, Total Buckets: 269
Sampling from 10 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Got allocated containers 4`, MaxSim Log: `Got allocated containers 1`.
	============  Query  ====================
	Log[1]: `Got allocated containers 4`
	Log[2]: `Got allocated containers 3`
	Log[3]: `Got allocated containers 5`
	============ Response ====================
LogTemplate[1]: `Got allocated containers {count}`  
LogTemplate[2]: `Got allocated containers {count}`  
LogTemplate[3]: `Got allocated containers {count}`  
	============ PostProcess ====================
	Post Template: `Got allocated containers <*>`
	Post Template: `Got allocated containers <*>`
	Post Template: `Got allocated containers <*>`
	============ Aggregate ====================
	Aggregated Template:  Got allocated containers <*>
[UpdateBucket] Logs: This iter found: 606, total: 167048/179993, remain: 12945. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 3959 -> 3353, remain buckets: 74
Update Success: Time for one update logs: 0.05808830261230469, template `Got allocated containers <*>`
========================================================================================


Iteration 67
Sample 3 from current logs bucket: ID: 32, Len: 4, Bucket Size: 605, Total Buckets: 269
Sampling from 604 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Done acknowledgement from attempt_1445087491445_0005_m_000000_0`, MaxSim Log: `Done acknowledgement from attempt_1445087491445_0005_m_000001_0`.
	============  Query  ====================
	Log[1]: `Done acknowledgement from attempt_1445087491445_0005_m_000000_0`
	Log[2]: `Done acknowledgement from attempt_1445182159119_0005_m_000003_0`
	Log[3]: `Done acknowledgement from attempt_1445182159119_0002_m_000009_1`
	============ Response ====================
LogTemplate[1]: `Done acknowledgement from attempt_<*>_<*>_<*>_<*>`  
LogTemplate[2]: `Done acknowledgement from attempt_<*>_<*>_<*>_<*>`  
LogTemplate[3]: `Done acknowledgement from attempt_<*>_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Done acknowledgement from <*>`
	Post Template: `Done acknowledgement from <*>`
	Post Template: `Done acknowledgement from <*>`
	============ Aggregate ====================
	Aggregated Template:  Done acknowledgement from <*>
[UpdateBucket] Logs: This iter found: 605, total: 167653/179993, remain: 12340. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 3353 -> 2748, remain buckets: 73
Update Success: Time for one update logs: 0.04867815971374512, template `Done acknowledgement from <*>`
========================================================================================


Iteration 68
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 578, Total Buckets: 269
Sampling from 72 logs, Sim Level: 1, MaxSim to anchor: 0.1111. Anchor: `Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog`, MaxSim Log: `Jetty bound to port 32067`.
	============  Query  ====================
	Log[1]: `Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog`
	============ Response ====================
LogTemplate[1]: `Logging to org.slf4j.impl.Log4jLoggerAdapter({api}) via {api}`
	============ PostProcess ====================
	Post Template: `Logging to org.slf4j.impl.Log4jLoggerAdapter(<*>) via <*>`
	============ Aggregate ====================
	Aggregated Template:  Logging to org.slf4j.impl.Log4jLoggerAdapter(<*>) via <*>
[UpdateBucket] Logs: This iter found: 69, total: 167722/179993, remain: 12271. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1862 -> 1793, remain buckets: 73
Update Success: Time for one update logs: 0.025506973266601562, template `Logging to org.slf4j.impl.Log4jLoggerAdapter(<*>) via <*>`
========================================================================================


Iteration 69
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 571, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.2000. Anchor: `OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter`, MaxSim Log: `maxTaskFailuresPerNode is 3`.
	============  Query  ====================
	Log[1]: `OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter`
	============ Response ====================
LogTemplate[1]: `OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter`
	============ PostProcess ====================
	Post Template: `OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter`
	============ Aggregate ====================
	Aggregated Template:  OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[UpdateBucket] Logs: This iter found: 69, total: 167791/179993, remain: 12202. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 571 -> 502, remain buckets: 73
Update Success: Time for one update logs: 0.011551380157470703, template `OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter`
========================================================================================


Iteration 70
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 568, Total Buckets: 269
Sampling from 163 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\2\Jetty_0_0_0_0_32067_mapreduce____.dbisl5\webapp`, MaxSim Log: `Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\2\Jetty_0_0_0_0_19907_mapreduce____lryhnl\webapp`.
	============  Query  ====================
	Log[1]: `Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\2\Jetty_0_0_0_0_32067_mapreduce____.dbisl5\webapp`
	Log[2]: `Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\2\Jetty_0_0_0_0_39670_mapreduce____y341kg\webapp`
	Log[3]: `Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to C:\Users\msrabi\AppData\Local\Temp\2\Jetty_0_0_0_0_19907_mapreduce____lryhnl\webapp`
	============ Response ====================
LogTemplate[1]: `Extract jar:file:{file}!/webapps/mapreduce to {directory}\webapp`  
LogTemplate[2]: `Extract jar:file:{file}!/webapps/mapreduce to {directory}\webapp`  
LogTemplate[3]: `Extract jar:file:{file}!/webapps/mapreduce to {directory}\webapp`  
	============ PostProcess ====================
	Post Template: `Extract jar:file:<*>!/webapps/mapreduce to <*>`
	Post Template: `Extract jar:file:<*>!/webapps/mapreduce to <*>`
	Post Template: `Extract jar:file:<*>!/webapps/mapreduce to <*>`
	============ Aggregate ====================
	Aggregated Template:  Extract jar:file:<*>!/webapps/mapreduce to <*>
[UpdateBucket] Logs: This iter found: 69, total: 167860/179993, remain: 12133. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2748 -> 2679, remain buckets: 73
Update Success: Time for one update logs: 0.0483248233795166, template `Extract jar:file:<*>!/webapps/mapreduce to <*>`
========================================================================================


Iteration 71
Sample 3 from current logs bucket: ID: 243, Len: 12, Bucket Size: 529, Total Buckets: 269
Sampling from 47 logs, Sim Level: 8, MaxSim to anchor: 0.3529. Anchor: `completedMapPercent 0.53846157 totalResourceLimit:<memory:16384, vCores:-4> finalMapResourceLimit:<memory:8192, vCores:-2> finalReduceResourceLimit:<memory:8192, vCores:-2> netScheduledMapResource:<memory:12288, vCores:12> netScheduledReduceResource:<memory:0, vCores:0>`, MaxSim Log: `completedMapPercent 0.07692308 totalResourceLimit:<memory:8192, vCores:-27> finalMapResourceLimit:<memory:7562, vCores:-25> finalReduceResourceLimit:<memory:630, vCores:-2> netScheduledMapResource:<memory:12288, vCores:12> netScheduledReduceResource:<memory:0, vCores:0>`.
	============  Query  ====================
	Log[1]: `completedMapPercent 0.53846157 totalResourceLimit:<memory:16384, vCores:-4> finalMapResourceLimit:<memory:8192, vCores:-2> finalReduceResourceLimit:<memory:8192, vCores:-2> netScheduledMapResource:<memory:12288, vCores:12> netScheduledReduceResource:<memory:0, vCores:0>`
	============ Response ====================
LogTemplate[1]: `completedMapPercent {number} totalResourceLimit:<memory:{number}, vCores:{number}> finalMapResourceLimit:<memory:{number}, vCores:{number}> finalReduceResourceLimit:<memory:{number}, vCores:{number}> netScheduledMapResource:<memory:{number}, vCores:{number}> netScheduledReduceResource:<memory:{number}, vCores:{number}>`
	============ PostProcess ====================
	Post Template: `completedMapPercent <*> totalResourceLimit:<memory:<*>, vCores:<*> finalMapResourceLimit:<memory:<*>, vCores:<*> finalReduceResourceLimit:<memory:<*>, vCores:<*> netScheduledMapResource:<memory:<*>, vCores:<*> netScheduledReduceResource:<memory:<*>, vCores:<*>`
	============ Aggregate ====================
	Aggregated Template:  completedMapPercent <*> totalResourceLimit:<memory:<*>, vCores:<*> finalMapResourceLimit:<memory:<*>, vCores:<*> finalReduceResourceLimit:<memory:<*>, vCores:<*> netScheduledMapResource:<memory:<*>, vCores:<*> netScheduledReduceResource:<memory:<*>, vCores:<*>
[UpdateBucket] Logs: This iter found: 531, total: 168391/179993, remain: 11602. 
[UpdateBucket] Buckets: Checked 2 ([243, 244]), Parent Bucket size: 687 -> 156, remain buckets: 72
Update Success: Time for one update logs: 0.04097890853881836, template `completedMapPercent <*> totalResourceLimit:<memory:<*>, vCores:<*> finalMapResourceLimit:<memory:<*>, vCores:<*> finalReduceResourceLimit:<memory:<*>, vCores:<*> netScheduledMapResource:<memory:<*>, vCores:<*> netScheduledReduceResource:<memory:<*>, vCores:<*>`
========================================================================================


Iteration 72
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 509, Total Buckets: 269
Sampling from 132 logs failed
	============  Query  ====================
	Log[1]: `Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)`
	============ Response ====================
LogTemplate[1]: `Added global filter '{filter_name}' (class={class_name})`
	============ PostProcess ====================
	Post Template: `Added global filter <*> (class=<*>)`
	============ Aggregate ====================
	Aggregated Template:  Added global filter <*> (class=<*>)
[UpdateBucket] Logs: This iter found: 69, total: 168460/179993, remain: 11533. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1793 -> 1724, remain buckets: 72
Update Success: Time for one update logs: 0.027441024780273438, template `Added global filter <*> (class=<*>)`
========================================================================================


Iteration 73
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 502, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.2000. Anchor: `maxTaskFailuresPerNode is 3`, MaxSim Log: `blacklistDisablePercent is 33`.
	============  Query  ====================
	Log[1]: `maxTaskFailuresPerNode is 3`
	============ Response ====================
LogTemplate[1]: `maxTaskFailuresPerNode is {number}`
	============ PostProcess ====================
	Post Template: `maxTaskFailuresPerNode is <*>`
	============ Aggregate ====================
	Aggregated Template:  maxTaskFailuresPerNode is <*>
[UpdateBucket] Logs: This iter found: 69, total: 168529/179993, remain: 11464. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 502 -> 433, remain buckets: 72
Update Success: Time for one update logs: 0.01618504524230957, template `maxTaskFailuresPerNode is <*>`
========================================================================================


Iteration 74
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 499, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Registered webapp guice modules`
	============ Response ====================
LogTemplate[1]: `Registered webapp guice modules`
	============ PostProcess ====================
	Post Template: `Registered webapp guice modules`
	============ Aggregate ====================
	Aggregated Template:  Registered webapp guice modules
[UpdateBucket] Logs: This iter found: 69, total: 168598/179993, remain: 11395. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2679 -> 2610, remain buckets: 72
Update Success: Time for one update logs: 0.03941607475280762, template `Registered webapp guice modules`
========================================================================================


Iteration 75
Sample 1 from current logs bucket: ID: 41, Len: 4, Bucket Size: 480, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `ERROR IN CONTACTING RM.`
	============ Response ====================
LogTemplate[1]: `ERROR IN CONTACTING RM.`
	============ PostProcess ====================
	Post Template: `ERROR IN CONTACTING RM.`
	============ Aggregate ====================
	Aggregated Template:  ERROR IN CONTACTING RM.
[UpdateBucket] Logs: This iter found: 480, total: 169078/179993, remain: 10915. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2610 -> 2130, remain buckets: 71
Update Success: Time for one update logs: 0.04668283462524414, template `ERROR IN CONTACTING RM.`
========================================================================================


Iteration 76
Sample 3 from current logs bucket: ID: 81, Len: 7, Bucket Size: 469, Total Buckets: 269
Sampling from 434 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `for url=13562/mapOutput?job=job_1445087491445_0005&reduce=0&map=attempt_1445087491445_0005_m_000010_0 sent hash and received reply`, MaxSim Log: `for url=13562/mapOutput?job=job_1445087491445_0005&reduce=0&map=attempt_1445087491445_0005_m_000000_0,attempt_1445087491445_0005_m_000001_0 sent hash and received reply`.
	============  Query  ====================
	Log[1]: `for url=13562/mapOutput?job=job_1445087491445_0005&reduce=0&map=attempt_1445087491445_0005_m_000010_0 sent hash and received reply`
	Log[2]: `for url=13562/mapOutput?job=job_1445062781478_0020&reduce=0&map=attempt_1445062781478_0020_m_000005_0 sent hash and received reply`
	Log[3]: `for url=13562/mapOutput?job=job_1445087491445_0002&reduce=0&map=attempt_1445087491445_0002_m_000006_1000 sent hash and received reply`
	============ Response ====================
LogTemplate[1]: `for url={url}/mapOutput?job={job}&reduce=0&map=attempt_{attempt}_m_{task}_<*> sent hash and received reply`
LogTemplate[2]: `for url={url}/mapOutput?job={job}&reduce=0&map=attempt_{attempt}_m_{task}_<*> sent hash and received reply`
LogTemplate[3]: `for url={url}/mapOutput?job={job}&reduce=0&map=attempt_{attempt}_m_{task}_<*> sent hash and received reply`
	============ PostProcess ====================
	Post Template: `for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply`
	Post Template: `for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply`
	Post Template: `for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply`
	============ Aggregate ====================
	Aggregated Template:  for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply
[UpdateBucket] Logs: This iter found: 469, total: 169547/179993, remain: 10446. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1674 -> 1205, remain buckets: 70
Update Success: Time for one update logs: 0.08736991882324219, template `for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply`
========================================================================================


Iteration 77
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 440, Total Buckets: 269
Sampling from 71 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Jetty bound to port 32067`, MaxSim Log: `Jetty bound to port 19907`.
	============  Query  ====================
	Log[1]: `Jetty bound to port 32067`
	Log[2]: `Jetty bound to port 22924`
	Log[3]: `Jetty bound to port 49789`
	============ Response ====================
LogTemplate[1]: `Jetty bound to port {port}`
LogTemplate[2]: `Jetty bound to port {port}`
LogTemplate[3]: `Jetty bound to port {port}`
	============ PostProcess ====================
	Post Template: `Jetty bound to port <*>`
	Post Template: `Jetty bound to port <*>`
	Post Template: `Jetty bound to port <*>`
	============ Aggregate ====================
	Aggregated Template:  Jetty bound to port <*>
[UpdateBucket] Logs: This iter found: 69, total: 169616/179993, remain: 10377. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1724 -> 1655, remain buckets: 70
Update Success: Time for one update logs: 0.020517826080322266, template `Jetty bound to port <*>`
========================================================================================


Iteration 78
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 433, Total Buckets: 269
Sampling from 13 logs failed
	============  Query  ====================
	Log[1]: `blacklistDisablePercent is 33`
	============ Response ====================
LogTemplate[1]: `blacklistDisablePercent is {number}`
	============ PostProcess ====================
	Post Template: `blacklistDisablePercent is <*>`
	============ Aggregate ====================
	Aggregated Template:  blacklistDisablePercent is <*>
[UpdateBucket] Logs: This iter found: 69, total: 169685/179993, remain: 10308. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 433 -> 364, remain buckets: 70
[TemplateDB] Try Merge: `blacklistDisablePercent is <*>` | `maxTaskFailuresPerNode is <*>`
[TemplateDB] Reject Merge, Remain Template: `blacklistDisablePercent is <*>`
Update Success: Time for one update logs: 0.018597126007080078, template `blacklistDisablePercent is <*>`
========================================================================================


Iteration 79
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 430, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Calling handler for JobFinishedEvent`
	============ Response ====================
LogTemplate[1]: `Calling handler for JobFinishedEvent`
	============ PostProcess ====================
	Post Template: `Calling handler for JobFinishedEvent`
	============ Aggregate ====================
	Aggregated Template:  Calling handler for JobFinishedEvent
[UpdateBucket] Logs: This iter found: 47, total: 169732/179993, remain: 10261. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2130 -> 2083, remain buckets: 70
Update Success: Time for one update logs: 0.040827035903930664, template `Calling handler for JobFinishedEvent`
========================================================================================


Iteration 80
Sample 1 from current logs bucket: ID: 50, Len: 5, Bucket Size: 414, Total Buckets: 269
Sampling from 128 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `attempt_1445087491445_0005_r_000000_0: Got 3 new map-outputs`, MaxSim Log: `attempt_1445087491445_0005_r_000000_0: Got 1 new map-outputs`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_r_000000_0: Got 3 new map-outputs`
	Log[2]: `attempt_1445144423722_0021_r_000000_0: Got 3 new map-outputs`
	Log[3]: `attempt_1445062781478_0014_r_000000_0: Got 3 new map-outputs`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_r_{task_id}_0: Got 3 new map-outputs`
	============ PostProcess ====================
	Post Template: `<*>: Got <*> new map-outputs`
	Post Template: `<*>: Got <*> new map-outputs`
	Post Template: `<*>: Got <*> new map-outputs`
	============ Aggregate ====================
	Aggregated Template:  <*>: Got <*> new map-outputs
[UpdateBucket] Logs: This iter found: 414, total: 170146/179993, remain: 9847. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1655 -> 1241, remain buckets: 69
Update Success: Time for one update logs: 0.032312870025634766, template `<*>: Got <*> new map-outputs`
========================================================================================


Iteration 81
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 383, Total Buckets: 269
Sampling from 94 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1.jhist to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`, MaxSim Log: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`.
	============  Query  ====================
	Log[1]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1.jhist to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	Log[2]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0015/job_1445182159119_0015_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	Log[3]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0008/job_1445087491445_0008_2_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	============ Response ====================
LogTemplate[1]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_1.jhist to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`

LogTemplate[2]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_1_conf.xml to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`

LogTemplate[3]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_2_conf.xml to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`
	============ PostProcess ====================
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1.jhist to hdfs://<*>/tmp/hadoop-yarn/staging`
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_2_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
	============ Aggregate ====================
	Aggregated Template:  Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1.jhist to hdfs://<*>/tmp/hadoop-yarn/staging
[UpdateBucket] Logs: This iter found: 33, total: 170179/179993, remain: 9814. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2083 -> 2050, remain buckets: 69
Update Success: Time for one update logs: 0.03826117515563965, template `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1.jhist to hdfs://<*>/tmp/hadoop-yarn/staging`
========================================================================================


Iteration 82
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 381, Total Buckets: 269
Sampling from 14 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `I/O error constructing remote block reader.`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`.
	============  Query  ====================
	Log[1]: `I/O error constructing remote block reader.`
	============ Response ====================
LogTemplate[1]: `I/O error constructing remote block reader.`
	============ PostProcess ====================
	Post Template: `I/O error constructing remote block reader.`
	============ Aggregate ====================
	Aggregated Template:  I/O error constructing remote block reader.
[UpdateBucket] Logs: This iter found: 16, total: 170195/179993, remain: 9798. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 2041 -> 2025, remain buckets: 69
Update Success: Time for one update logs: 0.0260159969329834, template `I/O error constructing remote block reader.`
========================================================================================


Iteration 83
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 371, Total Buckets: 269
Sampling from 2 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Connecting to ResourceManager at MSRA-SA-41/10.190.173.170:8030`, MaxSim Log: `Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030`.
	============  Query  ====================
	Log[1]: `Connecting to ResourceManager at MSRA-SA-41/10.190.173.170:8030`
	Log[2]: `Connecting to ResourceManager at msra-sa-41/10.190.173.170:8030`
	============ Response ====================
LogTemplate[1]: `Connecting to ResourceManager at {api}/{ip_or_url}:{port}`  
LogTemplate[2]: `Connecting to ResourceManager at {api}/{ip_or_url}:{port}`  
	============ PostProcess ====================
	Post Template: `Connecting to ResourceManager at <*>`
	Post Template: `Connecting to ResourceManager at <*>`
	============ Aggregate ====================
	Aggregated Template:  Connecting to ResourceManager at <*>
[UpdateBucket] Logs: This iter found: 69, total: 170264/179993, remain: 9729. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1241 -> 1172, remain buckets: 69
Update Success: Time for one update logs: 0.025087833404541016, template `Connecting to ResourceManager at <*>`
========================================================================================


Iteration 84
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 365, Total Buckets: 269
Sampling from 35 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `Successfully connected to /10.190.173.170:50010 for BP-1347369012-10.190.173.170-1444972147527:blk_1073742826_2022`, MaxSim Log: `Successfully connected to /10.190.173.170:50010 for BP-1347369012-10.190.173.170-1444972147527:blk_1073742829_2025`.
	============  Query  ====================
	Log[1]: `Successfully connected to /10.190.173.170:50010 for BP-1347369012-10.190.173.170-1444972147527:blk_1073742826_2022`
	Log[2]: `Successfully connected to /10.190.173.170:50010 for BP-1347369012-10.190.173.170-1444972147527:blk_1073742829_2025`
	Log[3]: `Successfully connected to /10.86.169.121:50010 for BP-1347369012-10.190.173.170-1444972147527:blk_1073744042_3267`
	============ Response ====================
LogTemplate[1]: `Successfully connected to /{ip_or_url}:50010 for BP-1347369012-10.190.173.170-1444972147527:{blk_id}_<*>`
	============ PostProcess ====================
	Post Template: `Successfully connected to <*> for BP-<*>`
	Post Template: `Successfully connected to <*> for BP-<*>`
	Post Template: `Successfully connected to <*> for BP-<*>`
	============ Aggregate ====================
	Aggregated Template:  Successfully connected to <*> for BP-<*>
[UpdateBucket] Logs: This iter found: 6, total: 170270/179993, remain: 9723. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 2025 -> 2019, remain buckets: 69
Update Success: Time for one update logs: 0.02398824691772461, template `Successfully connected to <*> for BP-<*>`
========================================================================================


Iteration 85
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 365, Total Buckets: 269
Sampling from 95 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`, MaxSim Log: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_0'`.
	============  Query  ====================
	Log[1]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
	Log[2]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445094324383_0004_m_000003_0'`
	Log[3]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0002_m_000007_0'`
	============ Response ====================
LogTemplate[1]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[2]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[3]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ PostProcess ====================
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ Aggregate ====================
	Aggregated Template:  Ignoring obsolete output of KILLED map-task: '<map_task_id>'
[UpdateBucket] Logs: This iter found: 0, total: 170270/179993, remain: 9723. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1205 -> 1205, remain buckets: 69
Update failed: Template can not match logs `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 365, Total Buckets: 269
Sampling from 95 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`, MaxSim Log: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_0'`.
	============  Query  ====================
	Log[1]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
	Log[2]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0002_m_000006_1'`
	Log[3]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445094324383_0005_m_000006_0'`
	============ Response ====================
LogTemplate[1]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[2]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[3]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ PostProcess ====================
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ Aggregate ====================
	Aggregated Template:  Ignoring obsolete output of KILLED map-task: '<map_task_id>'
[UpdateBucket] Logs: This iter found: 0, total: 170270/179993, remain: 9723. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1205 -> 1205, remain buckets: 69
Update failed: Template can not match logs `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 365, Total Buckets: 269
Sampling from 95 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`, MaxSim Log: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_0'`.
	============  Query  ====================
	Log[1]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
	Log[2]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445182159119_0015_m_000003_1'`
	Log[3]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000008_0'`
	============ Response ====================
LogTemplate[1]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[2]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
LogTemplate[3]: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ PostProcess ====================
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`
	============ Aggregate ====================
	Aggregated Template:  Ignoring obsolete output of KILLED map-task: '<map_task_id>'
[UpdateBucket] Logs: This iter found: 0, total: 170270/179993, remain: 9723. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1205 -> 1205, remain buckets: 69
Update failed: Template can not match logs `Ignoring obsolete output of KILLED map-task: '<map_task_id>'`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
[UpdateBucket] Logs: This iter found: 2, total: 170272/179993, remain: 9721. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1205 -> 1203, remain buckets: 69
Update Success: Time for one update logs: 0.05130791664123535, template `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
========================================================================================


Iteration 86
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 364, Total Buckets: 269
Sampling from 12 logs failed
	============  Query  ====================
	Log[1]: `maxContainerCapability: <memory:8192, vCores:32>`
	============ Response ====================
LogTemplate[1]: `maxContainerCapability: <memory:{memory}, vCores:{vcores}>`
	============ PostProcess ====================
	Post Template: `maxContainerCapability: <memory:<*>, vCores:<*>`
	============ Aggregate ====================
	Aggregated Template:  maxContainerCapability: <memory:<*>, vCores:<*>
[UpdateBucket] Logs: This iter found: 69, total: 170341/179993, remain: 9652. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 364 -> 295, remain buckets: 69
Update Success: Time for one update logs: 0.015249013900756836, template `maxContainerCapability: <memory:<*>, vCores:<*>`
========================================================================================


Iteration 87
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 363, Total Buckets: 269
Sampling from 94 logs, Sim Level: 3, MaxSim to anchor: 0.7500. Anchor: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_0'`, MaxSim Log: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000007_0'`.
	============  Query  ====================
	Log[1]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_0'`
	Log[2]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0004_m_000004_0'`
	Log[3]: `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0010_m_000000_0'`
	============ Response ====================
LogTemplate[1]: `Ignoring obsolete output of KILLED map-task: '{map_task_id}'`
LogTemplate[2]: `Ignoring obsolete output of KILLED map-task: '{map_task_id}'`
LogTemplate[3]: `Ignoring obsolete output of KILLED map-task: '{map_task_id}'`
	============ PostProcess ====================
	Post Template: `Ignoring obsolete output of KILLED map-task: '<*>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<*>'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<*>'`
	============ Aggregate ====================
	Aggregated Template:  Ignoring obsolete output of KILLED map-task: '<*>'
[UpdateBucket] Logs: This iter found: 64, total: 170405/179993, remain: 9588. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1203 -> 1139, remain buckets: 69
[TemplateDB] Try Merge: `Ignoring obsolete output of KILLED map-task: '<*>'` | `Ignoring obsolete output of KILLED map-task: 'attempt_1445087491445_0005_m_000011_1'`
	Post Template: `Ignoring obsolete output of KILLED map-task: '<*>'`
[TemplateDB] Merged: -> `Ignoring obsolete output of KILLED map-task: '<*>'`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 66/66, in child Bucket [79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]
Update Success: Time for one update logs: 0.12755990028381348, template `Ignoring obsolete output of KILLED map-task: '<*>'`
========================================================================================


Iteration 88
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 359, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10`, MaxSim Log: `MergerManager: memoryLimit=140928608, maxSingleShuffleLimit=35232152, mergeThreshold=93012888, ioSortFactor=10, memToMemMergeOutputsThreshold=10`.
	============  Query  ====================
	Log[1]: `MergerManager: memoryLimit=130652568, maxSingleShuffleLimit=32663142, mergeThreshold=86230696, ioSortFactor=10, memToMemMergeOutputsThreshold=10`
	============ Response ====================
LogTemplate[1]: `MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>`
	============ PostProcess ====================
	Post Template: `MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>`
	============ Aggregate ====================
	Aggregated Template:  MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>
[UpdateBucket] Logs: This iter found: 71, total: 170476/179993, remain: 9517. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 2019 -> 1948, remain buckets: 69
Update Success: Time for one update logs: 0.03234267234802246, template `MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>`
========================================================================================


Iteration 89
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 350, Total Buckets: 269
Sampling from 61 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`, MaxSim Log: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job_1445062781478_0018_2.jhist to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`.
	============  Query  ====================
	Log[1]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	Log[2]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0014/job_1445062781478_0014_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	Log[3]: `Copying hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445094324383_0005/job_1445094324383_0005_1_conf.xml to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	============ Response ====================
LogTemplate[1]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_1_conf.xml to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`  
LogTemplate[2]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_1_conf.xml to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`  
LogTemplate[3]: `Copying hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/{job_id}_1_conf.xml to hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`  
	============ PostProcess ====================
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
	============ Aggregate ====================
	Aggregated Template:  Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging
[UpdateBucket] Logs: This iter found: 33, total: 170509/179993, remain: 9484. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2050 -> 2017, remain buckets: 69
[TemplateDB] Try Merge: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging` | `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1.jhist to hdfs://<*>/tmp/hadoop-yarn/staging`
	Post Template: `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1<*> to hdfs://<*>/tmp/hadoop-yarn/staging`
[TemplateDB] Merged: -> `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1<*> to hdfs://<*>/tmp/hadoop-yarn/staging`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 66/66, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]
[UpdateBucket] Logs: This iter found: 28, total: 170537/179993, remain: 9456. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 2017 -> 1989, remain buckets: 69
[TemplateDB] Update Indexes: 66 -> 94 for `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1<*> to hdfs://<*>/tmp/hadoop-yarn/staging`
[TemplateBaseUpdate] Match unparsed logs 28 with new template `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1<*> to hdfs://<*>/tmp/hadoop-yarn/staging`
Update Success: Time for one update logs: 0.08585619926452637, template `Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1_conf.xml to hdfs://<*>/tmp/hadoop-yarn/staging`
========================================================================================


Iteration 90
Sample 3 from current logs bucket: ID: 54, Len: 5, Bucket Size: 317, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `MapTask metrics system shutdown complete.`, MaxSim Log: `ReduceTask metrics system shutdown complete.`.
	============  Query  ====================
	Log[1]: `MapTask metrics system shutdown complete.`
	Log[2]: `ReduceTask metrics system shutdown complete.`
	============ Response ====================
LogTemplate[1]: `MapTask metrics system shutdown complete.`  
LogTemplate[2]: `ReduceTask metrics system shutdown complete.`  
	============ PostProcess ====================
	Post Template: `MapTask metrics system shutdown complete.`
	Post Template: `ReduceTask metrics system shutdown complete.`
	============ Aggregate ====================
	Aggregated Template:  MapTask metrics system shutdown complete.
[UpdateBucket] Logs: This iter found: 302, total: 170839/179993, remain: 9154. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 1172 -> 870, remain buckets: 69
Update Success: Time for one update logs: 0.01948094367980957, template `MapTask metrics system shutdown complete.`
========================================================================================


Iteration 91
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 309, Total Buckets: 269
Sampling from 68 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:32067`, MaxSim Log: `Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:19907`.
	============  Query  ====================
	Log[1]: `Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:32067`
	============ Response ====================
LogTemplate[1]: `Started HttpServer2$SelectChannelConnectorWithSafeStartup@{ip_or_port}`
	============ PostProcess ====================
	Post Template: `Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>`
	============ Aggregate ====================
	Aggregated Template:  Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>
[UpdateBucket] Logs: This iter found: 69, total: 170908/179993, remain: 9085. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 309 -> 240, remain buckets: 69
Update Success: Time for one update logs: 0.01592397689819336, template `Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>`
========================================================================================


Iteration 92
Sample 3 from current logs bucket: ID: 13, Len: 4, Bucket Size: 302, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `MapTask metrics system stopped.`
	============ Response ====================
LogTemplate[1]: `MapTask metrics system stopped.`
	============ PostProcess ====================
	Post Template: `MapTask metrics system stopped.`
	============ Aggregate ====================
	Aggregated Template:  MapTask metrics system stopped.
[UpdateBucket] Logs: This iter found: 302, total: 171210/179993, remain: 8783. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1989 -> 1687, remain buckets: 68
[TemplateDB] Try Merge: `MapTask metrics system stopped.` | `MapTask metrics system started`
[TemplateDB] Reject Merge, Remain Template: `MapTask metrics system stopped.`
Update Success: Time for one update logs: 0.03547310829162598, template `MapTask metrics system stopped.`
========================================================================================


Iteration 93
Sample 3 from current logs bucket: ID: 37, Len: 4, Bucket Size: 302, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Stopping MapTask metrics system...`
	============ Response ====================
LogTemplate[1]: `Stopping MapTask metrics system...`
	============ PostProcess ====================
	Post Template: `Stopping MapTask metrics system...`
	============ Aggregate ====================
	Aggregated Template:  Stopping MapTask metrics system...
[UpdateBucket] Logs: This iter found: 302, total: 171512/179993, remain: 8481. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1687 -> 1385, remain buckets: 67
Update Success: Time for one update logs: 0.03782796859741211, template `Stopping MapTask metrics system...`
========================================================================================


Iteration 94
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 302, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.1111. Anchor: `Size of containertokens_dob is 1`, MaxSim Log: `1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com`.
	============  Query  ====================
	Log[1]: `Size of containertokens_dob is 1`
	============ Response ====================
LogTemplate[1]: `Size of {container_name} is {number}`
	============ PostProcess ====================
	Post Template: `Size of <*> is <*>`
	============ Aggregate ====================
	Aggregated Template:  Size of <*> is <*>
[UpdateBucket] Logs: This iter found: 69, total: 171581/179993, remain: 8412. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 870 -> 801, remain buckets: 67
Update Success: Time for one update logs: 0.01957106590270996, template `Size of <*> is <*>`
========================================================================================


Iteration 95
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 299, Total Buckets: 269
Sampling from 53 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `MRAppMaster launching normal, non-uberized, multi-container job job_1445087491445_0005.`, MaxSim Log: `MRAppMaster launching normal, non-uberized, multi-container job job_1445062781478_0018.`.
	============  Query  ====================
	Log[1]: `MRAppMaster launching normal, non-uberized, multi-container job job_1445087491445_0005.`
	Log[2]: `MRAppMaster launching normal, non-uberized, multi-container job job_1445144423722_0024.`
	Log[3]: `MRAppMaster launching normal, non-uberized, multi-container job job_1445087491445_0006.`
	============ Response ====================
LogTemplate[1]: `MRAppMaster launching normal, non-uberized, multi-container job {job_id}.`
	============ PostProcess ====================
	Post Template: `MRAppMaster launching normal, non-uberized, multi-container job <*>.`
	Post Template: `MRAppMaster launching normal, non-uberized, multi-container job <*>.`
	Post Template: `MRAppMaster launching normal, non-uberized, multi-container job <*>.`
	============ Aggregate ====================
	Aggregated Template:  MRAppMaster launching normal, non-uberized, multi-container job <*>.
[UpdateBucket] Logs: This iter found: 69, total: 171650/179993, remain: 8343. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1139 -> 1070, remain buckets: 67
Update Success: Time for one update logs: 0.07301092147827148, template `MRAppMaster launching normal, non-uberized, multi-container job <*>.`
========================================================================================


Iteration 96
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 295, Total Buckets: 269
Sampling from 11 logs failed
	============  Query  ====================
	Log[1]: `yarn.client.max-cached-nodemanagers-proxies : 0`
	============ Response ====================
LogTemplate[1]: `yarn.client.max-cached-nodemanagers-proxies : {number}`
	============ PostProcess ====================
	Post Template: `yarn.client.max-cached-nodemanagers-proxies : <*>`
	============ Aggregate ====================
	Aggregated Template:  yarn.client.max-cached-nodemanagers-proxies : <*>
[UpdateBucket] Logs: This iter found: 69, total: 171719/179993, remain: 8274. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 295 -> 226, remain buckets: 67
Update Success: Time for one update logs: 0.015046358108520508, template `yarn.client.max-cached-nodemanagers-proxies : <*>`
========================================================================================


Iteration 97
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 289, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Setting job diagnostics to`
	============ Response ====================
LogTemplate[1]: `Setting job diagnostics to {placeholder}`
	============ PostProcess ====================
	Post Template: `Setting job diagnostics to <*>`
	============ Aggregate ====================
	Aggregated Template:  Setting job diagnostics to <*>
[UpdateBucket] Logs: This iter found: 0, total: 171719/179993, remain: 8274. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1385 -> 1385, remain buckets: 67
Update failed: Template can not match logs `Setting job diagnostics to <*>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 1 from current logs bucket: ID: 48, Len: 4, Bucket Size: 289, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Setting job diagnostics to`
	============ Response ====================
LogTemplate[1]: `Setting job diagnostics to {placeholder}`
	============ PostProcess ====================
	Post Template: `Setting job diagnostics to <*>`
	============ Aggregate ====================
	Aggregated Template:  Setting job diagnostics to <*>
[UpdateBucket] Logs: This iter found: 0, total: 171719/179993, remain: 8274. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1385 -> 1385, remain buckets: 67
Update failed: Template can not match logs `Setting job diagnostics to <*>`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 1 from current logs bucket: ID: 48, Len: 4, Bucket Size: 289, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Setting job diagnostics to`
	============ Response ====================
LogTemplate[1]: `Setting job diagnostics to {placeholder}`
	============ PostProcess ====================
	Post Template: `Setting job diagnostics to <*>`
	============ Aggregate ====================
	Aggregated Template:  Setting job diagnostics to <*>
[UpdateBucket] Logs: This iter found: 0, total: 171719/179993, remain: 8274. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1385 -> 1385, remain buckets: 67
Update failed: Template can not match logs `Setting job diagnostics to <*>`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Setting job diagnostics to`
[UpdateBucket] Logs: This iter found: 48, total: 171767/179993, remain: 8226. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1385 -> 1337, remain buckets: 67
Update Success: Time for one update logs: 0.02200484275817871, template `Setting job diagnostics to`
========================================================================================


Iteration 98
Sample 1 from current logs bucket: ID: 78, Len: 6, Bucket Size: 288, Total Buckets: 269
Sampling from 12 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server`, MaxSim Log: `Calling stop for all the services`.
	============  Query  ====================
	Log[1]: `Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server`
	============ Response ====================
LogTemplate[1]: `Adding protocol {api} to the server`
	============ PostProcess ====================
	Post Template: `Adding protocol <*> to the server`
	============ Aggregate ====================
	Aggregated Template:  Adding protocol <*> to the server
[UpdateBucket] Logs: This iter found: 69, total: 171836/179993, remain: 8157. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1948 -> 1879, remain buckets: 67
Update Success: Time for one update logs: 0.025466203689575195, template `Adding protocol <*> to the server`
========================================================================================


Iteration 99
Sample 3 from current logs bucket: ID: 70, Len: 6, Bucket Size: 255, Total Buckets: 269
Sampling from 184 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445087491445_0005_m_000011`, MaxSim Log: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445087491445_0005_m_000009`.
	============  Query  ====================
	Log[1]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445087491445_0005_m_000011`
	Log[2]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445087491445_0003_m_000009`
	Log[3]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1445175094696_0001_m_000002`
	============ Response ====================
LogTemplate[1]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_{task_id}_m_{attempt_id}`
LogTemplate[2]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_{task_id}_m_{attempt_id}`
LogTemplate[3]: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_{task_id}_m_{attempt_id}`
	============ PostProcess ====================
	Post Template: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>`
	Post Template: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>`
	Post Template: `DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>`
	============ Aggregate ====================
	Aggregated Template:  DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
[UpdateBucket] Logs: This iter found: 255, total: 172091/179993, remain: 7902. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1879 -> 1624, remain buckets: 66
Update Success: Time for one update logs: 0.028717041015625, template `DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>`
========================================================================================


Iteration 100
Sample 3 from current logs bucket: ID: 91, Len: 7, Bucket Size: 255, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `We launched 1 speculations. Sleeping 15000 milliseconds.`
	============ Response ====================
LogTemplate[1]: `We launched {number} speculations. Sleeping {milliseconds} milliseconds.`
	============ PostProcess ====================
	Post Template: `We launched <*> speculations. Sleeping <*> milliseconds.`
	============ Aggregate ====================
	Aggregated Template:  We launched <*> speculations. Sleeping <*> milliseconds.
[UpdateBucket] Logs: This iter found: 255, total: 172346/179993, remain: 7647. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1070 -> 815, remain buckets: 65
Update Success: Time for one update logs: 0.09071588516235352, template `We launched <*> speculations. Sleeping <*> milliseconds.`
========================================================================================


Iteration 101
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 241, Total Buckets: 269
Sampling from 48 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445087491445_0005`, MaxSim Log: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445062781478_0018`.
	============  Query  ====================
	Log[1]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445087491445_0005`
	Log[2]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445087491445_0003`
	Log[3]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445094324383_0002`
	============ Response ====================
LogTemplate[1]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/{job_id}`  
LogTemplate[2]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/{job_id}`  
LogTemplate[3]: `History url is http://MSRA-SA-41.fareast.corp.microsoft.com:19888/jobhistory/job/{job_id}`  
	============ PostProcess ====================
	Post Template: `History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>`
	Post Template: `History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>`
	Post Template: `History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>`
	============ Aggregate ====================
	Aggregated Template:  History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>
[UpdateBucket] Logs: This iter found: 29, total: 172375/179993, remain: 7618. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1337 -> 1308, remain buckets: 65
Update Success: Time for one update logs: 0.035681962966918945, template `History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>`
========================================================================================


Iteration 102
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 240, Total Buckets: 269
Sampling from 53 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `JOB_CREATE job_1445087491445_0005`, MaxSim Log: `JOB_CREATE job_1445062781478_0018`.
	============  Query  ====================
	Log[1]: `JOB_CREATE job_1445087491445_0005`
	============ Response ====================
LogTemplate[1]: `JOB_CREATE {job_id}`
	============ PostProcess ====================
	Post Template: `JOB_CREATE <*>`
	============ Aggregate ====================
	Aggregated Template:  JOB_CREATE <*>
[UpdateBucket] Logs: This iter found: 69, total: 172444/179993, remain: 7549. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 240 -> 171, remain buckets: 65
[TemplateDB] Try Merge: `JOB_CREATE <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `JOB_CREATE <*>`
Update Success: Time for one update logs: 0.011873960494995117, template `JOB_CREATE <*>`
========================================================================================


Iteration 103
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 233, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Putting shuffle token in serviceData`
	============ Response ====================
LogTemplate[1]: `Putting shuffle token in {placeholder}`
	============ PostProcess ====================
	Post Template: `Putting shuffle token in <*>`
	============ Aggregate ====================
	Aggregated Template:  Putting shuffle token in <*>
[UpdateBucket] Logs: This iter found: 69, total: 172513/179993, remain: 7480. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 801 -> 732, remain buckets: 65
Update Success: Time for one update logs: 0.020477771759033203, template `Putting shuffle token in <*>`
========================================================================================


Iteration 104
Sample 1 from current logs bucket: ID: 215, Len: 7, Bucket Size: 230, Total Buckets: 269
Sampling from 111 logs failed
	============  Query  ====================
	Log[1]: `Reduce slow start threshold reached. Scheduling reduces.`
	============ Response ====================
LogTemplate[1]: `Reduce slow start threshold reached. Scheduling reduces.`
	============ PostProcess ====================
	Post Template: `Reduce slow start threshold reached. Scheduling reduces.`
	============ Aggregate ====================
	Aggregated Template:  Reduce slow start threshold reached. Scheduling reduces.
[UpdateBucket] Logs: This iter found: 65, total: 172578/179993, remain: 7415. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 815 -> 750, remain buckets: 65
Update Success: Time for one update logs: 0.07876801490783691, template `Reduce slow start threshold reached. Scheduling reduces.`
========================================================================================


Iteration 105
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 226, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Exception in createBlockOutputStream`
	============ Response ====================
LogTemplate[1]: `Exception in createBlockOutputStream`
	============ PostProcess ====================
	Post Template: `Exception in createBlockOutputStream`
	============ Aggregate ====================
	Aggregated Template:  Exception in createBlockOutputStream
[UpdateBucket] Logs: This iter found: 30, total: 172608/179993, remain: 7385. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 226 -> 196, remain buckets: 65
Update Success: Time for one update logs: 0.009831905364990234, template `Exception in createBlockOutputStream`
========================================================================================


Iteration 106
Sample 1 from current logs bucket: ID: 20, Len: 4, Bucket Size: 226, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Default file system [hdfs://msra-sa-41:9000]`
	============ Response ====================
LogTemplate[1]: `Default file system [hdfs://{ip_or_url}:{port}]`
	============ PostProcess ====================
	Post Template: `Default file system [hdfs://<*>]`
	============ Aggregate ====================
	Aggregated Template:  Default file system [hdfs://<*>]
[UpdateBucket] Logs: This iter found: 226, total: 172834/179993, remain: 7159. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1308 -> 1082, remain buckets: 64
Update Success: Time for one update logs: 0.03336000442504883, template `Default file system [hdfs://<*>]`
========================================================================================


Iteration 107
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 219, Total Buckets: 269
Sampling from 83 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Web app /mapreduce started at 32067`, MaxSim Log: `Web app /mapreduce started at 19907`.
	============  Query  ====================
	Log[1]: `Web app /mapreduce started at 32067`
	Log[2]: `Web app /mapreduce started at 24289`
	Log[3]: `Web app /mapreduce started at 49789`
	============ Response ====================
LogTemplate[1]: `Web app /mapreduce started at {port}`  
LogTemplate[2]: `Web app /mapreduce started at {port}`  
LogTemplate[3]: `Web app /mapreduce started at {port}`  
	============ PostProcess ====================
	Post Template: `Web app /mapreduce started at <*>`
	Post Template: `Web app /mapreduce started at <*>`
	Post Template: `Web app /mapreduce started at <*>`
	============ Aggregate ====================
	Aggregated Template:  Web app /mapreduce started at <*>
[UpdateBucket] Logs: This iter found: 69, total: 172903/179993, remain: 7090. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1624 -> 1555, remain buckets: 64
Update Success: Time for one update logs: 0.023392915725708008, template `Web app /mapreduce started at <*>`
========================================================================================


Iteration 108
Sample 3 from current logs bucket: ID: 259, Len: 23, Bucket Size: 217, Total Buckets: 269
Sampling from 113 logs, Sim Level: 2, MaxSim to anchor: 0.9167. Anchor: `Socket Reader #1 for port 32070: readAndProcess from client 10.86.164.9 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`, MaxSim Log: `Socket Reader #1 for port 32070: readAndProcess from client 172.22.149.145 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`.
	============  Query  ====================
	Log[1]: `Socket Reader #1 for port 32070: readAndProcess from client 10.86.164.9 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	Log[2]: `Socket Reader #1 for port 4824: readAndProcess from client 10.190.173.170 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	Log[3]: `Socket Reader #1 for port 47384: readAndProcess from client 172.22.149.145 threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	============ Response ====================
LogTemplate[1]: `Socket Reader #1 for port {port}: readAndProcess from client {ip} threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
LogTemplate[2]: `Socket Reader #1 for port {port}: readAndProcess from client {ip} threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
LogTemplate[3]: `Socket Reader #1 for port {port}: readAndProcess from client {ip} threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	============ PostProcess ====================
	Post Template: `Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	Post Template: `Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	Post Template: `Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
	============ Aggregate ====================
	Aggregated Template:  Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
[UpdateBucket] Logs: This iter found: 217, total: 173120/179993, remain: 6873. 
[UpdateBucket] Buckets: Checked 1 ([259]), Parent Bucket size: 217 -> 0, remain buckets: 63
Update Success: Time for one update logs: 0.011289119720458984, template `Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]`
========================================================================================


Iteration 109
Sample 3 from current logs bucket: ID: 35, Len: 4, Bucket Size: 216, Total Buckets: 269
Sampling from 211 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000011_1`, MaxSim Log: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000011_0`.
	============  Query  ====================
	Log[1]: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000011_1`
	Log[2]: `Could not delete hdfs://msra-sa-41:9000/out/out1/_temporary/1/_temporary/attempt_1445087491445_0004_m_000007_0`
	Log[3]: `Could not delete hdfs://msra-sa-41:9000/pageout/out3/_temporary/1/_temporary/attempt_1445062781478_0018_m_000008_0`
	============ Response ====================
LogTemplate[1]: `Could not delete hdfs://{ip_or_url}/out/out2/_temporary/1/_temporary/attempt_<*>_<*>_m_000011_1`
LogTemplate[2]: `Could not delete hdfs://{ip_or_url}/out/out1/_temporary/1/_temporary/attempt_<*>_<*>_m_000007_0`
LogTemplate[3]: `Could not delete hdfs://{ip_or_url}/pageout/out3/_temporary/1/_temporary/attempt_<*>_<*>_m_000008_0`
	============ PostProcess ====================
	Post Template: `Could not delete hdfs://<*>/out/out2/_temporary/1/_temporary/attempt_<*>_<*>_m_000011_1`
	Post Template: `Could not delete hdfs://<*>/out/out1/_temporary/1/_temporary/attempt_<*>_<*>_m_000007_0`
	Post Template: `Could not delete hdfs://<*>/pageout/out3/_temporary/1/_temporary/attempt_<*>_<*>_m_000008_0`
	============ Aggregate ====================
	Aggregated Template:  Could not delete hdfs://<*>/out/out2/_temporary/1/_temporary/attempt_<*>_<*>_m_000011_1
[UpdateBucket] Logs: This iter found: 1, total: 173121/179993, remain: 6872. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1082 -> 1081, remain buckets: 63
Update Success: Time for one update logs: 0.04754471778869629, template `Could not delete hdfs://<*>/out/out2/_temporary/1/_temporary/attempt_<*>_<*>_m_000011_1`
========================================================================================


Iteration 110
Sample 3 from current logs bucket: ID: 35, Len: 4, Bucket Size: 215, Total Buckets: 269
Sampling from 210 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000011_0`, MaxSim Log: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000007_0`.
	============  Query  ====================
	Log[1]: `Could not delete hdfs://msra-sa-41:9000/out/out2/_temporary/1/_temporary/attempt_1445087491445_0005_m_000011_0`
	Log[2]: `Could not delete hdfs://msra-sa-41:9000/out/out5/_temporary/1/_temporary/attempt_1445094324383_0005_m_000008_2`
	Log[3]: `Could not delete hdfs://msra-sa-41:9000/out/out3/_temporary/1/_temporary/attempt_1445087491445_0009_m_000006_2`
	============ Response ====================
LogTemplate[1]: `Could not delete hdfs://{ip_or_url}/out/out{placeholder}/_temporary/1/_temporary/attempt_{placeholder}_m_{placeholder}_{placeholder}`
	============ PostProcess ====================
	Post Template: `Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>`
	Post Template: `Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>`
	Post Template: `Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>`
	============ Aggregate ====================
	Aggregated Template:  Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>
[UpdateBucket] Logs: This iter found: 101, total: 173222/179993, remain: 6771. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 1081 -> 980, remain buckets: 63
[TemplateDB] Try Merge: `Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>` | `Could not delete hdfs://<*>/out/out2/_temporary/1/_temporary/attempt_<*>_<*>_m_000011_1`
	Post Template: `Could not delete hdfs://<*>/out/out<*>`
[TemplateDB] Merged: -> `Could not delete hdfs://<*>/out/out<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 102/102, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]
[UpdateBucket] Logs: This iter found: 10, total: 173232/179993, remain: 6761. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 980 -> 970, remain buckets: 63
[TemplateDB] Update Indexes: 102 -> 112 for `Could not delete hdfs://<*>/out/out<*>`
[TemplateBaseUpdate] Match unparsed logs 10 with new template `Could not delete hdfs://<*>/out/out<*>`
Update Success: Time for one update logs: 0.08437609672546387, template `Could not delete hdfs://<*>/out/out<*>/_temporary/1/_temporary/attempt_<*>_m_<*>_<*>`
========================================================================================


Iteration 111
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 212, Total Buckets: 269
Sampling from 49 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Stopping server on 32070`, MaxSim Log: `Stopping server on 19911`.
	============  Query  ====================
	Log[1]: `Stopping server on 32070`
	Log[2]: `Stopping server on 56183`
	Log[3]: `Stopping server on 10559`
	============ Response ====================
LogTemplate[1]: `Stopping server on {port}`
LogTemplate[2]: `Stopping server on {port}`
LogTemplate[3]: `Stopping server on {port}`
	============ PostProcess ====================
	Post Template: `Stopping server on <*>`
	Post Template: `Stopping server on <*>`
	Post Template: `Stopping server on <*>`
	============ Aggregate ====================
	Aggregated Template:  Stopping server on <*>
[UpdateBucket] Logs: This iter found: 48, total: 173280/179993, remain: 6713. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 970 -> 922, remain buckets: 63
Update Success: Time for one update logs: 0.034713029861450195, template `Stopping server on <*>`
========================================================================================


Iteration 112
Sample 3 from current logs bucket: ID: 73, Len: 6, Bucket Size: 204, Total Buckets: 269
Sampling from 17 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Assigning MSRA-SA-39.fareast.corp.microsoft.com:13562 with 1 to fetcher#5`, MaxSim Log: `Assigning MSRA-SA-39.fareast.corp.microsoft.com:13562 with 4 to fetcher#5`.
	============  Query  ====================
	Log[1]: `Assigning MSRA-SA-39.fareast.corp.microsoft.com:13562 with 1 to fetcher#5`
	Log[2]: `Assigning 04DN8IQ.fareast.corp.microsoft.com:13562 with 1 to fetcher#5`
	Log[3]: `Assigning MSRA-SA-41.fareast.corp.microsoft.com:13562 with 7 to fetcher#5`
	============ Response ====================
LogTemplate[1]: `Assigning {hostname}:13562 with <*> to fetcher#5`
LogTemplate[2]: `Assigning {hostname}:13562 with <*> to fetcher#5`
LogTemplate[3]: `Assigning {hostname}:13562 with <*> to fetcher#5`
	============ PostProcess ====================
	Post Template: `Assigning <*> with <*> to fetcher#<*>`
	Post Template: `Assigning <*> with <*> to fetcher#<*>`
	Post Template: `Assigning <*> with <*> to fetcher#<*>`
	============ Aggregate ====================
	Aggregated Template:  Assigning <*> with <*> to fetcher#<*>
[UpdateBucket] Logs: This iter found: 472, total: 173752/179993, remain: 6241. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1555 -> 1083, remain buckets: 60
Update Success: Time for one update logs: 0.035717010498046875, template `Assigning <*> with <*> to fetcher#<*>`
========================================================================================


Iteration 113
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 196, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.5000. Anchor: `Excluding datanode 10.86.169.121:50010`, MaxSim Log: `Excluding datanode 10.86.164.9:50010`.
	============  Query  ====================
	Log[1]: `Excluding datanode 10.86.169.121:50010`
	Log[2]: `Excluding datanode 10.86.165.66:50010`
	Log[3]: `Excluding datanode 10.86.164.9:50010`
	============ Response ====================
LogTemplate[1]: `Excluding datanode {ip_or_port}`  
LogTemplate[2]: `Excluding datanode {ip_or_port}`  
LogTemplate[3]: `Excluding datanode {ip_or_port}`  
	============ PostProcess ====================
	Post Template: `Excluding datanode <*>`
	Post Template: `Excluding datanode <*>`
	Post Template: `Excluding datanode <*>`
	============ Aggregate ====================
	Aggregated Template:  Excluding datanode <*>
[UpdateBucket] Logs: This iter found: 30, total: 173782/179993, remain: 6211. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 196 -> 166, remain buckets: 60
Update Success: Time for one update logs: 0.014255046844482422, template `Excluding datanode <*>`
========================================================================================


Iteration 114
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 196, Total Buckets: 269
Sampling from 3 logs, Sim Level: 1, MaxSim to anchor: 0.1111. Anchor: `We are finishing cleanly so this is the last retry`, MaxSim Log: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0`.
	============  Query  ====================
	Log[1]: `We are finishing cleanly so this is the last retry`
	============ Response ====================
LogTemplate[1]: `We are finishing cleanly so this is the last retry`
	============ PostProcess ====================
	Post Template: `We are finishing cleanly so this is the last retry`
	============ Aggregate ====================
	Aggregated Template:  We are finishing cleanly so this is the last retry
[UpdateBucket] Logs: This iter found: 50, total: 173832/179993, remain: 6161. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 354 -> 304, remain buckets: 60
Update Success: Time for one update logs: 0.00923299789428711, template `We are finishing cleanly so this is the last retry`
========================================================================================


Iteration 115
Sample 3 from current logs bucket: ID: 92, Len: 7, Bucket Size: 194, Total Buckets: 269
Sampling from 184 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Scheduling a redundant attempt for task task_1445087491445_0005_m_000011`, MaxSim Log: `Scheduling a redundant attempt for task task_1445087491445_0005_m_000009`.
	============  Query  ====================
	Log[1]: `Scheduling a redundant attempt for task task_1445087491445_0005_m_000011`
	Log[2]: `Scheduling a redundant attempt for task task_1445144423722_0020_m_000008`
	Log[3]: `Scheduling a redundant attempt for task task_1445094324383_0004_m_000006`
	============ Response ====================
LogTemplate[1]: `Scheduling a redundant attempt for task {task_id}`  
LogTemplate[2]: `Scheduling a redundant attempt for task {task_id}`  
LogTemplate[3]: `Scheduling a redundant attempt for task {task_id}`  
	============ PostProcess ====================
	Post Template: `Scheduling a redundant attempt for task <*>`
	Post Template: `Scheduling a redundant attempt for task <*>`
	Post Template: `Scheduling a redundant attempt for task <*>`
	============ Aggregate ====================
	Aggregated Template:  Scheduling a redundant attempt for task <*>
[UpdateBucket] Logs: This iter found: 194, total: 174026/179993, remain: 5967. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 750 -> 556, remain buckets: 59
Update Success: Time for one update logs: 0.08835291862487793, template `Scheduling a redundant attempt for task <*>`
========================================================================================


Iteration 116
Sample 3 from current logs bucket: ID: 58, Len: 5, Bucket Size: 190, Total Buckets: 269
Sampling from 189 logs, Sim Level: 3, MaxSim to anchor: 0.6667. Anchor: `Commit-pending state update from attempt_1445087491445_0005_r_000000_1`, MaxSim Log: `Commit-pending state update from attempt_1445062781478_0018_r_000000_1000`.
	============  Query  ====================
	Log[1]: `Commit-pending state update from attempt_1445087491445_0005_r_000000_1`
	Log[2]: `Commit-pending state update from attempt_1445062781478_0014_r_000000_0`
	Log[3]: `Commit-pending state update from attempt_1445094324383_0001_r_000000_0`
	============ Response ====================
LogTemplate[1]: `Commit-pending state update from attempt_<*>_<*>_r_<*>_<*>`  
LogTemplate[2]: `Commit-pending state update from attempt_<*>_<*>_r_<*>_<*>`  
LogTemplate[3]: `Commit-pending state update from attempt_<*>_<*>_r_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Commit-pending state update from <*>`
	Post Template: `Commit-pending state update from <*>`
	Post Template: `Commit-pending state update from <*>`
	============ Aggregate ====================
	Aggregated Template:  Commit-pending state update from <*>
[UpdateBucket] Logs: This iter found: 47, total: 174073/179993, remain: 5920. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 732 -> 685, remain buckets: 59
Update Success: Time for one update logs: 0.013360977172851562, template `Commit-pending state update from <*>`
========================================================================================


Iteration 117
Sample 3 from current logs bucket: ID: 69, Len: 6, Bucket Size: 186, Total Buckets: 269
Sampling from 185 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `IPC Server listener on 32060: starting`, MaxSim Log: `IPC Server listener on 32070: starting`.
	============  Query  ====================
	Log[1]: `IPC Server listener on 32060: starting`
	Log[2]: `IPC Server listener on 62304: starting`
	Log[3]: `Stopping IPC Server listener on 60153`
	============ Response ====================
LogTemplate[1]: `IPC Server listener on {port}: starting`
LogTemplate[2]: `IPC Server listener on {port}: starting`
LogTemplate[3]: `Stopping IPC Server listener on {port}`
	============ PostProcess ====================
	Post Template: `IPC Server listener on <*>: starting`
	Post Template: `IPC Server listener on <*>: starting`
	Post Template: `Stopping IPC Server listener on <*>`
	============ Aggregate ====================
	Aggregated Template:  IPC Server listener on <*>: starting
[UpdateBucket] Logs: This iter found: 138, total: 174211/179993, remain: 5782. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1083 -> 945, remain buckets: 59
Update Success: Time for one update logs: 0.02422809600830078, template `IPC Server listener on <*>: starting`
========================================================================================


Iteration 118
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 185, Total Buckets: 269
Sampling from 57 logs, Sim Level: 2, MaxSim to anchor: 0.1250. Anchor: `Upper limit on the thread pool size is 500`, MaxSim Log: `Killing taskAttempt:attempt_1445087491445_0005_m_000009_0 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:55452`.
	============  Query  ====================
	Log[1]: `Upper limit on the thread pool size is 500`
	============ Response ====================
LogTemplate[1]: `Upper limit on the thread pool size is {number}`
	============ PostProcess ====================
	Post Template: `Upper limit on the thread pool size is <*>`
	============ Aggregate ====================
	Aggregated Template:  Upper limit on the thread pool size is <*>
[UpdateBucket] Logs: This iter found: 69, total: 174280/179993, remain: 5713. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 441 -> 372, remain buckets: 59
Update Success: Time for one update logs: 0.019711971282958984, template `Upper limit on the thread pool size is <*>`
========================================================================================


Iteration 119
Sample 3 from current logs bucket: ID: 71, Len: 6, Bucket Size: 182, Total Buckets: 269
Sampling from 181 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Issuing kill to other attempt attempt_1445087491445_0005_m_000009_2`, MaxSim Log: `Issuing kill to other attempt attempt_1445087491445_0005_m_000006_2`.
	============  Query  ====================
	Log[1]: `Issuing kill to other attempt attempt_1445087491445_0005_m_000009_2`
	Log[2]: `Issuing kill to other attempt attempt_1445062781478_0018_m_000004_0`
	Log[3]: `Issuing kill to other attempt attempt_1445182159119_0002_m_000004_0`
	============ Response ====================
LogTemplate[1]: `Issuing kill to other attempt attempt_{timestamp}_{number}_m_{number}_{number}`  
LogTemplate[2]: `Issuing kill to other attempt attempt_{timestamp}_{number}_m_{number}_{number}`  
LogTemplate[3]: `Issuing kill to other attempt attempt_{timestamp}_{number}_m_{number}_{number}`  
	============ PostProcess ====================
	Post Template: `Issuing kill to other attempt <*>`
	Post Template: `Issuing kill to other attempt <*>`
	Post Template: `Issuing kill to other attempt <*>`
	============ Aggregate ====================
	Aggregated Template:  Issuing kill to other attempt <*>
[UpdateBucket] Logs: This iter found: 182, total: 174462/179993, remain: 5531. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 945 -> 763, remain buckets: 58
Update Success: Time for one update logs: 0.027623891830444336, template `Issuing kill to other attempt <*>`
========================================================================================


Iteration 120
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 171, Total Buckets: 269
Sampling from 35 logs failed
	============  Query  ====================
	Log[1]: `queue: default`
	============ Response ====================
LogTemplate[1]: `queue: {queue_name}`
	============ PostProcess ====================
	Post Template: `queue: <*>`
	============ Aggregate ====================
	Aggregated Template:  queue: <*>
[UpdateBucket] Logs: This iter found: 69, total: 174531/179993, remain: 5462. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 171 -> 102, remain buckets: 58
[TemplateDB] Try Merge: `queue: <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `queue: <*>`
Update Success: Time for one update logs: 0.011968851089477539, template `queue: <*>`
========================================================================================


Iteration 121
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 171, Total Buckets: 269
Sampling from 20 logs failed
	============  Query  ====================
	Log[1]: `Http request log for http.requests.mapreduce is not defined`
	============ Response ====================
LogTemplate[1]: `Http request log for {http_requests} is not defined`
	============ PostProcess ====================
	Post Template: `Http request log for <*> is not defined`
	============ Aggregate ====================
	Aggregated Template:  Http request log for <*> is not defined
[UpdateBucket] Logs: This iter found: 69, total: 174600/179993, remain: 5393. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 754 -> 685, remain buckets: 58
Update Success: Time for one update logs: 0.015285015106201172, template `Http request log for <*> is not defined`
========================================================================================


Iteration 122
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 166, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Assigned to reduce`
	============ Response ====================
LogTemplate[1]: `Assigned to {action}`
	============ PostProcess ====================
	Post Template: `Assigned to <*>`
	============ Aggregate ====================
	Aggregated Template:  Assigned to <*>
[UpdateBucket] Logs: This iter found: 73, total: 174673/179993, remain: 5320. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 166 -> 93, remain buckets: 58
Update Success: Time for one update logs: 0.009232044219970703, template `Assigned to <*>`
========================================================================================


Iteration 123
Sample 1 from current logs bucket: ID: 215, Len: 7, Bucket Size: 165, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.5556. Anchor: `Merging 13 files, 2831866878 bytes from disk`, MaxSim Log: `Merging 10 files, 601334942 bytes from disk`.
	============  Query  ====================
	Log[1]: `Merging 13 files, 2831866878 bytes from disk`
	Log[2]: `Merging 10 files, 2125289789 bytes from disk`
	Log[3]: `Merging 10 files, 601334942 bytes from disk`
	============ Response ====================
LogTemplate[1]: `Merging {number} files, {bytes} bytes from disk`
LogTemplate[2]: `Merging {number} files, {bytes} bytes from disk`
LogTemplate[3]: `Merging {number} files, {bytes} bytes from disk`
	============ PostProcess ====================
	Post Template: `Merging <*> files, <*> bytes from disk`
	Post Template: `Merging <*> files, <*> bytes from disk`
	Post Template: `Merging <*> files, <*> bytes from disk`
	============ Aggregate ====================
	Aggregated Template:  Merging <*> files, <*> bytes from disk
[UpdateBucket] Logs: This iter found: 56, total: 174729/179993, remain: 5264. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 556 -> 500, remain buckets: 58
Update Success: Time for one update logs: 0.08092498779296875, template `Merging <*> files, <*> bytes from disk`
========================================================================================


Iteration 124
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 164, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Stopping IPC Server Responder`
	============ Response ====================
LogTemplate[1]: `Stopping IPC Server Responder`
	============ PostProcess ====================
	Post Template: `Stopping IPC Server Responder`
	============ Aggregate ====================
	Aggregated Template:  Stopping IPC Server Responder
[UpdateBucket] Logs: This iter found: 48, total: 174777/179993, remain: 5216. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 922 -> 874, remain buckets: 58
Update Success: Time for one update logs: 0.03461813926696777, template `Stopping IPC Server Responder`
========================================================================================


Iteration 125
Sample 1 from current logs bucket: ID: 59, Len: 5, Bucket Size: 164, Total Buckets: 269
Sampling from 58 logs failed
	============  Query  ====================
	Log[1]: `Copied to done location: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	============ Response ====================
LogTemplate[1]: `Copied to done location: hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`
	============ PostProcess ====================
	Post Template: `Copied to done location: hdfs://<*>/tmp/hadoop-yarn/staging`
	============ Aggregate ====================
	Aggregated Template:  Copied to done location: hdfs://<*>/tmp/hadoop-yarn/staging
[UpdateBucket] Logs: This iter found: 94, total: 174871/179993, remain: 5122. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 685 -> 591, remain buckets: 58
Update Success: Time for one update logs: 0.01842498779296875, template `Copied to done location: hdfs://<*>/tmp/hadoop-yarn/staging`
========================================================================================


Iteration 126
Sample 3 from current logs bucket: ID: 237, Len: 10, Bucket Size: 158, Total Buckets: 269
Sampling from 157 logs, Sim Level: 3, MaxSim to anchor: 0.8182. Anchor: `Diagnostics report from attempt_1445087491445_0005_r_000000_0: Container released on a *lost* node`, MaxSim Log: `Diagnostics report from attempt_1445087491445_0005_m_000009_0: Container released on a *lost* node`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445087491445_0005_r_000000_0: Container released on a *lost* node`
	Log[2]: `Diagnostics report from attempt_1445182159119_0016_m_000007_0: Container released on a *lost* node`
	Log[3]: `Diagnostics report from attempt_1445094324383_0005_r_000000_0: Container released on a *lost* node`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>: Container released on a *lost* node`
LogTemplate[2]: `Diagnostics report from attempt_<*>: Container released on a *lost* node`
LogTemplate[3]: `Diagnostics report from attempt_<*>: Container released on a *lost* node`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Container released on a *lost* node`
	Post Template: `Diagnostics report from <*>: Container released on a *lost* node`
	Post Template: `Diagnostics report from <*>: Container released on a *lost* node`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Container released on a *lost* node
[UpdateBucket] Logs: This iter found: 55, total: 174926/179993, remain: 5067. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 304 -> 249, remain buckets: 58
Update Success: Time for one update logs: 0.010740995407104492, template `Diagnostics report from <*>: Container released on a *lost* node`
========================================================================================


Iteration 127
Sample 3 from current logs bucket: ID: 223, Len: 8, Bucket Size: 157, Total Buckets: 269
Sampling from 141 logs, Sim Level: 2, MaxSim to anchor: 0.7778. Anchor: `Number of reduces for job job_1445087491445_0005 = 1`, MaxSim Log: `Number of reduces for job job_1445062781478_0018 = 1`.
	============  Query  ====================
	Log[1]: `Number of reduces for job job_1445087491445_0005 = 1`
	Log[2]: `Number of reduces for job job_1445087491445_0010 = 1`
	Log[3]: `Number of reduces for job job_1445182159119_0012 = 1`
	============ Response ====================
LogTemplate[1]: `Number of reduces for job job_<*> = 1`
LogTemplate[2]: `Number of reduces for job job_<*> = 1`
LogTemplate[3]: `Number of reduces for job job_<*> = 1`
	============ PostProcess ====================
	Post Template: `Number of reduces for job <*> = <*>`
	Post Template: `Number of reduces for job <*> = <*>`
	Post Template: `Number of reduces for job <*> = <*>`
	============ Aggregate ====================
	Aggregated Template:  Number of reduces for job <*> = <*>
[UpdateBucket] Logs: This iter found: 69, total: 174995/179993, remain: 4998. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 685 -> 616, remain buckets: 58
Update Success: Time for one update logs: 0.02014303207397461, template `Number of reduces for job <*> = <*>`
========================================================================================


Iteration 128
Sample 3 from current logs bucket: ID: 244, Len: 12, Bucket Size: 156, Total Buckets: 269
Sampling from 55 logs, Sim Level: 3, MaxSim to anchor: 0.8333. Anchor: `Not uberizing job_1445087491445_0005 because: not enabled; too many maps; too much input;`, MaxSim Log: `Not uberizing job_1445062781478_0018 because: not enabled; too many maps; too much input;`.
	============  Query  ====================
	Log[1]: `Not uberizing job_1445087491445_0005 because: not enabled; too many maps; too much input;`
	Log[2]: `Not uberizing job_1445062781478_0018 because: not enabled; too many maps; too much input;`
	Log[3]: `Not uberizing job_1445175094696_0003 because: not enabled; too many maps; too much input;`
	============ Response ====================
LogTemplate[1]: `Not uberizing job_<*> because: not enabled; too many maps; too much input;`
	============ PostProcess ====================
	Post Template: `Not uberizing <*> because: not enabled; too many maps; too much input;`
	Post Template: `Not uberizing <*> because: not enabled; too many maps; too much input;`
	Post Template: `Not uberizing <*> because: not enabled; too many maps; too much input;`
	============ Aggregate ====================
	Aggregated Template:  Not uberizing <*> because: not enabled; too many maps; too much input;
[UpdateBucket] Logs: This iter found: 69, total: 175064/179993, remain: 4929. 
[UpdateBucket] Buckets: Checked 2 ([243, 244]), Parent Bucket size: 156 -> 87, remain buckets: 58
Update Success: Time for one update logs: 0.009830951690673828, template `Not uberizing <*> because: not enabled; too many maps; too much input;`
========================================================================================


Iteration 129
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 146, Total Buckets: 269
Sampling from 5 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0`, MaxSim Log: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 2`.
	============  Query  ====================
	Log[1]: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0`
	Log[2]: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 2`
	Log[3]: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is 1`
	============ Response ====================
LogTemplate[1]: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is {number}`
	============ PostProcess ====================
	Post Template: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>`
	Post Template: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>`
	Post Template: `Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>`
	============ Aggregate ====================
	Aggregated Template:  Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
[UpdateBucket] Logs: This iter found: 52, total: 175116/179993, remain: 4877. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 249 -> 197, remain buckets: 58
Update Success: Time for one update logs: 0.012832880020141602, template `Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>`
========================================================================================


Iteration 130
Sample 3 from current logs bucket: ID: 58, Len: 5, Bucket Size: 143, Total Buckets: 269
Sampling from 142 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Commit go/no-go request from attempt_1445087491445_0005_r_000000_1`, MaxSim Log: `Commit go/no-go request from attempt_1445062781478_0018_r_000000_1000`.
	============  Query  ====================
	Log[1]: `Commit go/no-go request from attempt_1445087491445_0005_r_000000_1`
	Log[2]: `Commit go/no-go request from attempt_1445094324383_0001_r_000000_0`
	Log[3]: `Commit go/no-go request from attempt_1445144423722_0024_r_000000_0`
	============ Response ====================
LogTemplate[1]: `Commit go/no-go request from attempt_<*>_<*>_r_<*>_<*>`  
LogTemplate[2]: `Commit go/no-go request from attempt_<*>_<*>_r_<*>_<*>`  
LogTemplate[3]: `Commit go/no-go request from attempt_<*>_<*>_r_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Commit go/no-go request from <*>`
	Post Template: `Commit go/no-go request from <*>`
	Post Template: `Commit go/no-go request from <*>`
	============ Aggregate ====================
	Aggregated Template:  Commit go/no-go request from <*>
[UpdateBucket] Logs: This iter found: 47, total: 175163/179993, remain: 4830. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 591 -> 544, remain buckets: 58
Update Success: Time for one update logs: 0.01931309700012207, template `Commit go/no-go request from <*>`
========================================================================================


Iteration 131
Sample 3 from current logs bucket: ID: 77, Len: 6, Bucket Size: 142, Total Buckets: 269
Sampling from 141 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `MSRA-SA-41.fareast.corp.microsoft.com:13562 freed by fetcher#4 in 2525ms`, MaxSim Log: `MSRA-SA-41.fareast.corp.microsoft.com:13562 freed by fetcher#4 in 1588ms`.
	============  Query  ====================
	Log[1]: `MSRA-SA-41.fareast.corp.microsoft.com:13562 freed by fetcher#4 in 2525ms`
	Log[2]: `MSRA-SA-41.fareast.corp.microsoft.com:13562 freed by fetcher#1 in 1242ms`
	Log[3]: `MSRA-SA-41.fareast.corp.microsoft.com:13562 freed by fetcher#2 in 2902ms`
	============ Response ====================
LogTemplate[1]: `{hostname} freed by fetcher#{fetcher_id} in {time}ms`
	============ PostProcess ====================
	Post Template: `<*> freed by fetcher#<*> in <*>`
	Post Template: `<*> freed by fetcher#<*> in <*>`
	Post Template: `<*> freed by fetcher#<*> in <*>`
	============ Aggregate ====================
	Aggregated Template:  <*> freed by fetcher#<*> in <*>
[UpdateBucket] Logs: This iter found: 455, total: 175618/179993, remain: 4375. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 763 -> 308, remain buckets: 54
Update Success: Time for one update logs: 0.04108476638793945, template `<*> freed by fetcher#<*> in <*>`
========================================================================================


Iteration 132
Sample 3 from current logs bucket: ID: 53, Len: 5, Bucket Size: 141, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Moved tmp to done: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging`
	============ Response ====================
LogTemplate[1]: `Moved tmp to done: hdfs://{ip_or_url}/tmp/hadoop-yarn/staging`
	============ PostProcess ====================
	Post Template: `Moved tmp to done: hdfs://<*>/tmp/hadoop-yarn/staging`
	============ Aggregate ====================
	Aggregated Template:  Moved tmp to done: hdfs://<*>/tmp/hadoop-yarn/staging
[UpdateBucket] Logs: This iter found: 141, total: 175759/179993, remain: 4234. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 544 -> 403, remain buckets: 53
Update Success: Time for one update logs: 0.02660989761352539, template `Moved tmp to done: hdfs://<*>/tmp/hadoop-yarn/staging`
========================================================================================


Iteration 133
Sample 3 from current logs bucket: ID: 19, Len: 4, Bucket Size: 140, Total Buckets: 269
	============  Query  ====================
	Log[1]: `ReduceTask metrics system started`
	============ Response ====================
LogTemplate[1]: `ReduceTask metrics system started`
	============ PostProcess ====================
	Post Template: `ReduceTask metrics system started`
	============ Aggregate ====================
	Aggregated Template:  ReduceTask metrics system started
[UpdateBucket] Logs: This iter found: 71, total: 175830/179993, remain: 4163. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 874 -> 803, remain buckets: 53
[TemplateDB] Try Merge: `ReduceTask metrics system started` | `MapTask metrics system started`
[TemplateDB] Reject Merge, Remain Template: `ReduceTask metrics system started`
Update Success: Time for one update logs: 0.033358097076416016, template `ReduceTask metrics system started`
========================================================================================


Iteration 134
Sample 1 from current logs bucket: ID: 0, Len: 1, Bucket Size: 138, Total Buckets: 269
Sampling from 2 logs failed
	============  Query  ====================
	Log[1]: `jetty-6.1.26`
	============ Response ====================
LogTemplate[1]: `{server_name}`
	============ PostProcess ====================
Get a too general template. Error.
	============ Aggregate ====================
	Aggregated Template:  
Update failed: Validate template `` failed. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 0, Len: 1, Bucket Size: 138, Total Buckets: 269
Sampling from 2 logs failed
	============  Query  ====================
	Log[1]: `jetty-6.1.26`
	============ Response ====================
LogTemplate[1]: `{server_name}`
	============ PostProcess ====================
Get a too general template. Error.
	============ Aggregate ====================
	Aggregated Template:  
Update failed: Validate template `` failed. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 0, Len: 1, Bucket Size: 138, Total Buckets: 269
Sampling from 2 logs failed
	============  Query  ====================
	Log[1]: `jetty-6.1.26`
	============ Response ====================
LogTemplate[1]: `{server_name}`
	============ PostProcess ====================
Get a too general template. Error.
	============ Aggregate ====================
	Aggregated Template:  
Update failed: Validate template `` failed. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `jetty-<*>`
[UpdateBucket] Logs: This iter found: 69, total: 175899/179993, remain: 4094. 
[UpdateBucket] Buckets: Checked 1 ([0]), Parent Bucket size: 138 -> 69, remain buckets: 53
Update Success: Time for one update logs: 0.009064197540283203, template `jetty-<*>`
========================================================================================


Iteration 135
Sample 3 from current logs bucket: ID: 21, Len: 4, Bucket Size: 138, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Using callQueue class java.util.concurrent.LinkedBlockingQueue`
	============ Response ====================
LogTemplate[1]: `Using callQueue class java.util.concurrent.{api}`
	============ PostProcess ====================
	Post Template: `Using callQueue class java.util.concurrent.<*>`
	============ Aggregate ====================
	Aggregated Template:  Using callQueue class java.util.concurrent.<*>
[UpdateBucket] Logs: This iter found: 138, total: 176037/179993, remain: 3956. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 803 -> 665, remain buckets: 52
Update Success: Time for one update logs: 0.03529977798461914, template `Using callQueue class java.util.concurrent.<*>`
========================================================================================


Iteration 136
Sample 3 from current logs bucket: ID: 22, Len: 4, Bucket Size: 138, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `IPC Server Responder: starting`
	============ Response ====================
LogTemplate[1]: `IPC Server Responder: starting`
	============ PostProcess ====================
	Post Template: `IPC Server Responder: starting`
	============ Aggregate ====================
	Aggregated Template:  IPC Server Responder: starting
[UpdateBucket] Logs: This iter found: 138, total: 176175/179993, remain: 3818. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 665 -> 527, remain buckets: 51
Update Success: Time for one update logs: 0.03861498832702637, template `IPC Server Responder: starting`
========================================================================================


Iteration 137
Sample 3 from current logs bucket: ID: 23, Len: 4, Bucket Size: 138, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `adding path spec: /mapreduce/*`, MaxSim Log: `adding path spec: /ws/*`.
	============  Query  ====================
	Log[1]: `adding path spec: /mapreduce/*`
	Log[2]: `adding path spec: /ws/*`
	============ Response ====================
LogTemplate[1]: `adding path spec: {directory}/*`
LogTemplate[2]: `adding path spec: {directory}/*`
	============ PostProcess ====================
	Post Template: `adding path spec: <*>/*`
	Post Template: `adding path spec: <*>/*`
	============ Aggregate ====================
	Aggregated Template:  adding path spec: <*>/*
[UpdateBucket] Logs: This iter found: 138, total: 176313/179993, remain: 3680. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 527 -> 389, remain buckets: 50
Update Success: Time for one update logs: 0.03618311882019043, template `adding path spec: <*>/*`
========================================================================================


Iteration 138
Sample 3 from current logs bucket: ID: 82, Len: 7, Bucket Size: 138, Total Buckets: 269
Sampling from 137 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Starting Socket Reader #1 for port 32060`, MaxSim Log: `Starting Socket Reader #1 for port 32070`.
	============  Query  ====================
	Log[1]: `Starting Socket Reader #1 for port 32060`
	Log[2]: `Starting Socket Reader #1 for port 53983`
	Log[3]: `Starting Socket Reader #1 for port 24281`
	============ Response ====================
LogTemplate[1]: `Starting Socket Reader #1 for port {port}`
LogTemplate[2]: `Starting Socket Reader #1 for port {port}`
LogTemplate[3]: `Starting Socket Reader #1 for port {port}`
	============ PostProcess ====================
	Post Template: `Starting Socket Reader <*> for port <*>`
	Post Template: `Starting Socket Reader <*> for port <*>`
	Post Template: `Starting Socket Reader <*> for port <*>`
	============ Aggregate ====================
	Aggregated Template:  Starting Socket Reader <*> for port <*>
[UpdateBucket] Logs: This iter found: 138, total: 176451/179993, remain: 3542. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 500 -> 362, remain buckets: 49
Update Success: Time for one update logs: 0.08185291290283203, template `Starting Socket Reader <*> for port <*>`
========================================================================================


Iteration 139
Sample 3 from current logs bucket: ID: 83, Len: 7, Bucket Size: 138, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce`, MaxSim Log: `Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static`.
	============  Query  ====================
	Log[1]: `Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce`
	Log[2]: `Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static`
	============ Response ====================
LogTemplate[1]: `Added filter AM_PROXY_FILTER (class=<*>) to context {context}`

LogTemplate[2]: `Added filter AM_PROXY_FILTER (class=<*>) to context {context}`
	============ PostProcess ====================
	Post Template: `Added filter AM_PROXY_FILTER (class=<*>) to context <*>`
	Post Template: `Added filter AM_PROXY_FILTER (class=<*>) to context <*>`
	============ Aggregate ====================
	Aggregated Template:  Added filter AM_PROXY_FILTER (class=<*>) to context <*>
[UpdateBucket] Logs: This iter found: 138, total: 176589/179993, remain: 3404. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 362 -> 224, remain buckets: 48
Update Success: Time for one update logs: 0.06057119369506836, template `Added filter AM_PROXY_FILTER (class=<*>) to context <*>`
========================================================================================


Iteration 140
Sample 3 from current logs bucket: ID: 228, Len: 9, Bucket Size: 138, Total Buckets: 269
Sampling from 107 logs, Sim Level: 2, MaxSim to anchor: 0.8000. Anchor: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`, MaxSim Log: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job.jar`.
	============  Query  ====================
	Log[1]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
	Log[2]: `The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0018/job.xml`
	Log[3]: `The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0017/job.xml`
	============ Response ====================
LogTemplate[1]: `The job-jar file on the remote FS is {ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
LogTemplate[2]: `The job-conf file on the remote FS is {directory}/job.xml`
LogTemplate[3]: `The job-conf file on the remote FS is {directory}/job.xml`
	============ PostProcess ====================
	Post Template: `The job-jar file on the remote FS is <*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
	Post Template: `The job-conf file on the remote FS is <*>/job.xml`
	Post Template: `The job-conf file on the remote FS is <*>/job.xml`
	============ Aggregate ====================
	Aggregated Template:  The job-conf file on the remote FS is <*>/job.xml
[UpdateBucket] Logs: This iter found: 69, total: 176658/179993, remain: 3335. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 372 -> 303, remain buckets: 48
Update Success: Time for one update logs: 0.01789402961730957, template `The job-conf file on the remote FS is <*>/job.xml`
========================================================================================


Iteration 141
Sample 3 from current logs bucket: ID: 249, Len: 13, Bucket Size: 129, Total Buckets: 269
Sampling from 12 logs, Sim Level: 1, MaxSim to anchor: 0.0870. Anchor: `Adding #0 tokens and #1 secret keys for NM use for launching container`, MaxSim Log: `Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`.
	============  Query  ====================
	Log[1]: `Adding #0 tokens and #1 secret keys for NM use for launching container`
	============ Response ====================
LogTemplate[1]: `Adding #0 tokens and #1 secret keys for NM use for launching container`
	============ PostProcess ====================
	Post Template: `Adding <*> tokens and <*> secret keys for NM use for launching container`
	============ Aggregate ====================
	Aggregated Template:  Adding <*> tokens and <*> secret keys for NM use for launching container
[UpdateBucket] Logs: This iter found: 69, total: 176727/179993, remain: 3266. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 129 -> 60, remain buckets: 48
Update Success: Time for one update logs: 0.010694742202758789, template `Adding <*> tokens and <*> secret keys for NM use for launching container`
========================================================================================


Iteration 142
Sample 3 from current logs bucket: ID: 57, Len: 5, Bucket Size: 122, Total Buckets: 269
Sampling from 116 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Created MRAppMaster for application appattempt_1445087491445_0005_000001`, MaxSim Log: `Created MRAppMaster for application appattempt_1445062781478_0018_000002`.
	============  Query  ====================
	Log[1]: `Created MRAppMaster for application appattempt_1445087491445_0005_000001`
	Log[2]: `Created MRAppMaster for application appattempt_1445144423722_0022_000001`
	Log[3]: `Created MRAppMaster for application appattempt_1445062781478_0017_000001`
	============ Response ====================
LogTemplate[1]: `Created MRAppMaster for application {application}`
	============ PostProcess ====================
	Post Template: `Created MRAppMaster for application <*>`
	Post Template: `Created MRAppMaster for application <*>`
	Post Template: `Created MRAppMaster for application <*>`
	============ Aggregate ====================
	Aggregated Template:  Created MRAppMaster for application <*>
[UpdateBucket] Logs: This iter found: 69, total: 176796/179993, remain: 3197. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 403 -> 334, remain buckets: 48
Update Success: Time for one update logs: 0.01760101318359375, template `Created MRAppMaster for application <*>`
========================================================================================


Iteration 143
Sample 3 from current logs bucket: ID: 232, Len: 9, Bucket Size: 118, Total Buckets: 269
Sampling from 117 logs, Sim Level: 2, MaxSim to anchor: 0.8000. Anchor: `attempt_1445087491445_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events`, MaxSim Log: `attempt_1445087491445_0005_r_000000_1 Thread started: EventFetcher for fetching Map Completion Events`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events`
	Log[2]: `attempt_1445094324383_0002_r_000000_2 Thread started: EventFetcher for fetching Map Completion Events`
	Log[3]: `attempt_1445062781478_0016_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events`
	============ Response ====================
LogTemplate[1]: `attempt_{job_id}_r_{task_id}_0 Thread started: EventFetcher for fetching Map Completion Events`
	============ PostProcess ====================
	Post Template: `<*> Thread started: EventFetcher for fetching Map Completion Events`
	Post Template: `<*> Thread started: EventFetcher for fetching Map Completion Events`
	Post Template: `<*> Thread started: EventFetcher for fetching Map Completion Events`
	============ Aggregate ====================
	Aggregated Template:  <*> Thread started: EventFetcher for fetching Map Completion Events
[UpdateBucket] Logs: This iter found: 71, total: 176867/179993, remain: 3126. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 303 -> 232, remain buckets: 48
Update Success: Time for one update logs: 0.014952898025512695, template `<*> Thread started: EventFetcher for fetching Map Completion Events`
========================================================================================


Iteration 144
Sample 3 from current logs bucket: ID: 221, Len: 8, Bucket Size: 117, Total Buckets: 269
Sampling from 14 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`, MaxSim Log: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`.
	============  Query  ====================
	Log[1]: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`
	Log[2]: `assigned 5 of 5 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#4`
	Log[3]: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#2`
	============ Response ====================
LogTemplate[1]: `assigned <*> of <*> to {ip_or_url} to fetcher#*`
	============ PostProcess ====================
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	============ Aggregate ====================
	Aggregated Template:  assigned <*> of <*> to <*> to fetcher#*
[UpdateBucket] Logs: This iter found: 0, total: 176867/179993, remain: 3126. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 616 -> 616, remain buckets: 48
Update failed: Template can not match logs `assigned <*> of <*> to <*> to fetcher#*`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 221, Len: 8, Bucket Size: 117, Total Buckets: 269
Sampling from 14 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`, MaxSim Log: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`.
	============  Query  ====================
	Log[1]: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`
	Log[2]: `assigned 3 of 3 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#4`
	Log[3]: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#2`
	============ Response ====================
LogTemplate[1]: `assigned <*> of <*> to {ip_or_url} to fetcher#*`
	============ PostProcess ====================
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	============ Aggregate ====================
	Aggregated Template:  assigned <*> of <*> to <*> to fetcher#*
[UpdateBucket] Logs: This iter found: 0, total: 176867/179993, remain: 3126. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 616 -> 616, remain buckets: 48
Update failed: Template can not match logs `assigned <*> of <*> to <*> to fetcher#*`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 221, Len: 8, Bucket Size: 117, Total Buckets: 269
Sampling from 14 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`, MaxSim Log: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`.
	============  Query  ====================
	Log[1]: `assigned 1 of 1 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#1`
	Log[2]: `assigned 5 of 5 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#4`
	Log[3]: `assigned 2 of 2 to MSRA-SA-39.fareast.corp.microsoft.com:13562 to fetcher#2`
	============ Response ====================
LogTemplate[1]: `assigned <*> of <*> to {ip_or_url} to fetcher#*`
	============ PostProcess ====================
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	Post Template: `assigned <*> of <*> to <*> to fetcher#*`
	============ Aggregate ====================
	Aggregated Template:  assigned <*> of <*> to <*> to fetcher#*
[UpdateBucket] Logs: This iter found: 0, total: 176867/179993, remain: 3126. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 616 -> 616, remain buckets: 48
Update failed: Template can not match logs `assigned <*> of <*> to <*> to fetcher#*`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `assigned <*> of <*> to MSRA-SA-<*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
[UpdateBucket] Logs: This iter found: 397, total: 177264/179993, remain: 2729. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 616 -> 219, remain buckets: 45
Update Success: Time for one update logs: 0.024854183197021484, template `assigned <*> of <*> to MSRA-SA-<*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
========================================================================================


Iteration 145
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 116, Total Buckets: 269
Sampling from 19 logs, Sim Level: 1, MaxSim to anchor: 0.1429. Anchor: `EventFetcher is interrupted.. Returning`, MaxSim Log: `History url is http://MININT-FNANLI5.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445144423722_0020`.
	============  Query  ====================
	Log[1]: `EventFetcher is interrupted.. Returning`
	============ Response ====================
LogTemplate[1]: `EventFetcher is interrupted.. Returning`
	============ PostProcess ====================
	Post Template: `EventFetcher is interrupted.. Returning`
	============ Aggregate ====================
	Aggregated Template:  EventFetcher is interrupted.. Returning
[UpdateBucket] Logs: This iter found: 54, total: 177318/179993, remain: 2675. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 389 -> 335, remain buckets: 45
Update Success: Time for one update logs: 0.031948089599609375, template `EventFetcher is interrupted.. Returning`
========================================================================================


Iteration 146
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 116, Total Buckets: 269
Sampling from 56 logs, Sim Level: 3, MaxSim to anchor: 0.8000. Anchor: `Killing taskAttempt:attempt_1445087491445_0005_m_000009_0 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:55452`, MaxSim Log: `Killing taskAttempt:attempt_1445087491445_0005_m_000011_0 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:55452`.
	============  Query  ====================
	Log[1]: `Killing taskAttempt:attempt_1445087491445_0005_m_000009_0 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:55452`
	Log[2]: `Killing taskAttempt:attempt_1445062781478_0012_m_000005_0 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:64484`
	Log[3]: `Killing taskAttempt:attempt_1445182159119_0003_m_000000_2 because it is running on unusable node:04DN8IQ.fareast.corp.microsoft.com:64260`
	============ Response ====================
LogTemplate[1]: `Killing taskAttempt:attempt_<*> because it is running on unusable node:<*>:<*>`

LogTemplate[2]: `Killing taskAttempt:attempt_<*> because it is running on unusable node:<*>:<*>`

LogTemplate[3]: `Killing taskAttempt:attempt_<*> because it is running on unusable node:<*>:<*>`
	============ PostProcess ====================
	Post Template: `Killing taskAttempt:<*> because it is running on unusable node:<*>`
	Post Template: `Killing taskAttempt:<*> because it is running on unusable node:<*>`
	Post Template: `Killing taskAttempt:<*> because it is running on unusable node:<*>`
	============ Aggregate ====================
	Aggregated Template:  Killing taskAttempt:<*> because it is running on unusable node:<*>
[UpdateBucket] Logs: This iter found: 55, total: 177373/179993, remain: 2620. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 232 -> 177, remain buckets: 45
Update Success: Time for one update logs: 0.013299942016601562, template `Killing taskAttempt:<*> because it is running on unusable node:<*>`
========================================================================================


Iteration 147
Sample 3 from current logs bucket: ID: 214, Len: 7, Bucket Size: 115, Total Buckets: 269
Sampling from 55 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Adding job token for job_1445087491445_0005 to jobTokenSecretManager`, MaxSim Log: `Adding job token for job_1445062781478_0018 to jobTokenSecretManager`.
	============  Query  ====================
	Log[1]: `Adding job token for job_1445087491445_0005 to jobTokenSecretManager`
	Log[2]: `Adding job token for job_1445062781478_0012 to jobTokenSecretManager`
	Log[3]: `Adding job token for job_1445062781478_0019 to jobTokenSecretManager`
	============ Response ====================
LogTemplate[1]: `Adding job token for {job_id} to jobTokenSecretManager`  
LogTemplate[2]: `Adding job token for {job_id} to jobTokenSecretManager`  
LogTemplate[3]: `Adding job token for {job_id} to jobTokenSecretManager`  
	============ PostProcess ====================
	Post Template: `Adding job token for <*> to jobTokenSecretManager`
	Post Template: `Adding job token for <*> to jobTokenSecretManager`
	Post Template: `Adding job token for <*> to jobTokenSecretManager`
	============ Aggregate ====================
	Aggregated Template:  Adding job token for <*> to jobTokenSecretManager
[UpdateBucket] Logs: This iter found: 69, total: 177442/179993, remain: 2551. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 224 -> 155, remain buckets: 45
Update Success: Time for one update logs: 0.08193802833557129, template `Adding job token for <*> to jobTokenSecretManager`
========================================================================================


Iteration 148
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 109, Total Buckets: 269
Sampling from 105 logs, Sim Level: 2, MaxSim to anchor: 0.7500. Anchor: `Task attempt_1445087491445_0005_r_000000_1 is allowed to commit now`, MaxSim Log: `Task attempt_1445062781478_0018_r_000000_1000 is allowed to commit now`.
	============  Query  ====================
	Log[1]: `Task attempt_1445087491445_0005_r_000000_1 is allowed to commit now`
	Log[2]: `Task attempt_1445182159119_0011_r_000000_0 is allowed to commit now`
	Log[3]: `Task attempt_1445182159119_0003_r_000000_1 is allowed to commit now`
	============ Response ====================
LogTemplate[1]: `Task attempt_<*>_<*>_r_<*>_<*> is allowed to commit now`
	============ PostProcess ====================
	Post Template: `Task <*> is allowed to commit now`
	Post Template: `Task <*> is allowed to commit now`
	Post Template: `Task <*> is allowed to commit now`
	============ Aggregate ====================
	Aggregated Template:  Task <*> is allowed to commit now
[UpdateBucket] Logs: This iter found: 48, total: 177490/179993, remain: 2503. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 155 -> 107, remain buckets: 45
Update Success: Time for one update logs: 0.07961106300354004, template `Task <*> is allowed to commit now`
========================================================================================


Iteration 149
Sample 3 from current logs bucket: ID: 35, Len: 4, Bucket Size: 104, Total Buckets: 269
Sampling from 100 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Could not delete hdfs://msra-sa-41:9000/pageout/out3/_temporary/2/_temporary/attempt_1445062781478_0018_m_000007_1001`, MaxSim Log: `Could not delete hdfs://msra-sa-41:9000/pageout/out3/_temporary/1/_temporary/attempt_1445062781478_0018_m_000003_0`.
	============  Query  ====================
	Log[1]: `Could not delete hdfs://msra-sa-41:9000/pageout/out3/_temporary/2/_temporary/attempt_1445062781478_0018_m_000007_1001`
	Log[2]: `Could not delete hdfs://msra-sa-41:9000/pageout/out4/_temporary/1/_temporary/attempt_1445062781478_0019_m_000006_1`
	Log[3]: `Could not delete hdfs://msra-sa-41:9000/pageout/out4/_temporary/1/_temporary/attempt_1445062781478_0014_m_000000_0`
	============ Response ====================
LogTemplate[1]: `Could not delete hdfs://{ip_or_url}/pageout/out3/_temporary/{placeholder}/_temporary/attempt_{placeholder}_m_{placeholder}_{placeholder}`

LogTemplate[2]: `Could not delete hdfs://{ip_or_url}/pageout/out4/_temporary/{placeholder}/_temporary/attempt_{placeholder}_m_{placeholder}_{placeholder}`

LogTemplate[3]: `Could not delete hdfs://{ip_or_url}/pageout/out4/_temporary/{placeholder}/_temporary/attempt_{placeholder}_m_{placeholder}_{placeholder}`
	============ PostProcess ====================
	Post Template: `Could not delete hdfs://<*>/pageout/out3/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>`
	Post Template: `Could not delete hdfs://<*>/pageout/out4/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>`
	Post Template: `Could not delete hdfs://<*>/pageout/out4/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>`
	============ Aggregate ====================
	Aggregated Template:  Could not delete hdfs://<*>/pageout/out4/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>
[UpdateBucket] Logs: This iter found: 19, total: 177509/179993, remain: 2484. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 335 -> 316, remain buckets: 45
[TemplateDB] Try Merge: `Could not delete hdfs://<*>/pageout/out4/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>` | `Could not delete hdfs://<*>/out/out<*>`
	Post Template: `Could not delete hdfs://<*>`
[TemplateDB] Merged: -> `Could not delete hdfs://<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 131/131, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]
[UpdateBucket] Logs: This iter found: 85, total: 177594/179993, remain: 2399. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 316 -> 231, remain buckets: 44
[TemplateDB] Update Indexes: 131 -> 216 for `Could not delete hdfs://<*>`
[TemplateBaseUpdate] Match unparsed logs 85 with new template `Could not delete hdfs://<*>`
Update Success: Time for one update logs: 0.07925915718078613, template `Could not delete hdfs://<*>/pageout/out4/_temporary/<*>/_temporary/attempt_<*>_m_<*>_<*>`
========================================================================================


Iteration 150
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 104, Total Buckets: 269
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `Calling stop for all the services`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`.
	============  Query  ====================
	Log[1]: `Calling stop for all the services`
	============ Response ====================
LogTemplate[1]: `Calling stop for all the services`
	============ PostProcess ====================
	Post Template: `Calling stop for all the services`
	============ Aggregate ====================
	Aggregated Template:  Calling stop for all the services
[UpdateBucket] Logs: This iter found: 52, total: 177646/179993, remain: 2347. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 308 -> 256, remain buckets: 44
Update Success: Time for one update logs: 0.021908998489379883, template `Calling stop for all the services`
========================================================================================


Iteration 151
Sample 3 from current logs bucket: ID: 237, Len: 10, Bucket Size: 103, Total Buckets: 269
Sampling from 102 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `Recovering task task_1445062781478_0018_m_000000 from prior app attempt, status was SUCCEEDED`, MaxSim Log: `Recovering task task_1445062781478_0018_m_000001 from prior app attempt, status was SUCCEEDED`.
	============  Query  ====================
	Log[1]: `Recovering task task_1445062781478_0018_m_000000 from prior app attempt, status was SUCCEEDED`
	Log[2]: `Recovering task task_1445087491445_0004_m_000003 from prior app attempt, status was SUCCEEDED`
	Log[3]: `Recovering task task_1445182159119_0002_m_000000 from prior app attempt, status was SUCCEEDED`
	============ Response ====================
LogTemplate[1]: `Recovering task {task_id} from prior app attempt, status was SUCCEEDED`
LogTemplate[2]: `Recovering task {task_id} from prior app attempt, status was SUCCEEDED`
LogTemplate[3]: `Recovering task {task_id} from prior app attempt, status was SUCCEEDED`
	============ PostProcess ====================
	Post Template: `Recovering task <*> from prior app attempt, status was SUCCEEDED`
	Post Template: `Recovering task <*> from prior app attempt, status was SUCCEEDED`
	Post Template: `Recovering task <*> from prior app attempt, status was SUCCEEDED`
	============ Aggregate ====================
	Aggregated Template:  Recovering task <*> from prior app attempt, status was SUCCEEDED
[UpdateBucket] Logs: This iter found: 96, total: 177742/179993, remain: 2251. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 197 -> 101, remain buckets: 44
Update Success: Time for one update logs: 0.010938167572021484, template `Recovering task <*> from prior app attempt, status was SUCCEEDED`
========================================================================================


Iteration 152
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 102, Total Buckets: 269
Sampling from 34 logs failed
	============  Query  ====================
	Log[1]: `mapResourceRequest:<memory:1024, vCores:1>`
	============ Response ====================
LogTemplate[1]: `mapResourceRequest:<memory:{memory}, vCores:{vCores}>`
	============ PostProcess ====================
	Post Template: `mapResourceRequest:<memory:<*>, vCores:<*>`
	============ Aggregate ====================
	Aggregated Template:  mapResourceRequest:<memory:<*>, vCores:<*>
[UpdateBucket] Logs: This iter found: 65, total: 177807/179993, remain: 2186. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 102 -> 37, remain buckets: 44
Update Success: Time for one update logs: 0.013099193572998047, template `mapResourceRequest:<memory:<*>, vCores:<*>`
========================================================================================


Iteration 153
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 102, Total Buckets: 269
Sampling from 19 logs failed
	============  Query  ====================
	Log[1]: `All maps assigned. Ramping up all remaining reduces:1`
	============ Response ====================
LogTemplate[1]: `All maps assigned. Ramping up all remaining reduces:{number}`
	============ PostProcess ====================
	Post Template: `All maps assigned. Ramping up all remaining reduces:<*>`
	============ Aggregate ====================
	Aggregated Template:  All maps assigned. Ramping up all remaining reduces:<*>
[UpdateBucket] Logs: This iter found: 43, total: 177850/179993, remain: 2143. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 219 -> 176, remain buckets: 44
Update Success: Time for one update logs: 0.016431093215942383, template `All maps assigned. Ramping up all remaining reduces:<*>`
========================================================================================


Iteration 154
Sample 3 from current logs bucket: ID: 36, Len: 4, Bucket Size: 100, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Notify RMCommunicator isAMLastRetry: true`, MaxSim Log: `Notify JHEH isAMLastRetry: true`.
	============  Query  ====================
	Log[1]: `Notify RMCommunicator isAMLastRetry: true`
	Log[2]: `Notify JHEH isAMLastRetry: true`
	============ Response ====================
LogTemplate[1]: `Notify {service} isAMLastRetry: {boolean}`
LogTemplate[2]: `Notify {service} isAMLastRetry: {boolean}`
	============ PostProcess ====================
	Post Template: `Notify <*> isAMLastRetry: <*>`
	Post Template: `Notify <*> isAMLastRetry: <*>`
	============ Aggregate ====================
	Aggregated Template:  Notify <*> isAMLastRetry: <*>
[UpdateBucket] Logs: This iter found: 104, total: 177954/179993, remain: 2039. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 231 -> 127, remain buckets: 43
Update Success: Time for one update logs: 0.03553199768066406, template `Notify <*> isAMLastRetry: <*>`
========================================================================================


Iteration 155
Sample 3 from current logs bucket: ID: 55, Len: 5, Bucket Size: 100, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Ramping down all scheduled reduces:0`
	============ Response ====================
LogTemplate[1]: `Ramping down all scheduled reduces:{number}`
	============ PostProcess ====================
	Post Template: `Ramping down all scheduled reduces:<*>`
	============ Aggregate ====================
	Aggregated Template:  Ramping down all scheduled reduces:<*>
[UpdateBucket] Logs: This iter found: 100, total: 178054/179993, remain: 1939. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 334 -> 234, remain buckets: 42
Update Success: Time for one update logs: 0.017989158630371094, template `Ramping down all scheduled reduces:<*>`
========================================================================================


Iteration 156
Sample 3 from current logs bucket: ID: 72, Len: 6, Bucket Size: 100, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `RMCommunicator notified that shouldUnregistered is: true`, MaxSim Log: `JobHistoryEventHandler notified that forceJobCompletion is true`.
	============  Query  ====================
	Log[1]: `RMCommunicator notified that shouldUnregistered is: true`
	============ Response ====================
LogTemplate[1]: `RMCommunicator notified that shouldUnregistered is: {boolean}`
	============ PostProcess ====================
	Post Template: `RMCommunicator notified that shouldUnregistered is: <*>`
	============ Aggregate ====================
	Aggregated Template:  RMCommunicator notified that shouldUnregistered is: <*>
[UpdateBucket] Logs: This iter found: 52, total: 178106/179993, remain: 1887. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 256 -> 204, remain buckets: 42
Update Success: Time for one update logs: 0.023879289627075195, template `RMCommunicator notified that shouldUnregistered is: <*>`
========================================================================================


Iteration 157
Sample 3 from current logs bucket: ID: 241, Len: 11, Bucket Size: 100, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Going to preempt 1 due to lack of space for maps`
	============ Response ====================
LogTemplate[1]: `Going to preempt <*> due to lack of space for maps`
	============ PostProcess ====================
	Post Template: `Going to preempt <*> due to lack of space for maps`
	============ Aggregate ====================
	Aggregated Template:  Going to preempt <*> due to lack of space for maps
[UpdateBucket] Logs: This iter found: 100, total: 178206/179993, remain: 1787. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 182 -> 82, remain buckets: 41
Update Success: Time for one update logs: 0.014662742614746094, template `Going to preempt <*> due to lack of space for maps`
========================================================================================


Iteration 158
Sample 3 from current logs bucket: ID: 58, Len: 5, Bucket Size: 96, Total Buckets: 269
Sampling from 95 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Read from history task task_1445062781478_0018_m_000008`, MaxSim Log: `Read from history task task_1445062781478_0018_m_000009`.
	============  Query  ====================
	Log[1]: `Read from history task task_1445062781478_0018_m_000008`
	Log[2]: `Read from history task task_1445087491445_0006_m_000003`
	Log[3]: `Read from history task task_1445087491445_0002_m_000008`
	============ Response ====================
LogTemplate[1]: `Read from history task task_<*>{task_id}_m_<*>{mapper_id}`
	============ PostProcess ====================
	Post Template: `Read from history task <*>`
	Post Template: `Read from history task <*>`
	Post Template: `Read from history task <*>`
	============ Aggregate ====================
	Aggregated Template:  Read from history task <*>
[UpdateBucket] Logs: This iter found: 96, total: 178302/179993, remain: 1691. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 234 -> 138, remain buckets: 40
Update Success: Time for one update logs: 0.022070646286010742, template `Read from history task <*>`
========================================================================================


Iteration 159
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 94, Total Buckets: 269
Sampling from 4 logs, Sim Level: 3, MaxSim to anchor: 0.8000. Anchor: `finalMerge called with 0 in-memory map-outputs and 13 on-disk map-outputs`, MaxSim Log: `finalMerge called with 0 in-memory map-outputs and 10 on-disk map-outputs`.
	============  Query  ====================
	Log[1]: `finalMerge called with 0 in-memory map-outputs and 13 on-disk map-outputs`
	Log[2]: `finalMerge called with 0 in-memory map-outputs and 10 on-disk map-outputs`
	============ Response ====================
LogTemplate[1]: `finalMerge called with {number} in-memory map-outputs and {number} on-disk map-outputs`
LogTemplate[2]: `finalMerge called with {number} in-memory map-outputs and {number} on-disk map-outputs`
	============ PostProcess ====================
	Post Template: `finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs`
	Post Template: `finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs`
	============ Aggregate ====================
	Aggregated Template:  finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs
[UpdateBucket] Logs: This iter found: 56, total: 178358/179993, remain: 1635. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 101 -> 45, remain buckets: 40
Update Success: Time for one update logs: 0.011093854904174805, template `finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs`
========================================================================================


Iteration 160
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 93, Total Buckets: 269
Sampling from 5 logs failed
	============  Query  ====================
	Log[1]: `Ramping up 1`
	============ Response ====================
LogTemplate[1]: `Ramping up {number}`
	============ PostProcess ====================
	Post Template: `Ramping up <*>`
	============ Aggregate ====================
	Aggregated Template:  Ramping up <*>
[UpdateBucket] Logs: This iter found: 31, total: 178389/179993, remain: 1604. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 93 -> 62, remain buckets: 40
Update Success: Time for one update logs: 0.011782169342041016, template `Ramping up <*>`
========================================================================================


Iteration 161
Sample 3 from current logs bucket: ID: 223, Len: 8, Bucket Size: 88, Total Buckets: 269
Sampling from 87 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Event Writer setup for JobId: job_1445087491445_0005, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1.jhist`, MaxSim Log: `Event Writer setup for JobId: job_1445062781478_0018, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job_1445062781478_0018_2.jhist`.
	============  Query  ====================
	Log[1]: `Event Writer setup for JobId: job_1445087491445_0005, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job_1445087491445_0005_1.jhist`
	Log[2]: `Event Writer setup for JobId: job_1445182159119_0002, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0002/job_1445182159119_0002_2.jhist`
	Log[3]: `Event Writer setup for JobId: job_1445182159119_0018, File: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0018/job_1445182159119_0018_2.jhist`
	============ Response ====================
LogTemplate[1]: `Event Writer setup for JobId: {job_id}, File: {hdfs_file}`
LogTemplate[2]: `Event Writer setup for JobId: {job_id}, File: {hdfs_file}`
LogTemplate[3]: `Event Writer setup for JobId: {job_id}, File: {hdfs_file}`
	============ PostProcess ====================
	Post Template: `Event Writer setup for JobId: <*> File: <*>`
	Post Template: `Event Writer setup for JobId: <*> File: <*>`
	Post Template: `Event Writer setup for JobId: <*> File: <*>`
	============ Aggregate ====================
	Aggregated Template:  Event Writer setup for JobId: <*> File: <*>
[UpdateBucket] Logs: This iter found: 69, total: 178458/179993, remain: 1535. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 176 -> 107, remain buckets: 40
Update Success: Time for one update logs: 0.018819093704223633, template `Event Writer setup for JobId: <*> File: <*>`
========================================================================================


Iteration 162
Sample 3 from current logs bucket: ID: 244, Len: 12, Bucket Size: 87, Total Buckets: 269
Sampling from 67 logs, Sim Level: 3, MaxSim to anchor: 0.8333. Anchor: `Input size for job job_1445087491445_0005 = 1751822336. Number of splits = 13`, MaxSim Log: `Input size for job job_1445087491445_0002 = 1751822336. Number of splits = 13`.
	============  Query  ====================
	Log[1]: `Input size for job job_1445087491445_0005 = 1751822336. Number of splits = 13`
	Log[2]: `Input size for job job_1445076437777_0003 = 1256521728. Number of splits = 10`
	Log[3]: `Input size for job job_1445087491445_0010 = 1313861632. Number of splits = 10`
	============ Response ====================
LogTemplate[1]: `Input size for job {job_id} = {size}. Number of splits = {num_splits}`
LogTemplate[2]: `Input size for job {job_id} = {size}. Number of splits = {num_splits}`
LogTemplate[3]: `Input size for job {job_id} = {size}. Number of splits = {num_splits}`
	============ PostProcess ====================
	Post Template: `Input size for job <*> = <*> Number of splits = <*>`
	Post Template: `Input size for job <*> = <*> Number of splits = <*>`
	Post Template: `Input size for job <*> = <*> Number of splits = <*>`
	============ Aggregate ====================
	Aggregated Template:  Input size for job <*> = <*> Number of splits = <*>
[UpdateBucket] Logs: This iter found: 69, total: 178527/179993, remain: 1466. 
[UpdateBucket] Buckets: Checked 2 ([243, 244]), Parent Bucket size: 87 -> 18, remain buckets: 40
Update Success: Time for one update logs: 0.008327960968017578, template `Input size for job <*> = <*> Number of splits = <*>`
========================================================================================


Iteration 163
Sample 3 from current logs bucket: ID: 257, Len: 19, Bucket Size: 83, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8889. Anchor: `Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`, MaxSim Log: `Failed to connect to /10.86.165.66:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`.
	============  Query  ====================
	Log[1]: `Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
	Log[2]: `Failed to connect to /10.86.165.66:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
	============ Response ====================
LogTemplate[1]: `Failed to connect to /{ip_or_url}:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
	============ PostProcess ====================
	Post Template: `Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
	Post Template: `Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
	============ Aggregate ====================
	Aggregated Template:  Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
[UpdateBucket] Logs: This iter found: 5, total: 178532/179993, remain: 1461. 
[UpdateBucket] Buckets: Checked 1 ([257]), Parent Bucket size: 83 -> 78, remain buckets: 40
Update Success: Time for one update logs: 0.004312038421630859, template `Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information`
========================================================================================


Iteration 164
Sample 3 from current logs bucket: ID: 242, Len: 11, Bucket Size: 82, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.0476. Anchor: `Emitting job history data to the timeline server is not enabled`, MaxSim Log: `Error communicating with RM: Could not contact RM after 360000 milliseconds.`.
	============  Query  ====================
	Log[1]: `Emitting job history data to the timeline server is not enabled`
	============ Response ====================
LogTemplate[1]: `Emitting job history data to the timeline server is not enabled`
	============ PostProcess ====================
	Post Template: `Emitting job history data to the timeline server is not enabled`
	============ Aggregate ====================
	Aggregated Template:  Emitting job history data to the timeline server is not enabled
[UpdateBucket] Logs: This iter found: 69, total: 178601/179993, remain: 1392. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 82 -> 13, remain buckets: 40
Update Success: Time for one update logs: 0.008116960525512695, template `Emitting job history data to the timeline server is not enabled`
========================================================================================


Iteration 165
Sample 3 from current logs bucket: ID: 257, Len: 19, Bucket Size: 78, Total Buckets: 269
Sampling from 68 logs, Sim Level: 8, MaxSim to anchor: 0.9412. Anchor: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 5 cluster_timestamp: 1445087491445 } attemptId: 1 } keyId: -1547346236)`, MaxSim Log: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1445087491445 } attemptId: 1 } keyId: -1547346236)`.
	============  Query  ====================
	Log[1]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 5 cluster_timestamp: 1445087491445 } attemptId: 1 } keyId: -1547346236)`
	Log[2]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 23 cluster_timestamp: 1445144423722 } attemptId: 2 } keyId: -127633188)`
	Log[3]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 13 cluster_timestamp: 1445062781478 } attemptId: 2 } keyId: 471522253)`
	============ Response ====================
LogTemplate[1]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: {id} cluster_timestamp: {cluster_timestamp} } attemptId: {attemptId} } keyId: {keyId})`
LogTemplate[2]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: {id} cluster_timestamp: {cluster_timestamp} } attemptId: {attemptId} } keyId: {keyId})`
LogTemplate[3]: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: {id} cluster_timestamp: {cluster_timestamp} } attemptId: {attemptId} } keyId: {keyId})`
	============ PostProcess ====================
	Post Template: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)`
	Post Template: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)`
	Post Template: `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)`
	============ Aggregate ====================
	Aggregated Template:  Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)
[UpdateBucket] Logs: This iter found: 69, total: 178670/179993, remain: 1323. 
[UpdateBucket] Buckets: Checked 1 ([257]), Parent Bucket size: 78 -> 9, remain buckets: 40
Update Success: Time for one update logs: 0.008652925491333008, template `Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)`
========================================================================================


Iteration 166
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 70, Total Buckets: 269
Sampling from 44 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Deleting staging directory hdfs://msra-sa-41:9000 /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005`, MaxSim Log: `Deleting staging directory hdfs://msra-sa-41:9000 /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018`.
	============  Query  ====================
	Log[1]: `Deleting staging directory hdfs://msra-sa-41:9000 /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005`
	Log[2]: `Deleting staging directory hdfs://msra-sa-41:9000 /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445144423722_0024`
	Log[3]: `Deleting staging directory hdfs://msra-sa-41:9000 /tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0004`
	============ Response ====================
LogTemplate[1]: `Deleting staging directory hdfs://{ip_or_url} {directory}/.staging/job_{job_id}_{job_attempt}`
	============ PostProcess ====================
	Post Template: `Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>`
	Post Template: `Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>`
	Post Template: `Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>`
	============ Aggregate ====================
	Aggregated Template:  Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>
[UpdateBucket] Logs: This iter found: 45, total: 178715/179993, remain: 1278. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 138 -> 93, remain buckets: 40
Update Success: Time for one update logs: 0.017928123474121094, template `Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>`
========================================================================================


Iteration 167
Sample 3 from current logs bucket: ID: 0, Len: 1, Bucket Size: 69, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `nodeBlacklistingEnabled:true`
	============ Response ====================
LogTemplate[1]: `nodeBlacklistingEnabled:{boolean}`
	============ PostProcess ====================
	Post Template: `nodeBlacklistingEnabled:<*>`
	============ Aggregate ====================
	Aggregated Template:  nodeBlacklistingEnabled:<*>
[UpdateBucket] Logs: This iter found: 69, total: 178784/179993, remain: 1209. 
[UpdateBucket] Buckets: Checked 1 ([0]), Parent Bucket size: 69 -> 0, remain buckets: 39
Update Success: Time for one update logs: 0.007252931594848633, template `nodeBlacklistingEnabled:<*>`
========================================================================================


Iteration 168
Sample 3 from current logs bucket: ID: 19, Len: 4, Bucket Size: 69, Total Buckets: 269
	============  Query  ====================
	Log[1]: `MRAppMaster metrics system started`
	============ Response ====================
LogTemplate[1]: `MRAppMaster metrics system started`
	============ PostProcess ====================
	Post Template: `MRAppMaster metrics system started`
	============ Aggregate ====================
	Aggregated Template:  MRAppMaster metrics system started
[UpdateBucket] Logs: This iter found: 69, total: 178853/179993, remain: 1140. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 127 -> 58, remain buckets: 38
[TemplateDB] Try Merge: `MRAppMaster metrics system started` | `MapTask metrics system started`
[TemplateDB] Reject Merge, Remain Template: `MRAppMaster metrics system started`
Update Success: Time for one update logs: 0.030778884887695312, template `MRAppMaster metrics system started`
========================================================================================


Iteration 169
Sample 1 from current logs bucket: ID: 228, Len: 9, Bucket Size: 69, Total Buckets: 269
Sampling from 53 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`, MaxSim Log: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job.jar`.
	============  Query  ====================
	Log[1]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
	Log[2]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0014/job.jar`
	Log[3]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0015/job.jar`
	============ Response ====================
LogTemplate[1]: `The job-jar file on the remote FS is hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
LogTemplate[2]: `The job-jar file on the remote FS is hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0014/job.jar`
LogTemplate[3]: `The job-jar file on the remote FS is hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0015/job.jar`
	============ PostProcess ====================
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0014/job.jar`
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0015/job.jar`
	============ Aggregate ====================
	Aggregated Template:  The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar
[UpdateBucket] Logs: This iter found: 1, total: 178854/179993, remain: 1139. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 177 -> 176, remain buckets: 38
Update Success: Time for one update logs: 0.019319772720336914, template `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
========================================================================================


Iteration 170
Sample 3 from current logs bucket: ID: 228, Len: 9, Bucket Size: 68, Total Buckets: 269
Sampling from 52 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job.jar`, MaxSim Log: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0002/job.jar`.
	============  Query  ====================
	Log[1]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job.jar`
	Log[2]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0011/job.jar`
	Log[3]: `The job-jar file on the remote FS is hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445094324383_0004/job.jar`
	============ Response ====================
LogTemplate[1]: `The job-jar file on the remote FS is hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/job.jar`
	============ PostProcess ====================
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
	============ Aggregate ====================
	Aggregated Template:  The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar
[UpdateBucket] Logs: This iter found: 68, total: 178922/179993, remain: 1071. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 176 -> 108, remain buckets: 37
[TemplateDB] Try Merge: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar` | `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0005/job.jar`
	Post Template: `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
[TemplateDB] Merged: -> `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 69/69, in child Bucket [225, 226, 227, 228, 229, 230, 231, 232, 233]
Update Success: Time for one update logs: 0.0254819393157959, template `The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar`
========================================================================================


Iteration 171
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 62, Total Buckets: 269
	============  Query  ====================
	Log[1]: `TaskHeartbeatHandler thread interrupted`
	============ Response ====================
LogTemplate[1]: `TaskHeartbeatHandler thread interrupted`
	============ PostProcess ====================
	Post Template: `TaskHeartbeatHandler thread interrupted`
	============ Aggregate ====================
	Aggregated Template:  TaskHeartbeatHandler thread interrupted
[UpdateBucket] Logs: This iter found: 48, total: 178970/179993, remain: 1023. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 62 -> 14, remain buckets: 37
Update Success: Time for one update logs: 0.01145315170288086, template `TaskHeartbeatHandler thread interrupted`
========================================================================================


Iteration 172
Sample 1 from current logs bucket: ID: 215, Len: 7, Bucket Size: 61, Total Buckets: 269
Sampling from 57 logs, Sim Level: 2, MaxSim to anchor: 0.5556. Anchor: `Saved output of task 'attempt_1445087491445_0005_r_000000_1' to hdfs://msra-sa-41:9000/out/out2/_temporary/1/task_1445087491445_0005_r_000000`, MaxSim Log: `Saved output of task 'attempt_1445062781478_0018_r_000000_1000' to hdfs://msra-sa-41:9000/pageout/out3/_temporary/2/task_1445062781478_0018_r_000000`.
	============  Query  ====================
	Log[1]: `Saved output of task 'attempt_1445087491445_0005_r_000000_1' to hdfs://msra-sa-41:9000/out/out2/_temporary/1/task_1445087491445_0005_r_000000`
	Log[2]: `Saved output of task 'attempt_1445182159119_0015_r_000000_0' to hdfs://msra-sa-41:9000/pageout/out5/_temporary/1/task_1445182159119_0015_r_000000`
	Log[3]: `Saved output of task 'attempt_1445182159119_0020_r_000000_0' to hdfs://msra-sa-41:9000/pageout/out5/_temporary/1/task_1445182159119_0020_r_000000`
	============ Response ====================
LogTemplate[1]: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/out/out2/_temporary/1/task_<task_id>`

LogTemplate[2]: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>`

LogTemplate[3]: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>`
	============ PostProcess ====================
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/out/out2/_temporary/1/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>`
	Post Template: `Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>`
	============ Aggregate ====================
	Aggregated Template:  Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>
[UpdateBucket] Logs: This iter found: 0, total: 178970/179993, remain: 1023. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 107 -> 107, remain buckets: 37
Update failed: Template can not match logs `Saved output of task '<task_id>' to hdfs://<ip_or_url>/pageout/out5/_temporary/1/task_<task_id>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 61, Total Buckets: 269
Sampling from 57 logs, Sim Level: 2, MaxSim to anchor: 0.5556. Anchor: `Saved output of task 'attempt_1445087491445_0005_r_000000_1' to hdfs://msra-sa-41:9000/out/out2/_temporary/1/task_1445087491445_0005_r_000000`, MaxSim Log: `Saved output of task 'attempt_1445062781478_0018_r_000000_1000' to hdfs://msra-sa-41:9000/pageout/out3/_temporary/2/task_1445062781478_0018_r_000000`.
	============  Query  ====================
	Log[1]: `Saved output of task 'attempt_1445087491445_0005_r_000000_1' to hdfs://msra-sa-41:9000/out/out2/_temporary/1/task_1445087491445_0005_r_000000`
	Log[2]: `Saved output of task 'attempt_1445087491445_0008_r_000000_1000' to hdfs://msra-sa-41:9000/out/out4/_temporary/2/task_1445087491445_0008_r_000000`
	Log[3]: `Saved output of task 'attempt_1445062781478_0014_r_000000_0' to hdfs://msra-sa-41:9000/pageout/out4/_temporary/1/task_1445062781478_0014_r_000000`
	============ Response ====================
LogTemplate[1]: `Saved output of task '{attempt_id}' to {hdfs_path}`
LogTemplate[2]: `Saved output of task '{attempt_id}' to {hdfs_path}`
LogTemplate[3]: `Saved output of task '{attempt_id}' to {hdfs_path}`
	============ PostProcess ====================
	Post Template: `Saved output of task <*> to <*>`
	Post Template: `Saved output of task <*> to <*>`
	Post Template: `Saved output of task <*> to <*>`
	============ Aggregate ====================
	Aggregated Template:  Saved output of task <*> to <*>
[UpdateBucket] Logs: This iter found: 48, total: 179018/179993, remain: 975. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 107 -> 59, remain buckets: 37
Update Success: Time for one update logs: 0.07692313194274902, template `Saved output of task <*> to <*>`
========================================================================================


Iteration 173
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 61, Total Buckets: 269
Sampling from 5 logs failed
	============  Query  ====================
	Log[1]: `Merging 0 segments, 0 bytes from memory into reduce`
	============ Response ====================
LogTemplate[1]: `Merging {number} segments, {number} bytes from memory into reduce`
	============ PostProcess ====================
	Post Template: `Merging <*> segments, <*> bytes from memory into reduce`
	============ Aggregate ====================
	Aggregated Template:  Merging <*> segments, <*> bytes from memory into reduce
[UpdateBucket] Logs: This iter found: 56, total: 179074/179993, remain: 919. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 108 -> 52, remain buckets: 37
Update Success: Time for one update logs: 0.01739811897277832, template `Merging <*> segments, <*> bytes from memory into reduce`
========================================================================================


Iteration 174
Sample 3 from current logs bucket: ID: 249, Len: 13, Bucket Size: 60, Total Buckets: 269
Sampling from 42 logs, Sim Level: 7, MaxSim to anchor: 0.6250. Anchor: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:13 CompletedReds:0 ContAlloc:27 ContRel:0 HostLocal:12 RackLocal:13`, MaxSim Log: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:10 CompletedReds:0 ContAlloc:13 ContRel:0 HostLocal:12 RackLocal:0`.
	============  Query  ====================
	Log[1]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:13 CompletedReds:0 ContAlloc:27 ContRel:0 HostLocal:12 RackLocal:13`
	Log[2]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:10 CompletedReds:0 ContAlloc:18 ContRel:0 HostLocal:9 RackLocal:8`
	Log[3]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:10 CompletedReds:0 ContAlloc:13 ContRel:0 HostLocal:10 RackLocal:0`
	============ Response ====================
LogTemplate[1]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:{num1} CompletedReds:0 ContAlloc:{num2} ContRel:0 HostLocal:{num3} RackLocal:{num4}`
LogTemplate[2]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:{num1} CompletedReds:0 ContAlloc:{num2} ContRel:0 HostLocal:{num3} RackLocal:{num4}`
LogTemplate[3]: `Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:{num1} CompletedReds:0 ContAlloc:{num2} ContRel:0 HostLocal:{num3} RackLocal:{num4}`
	============ PostProcess ====================
	Post Template: `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	Post Template: `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
	============ Aggregate ====================
	Aggregated Template:  Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
[UpdateBucket] Logs: This iter found: 48, total: 179122/179993, remain: 871. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 60 -> 12, remain buckets: 37
[TemplateDB] Try Merge: `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>` | `Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
[TemplateDB] Reject Merge, Remain Template: `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
Update Success: Time for one update logs: 0.015115976333618164, template `Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>`
========================================================================================


Iteration 175
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 59, Total Buckets: 269
Sampling from 11 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `assigned 1 of 1 to 04DN8IQ.fareast.corp.microsoft.com:13562 to fetcher#4`, MaxSim Log: `assigned 1 of 1 to 04DN8IQ.fareast.corp.microsoft.com:13562 to fetcher#1`.
	============  Query  ====================
	Log[1]: `assigned 1 of 1 to 04DN8IQ.fareast.corp.microsoft.com:13562 to fetcher#4`
	Log[2]: `assigned 1 of 1 to MININT-FNANLI5.fareast.corp.microsoft.com:13562 to fetcher#3`
	Log[3]: `assigned 1 of 1 to MININT-75DGDAM1.fareast.corp.microsoft.com:13562 to fetcher#1`
	============ Response ====================
LogTemplate[1]: `assigned 1 of 1 to {hostname}.fareast.corp.microsoft.com:{port} to fetcher#{fetcher_number}`
LogTemplate[2]: `assigned 1 of 1 to {hostname}.fareast.corp.microsoft.com:{port} to fetcher#{fetcher_number}`
LogTemplate[3]: `assigned 1 of 1 to {hostname}.fareast.corp.microsoft.com:{port} to fetcher#{fetcher_number}`
	============ PostProcess ====================
	Post Template: `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
	Post Template: `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
	Post Template: `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
	============ Aggregate ====================
	Aggregated Template:  assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>
[UpdateBucket] Logs: This iter found: 75, total: 179197/179993, remain: 796. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 107 -> 32, remain buckets: 36
[TemplateDB] Try Merge: `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>` | `assigned <*> of <*> to MSRA-SA-<*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
	Post Template: `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
[TemplateDB] Merged: -> `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 472/472, in child Bucket [216, 217, 218, 219, 220, 221, 222, 223, 224]
Update Success: Time for one update logs: 0.03821706771850586, template `assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>`
========================================================================================


Iteration 176
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 58, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Exception in getting events`
	============ Response ====================
LogTemplate[1]: `Exception in getting events`
	============ PostProcess ====================
	Post Template: `Exception in getting events`
	============ Aggregate ====================
	Aggregated Template:  Exception in getting events
[UpdateBucket] Logs: This iter found: 3, total: 179200/179993, remain: 793. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 58 -> 55, remain buckets: 36
Update Success: Time for one update logs: 0.03294825553894043, template `Exception in getting events`
========================================================================================


Iteration 177
Sample 1 from current logs bucket: ID: 62, Len: 6, Bucket Size: 56, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`
	============ Response ====================
LogTemplate[1]: `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`
	============ PostProcess ====================
	Post Template: `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`
	============ Aggregate ====================
	Aggregated Template:  mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[UpdateBucket] Logs: This iter found: 56, total: 179256/179993, remain: 737. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 204 -> 148, remain buckets: 35
Update Success: Time for one update logs: 0.018558979034423828, template `mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords`
========================================================================================


Iteration 178
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 55, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Stopping ReduceTask metrics system...`, MaxSim Log: `ReduceTask metrics system stopped.`.
	============  Query  ====================
	Log[1]: `Stopping ReduceTask metrics system...`
	============ Response ====================
LogTemplate[1]: `Stopping ReduceTask metrics system...`
	============ PostProcess ====================
	Post Template: `Stopping ReduceTask metrics system...`
	============ Aggregate ====================
	Aggregated Template:  Stopping ReduceTask metrics system...
[UpdateBucket] Logs: This iter found: 15, total: 179271/179993, remain: 722. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 55 -> 40, remain buckets: 35
[TemplateDB] Try Merge: `Stopping ReduceTask metrics system...` | `Stopping MapTask metrics system...`
[TemplateDB] Reject Merge, Remain Template: `Stopping ReduceTask metrics system...`
Update Success: Time for one update logs: 0.017503976821899414, template `Stopping ReduceTask metrics system...`
========================================================================================


Iteration 179
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 54, Total Buckets: 269
Sampling from 24 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/10.86.169.121"; destination host is: "04dn8iq.fareast.corp.microsoft.com":51086;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-39/172.22.149.145"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":52839;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`

LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`

LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";
[UpdateBucket] Logs: This iter found: 0, total: 179271/179993, remain: 722. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 54 -> 54, remain buckets: 35
Update failed: Template can not match logs `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 54, Total Buckets: 269
Sampling from 24 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-39/172.22.149.145"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":49594;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.15"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":62270;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`
LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`
LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "<*>{destination_host}";`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";
[UpdateBucket] Logs: This iter found: 0, total: 179271/179993, remain: 722. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 54 -> 54, remain buckets: 35
Update failed: Template can not match logs `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 54, Total Buckets: 269
Sampling from 24 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.9"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":55226;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":25859;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>/{ip_or_url}"; destination host is: "<*>/{ip_or_url}";`

LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>/{ip_or_url}"; destination host is: "<*>/{ip_or_url}";`

LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>/{ip_or_url}"; destination host is: "<*>/{ip_or_url}";`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";
[UpdateBucket] Logs: This iter found: 0, total: 179271/179993, remain: 722. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 54 -> 54, remain buckets: 35
Update failed: Template can not match logs `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>";`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
[UpdateBucket] Logs: This iter found: 1, total: 179272/179993, remain: 721. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 54 -> 53, remain buckets: 35
Update Success: Time for one update logs: 0.006591081619262695, template `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
========================================================================================


Iteration 180
Sample 3 from current logs bucket: ID: 57, Len: 5, Bucket Size: 53, Total Buckets: 269
Sampling from 47 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Result of canCommit for attempt_1445087491445_0005_r_000000_1:true`, MaxSim Log: `Result of canCommit for attempt_1445062781478_0018_r_000000_1000:true`.
	============  Query  ====================
	Log[1]: `Result of canCommit for attempt_1445087491445_0005_r_000000_1:true`
	Log[2]: `Result of canCommit for attempt_1445087491445_0001_r_000000_0:true`
	Log[3]: `Result of canCommit for attempt_1445087491445_0008_r_000000_1000:true`
	============ Response ====================
LogTemplate[1]: `Result of canCommit for attempt_<*>_r_<*>_<*>_<*>:true`
LogTemplate[2]: `Result of canCommit for attempt_<*>_r_<*>_<*>_<*>:true`
LogTemplate[3]: `Result of canCommit for attempt_<*>_r_<*>_<*>_<*>:true`
	============ PostProcess ====================
	Post Template: `Result of canCommit for <*>:true`
	Post Template: `Result of canCommit for <*>:true`
	Post Template: `Result of canCommit for <*>:true`
	============ Aggregate ====================
	Aggregated Template:  Result of canCommit for <*>:true
[UpdateBucket] Logs: This iter found: 47, total: 179319/179993, remain: 674. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 93 -> 46, remain buckets: 35
Update Success: Time for one update logs: 0.01079416275024414, template `Result of canCommit for <*>:true`
========================================================================================


Iteration 181
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 53, Total Buckets: 269
Sampling from 23 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":62270;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":53419;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/10.86.169.121"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":58957;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.15"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":62270;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;
[UpdateBucket] Logs: This iter found: 4, total: 179323/179993, remain: 670. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 53 -> 49, remain buckets: 35
[TemplateDB] Try Merge: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;` | `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
[TemplateDB] Merged: -> `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 5/5, in child Bucket [262]
Update Success: Time for one update logs: 0.013793230056762695, template `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
========================================================================================


Iteration 182
Sample 3 from current logs bucket: ID: 72, Len: 6, Bucket Size: 50, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `JobHistoryEventHandler notified that forceJobCompletion is true`
	============ Response ====================
LogTemplate[1]: `JobHistoryEventHandler notified that forceJobCompletion is true`
	============ PostProcess ====================
	Post Template: `JobHistoryEventHandler notified that forceJobCompletion is true`
	============ Aggregate ====================
	Aggregated Template:  JobHistoryEventHandler notified that forceJobCompletion is true
[UpdateBucket] Logs: This iter found: 50, total: 179373/179993, remain: 620. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 148 -> 98, remain buckets: 34
Update Success: Time for one update logs: 0.017903804779052734, template `JobHistoryEventHandler notified that forceJobCompletion is true`
========================================================================================


Iteration 183
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 50, Total Buckets: 269
Sampling from 19 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Previous history file is at hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job_1445062781478_0018_1.jhist`, MaxSim Log: `Previous history file is at hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445087491445_0002/job_1445087491445_0002_1.jhist`.
	============  Query  ====================
	Log[1]: `Previous history file is at hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445062781478_0018/job_1445062781478_0018_1.jhist`
	Log[2]: `Previous history file is at hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0018/job_1445182159119_0018_1.jhist`
	Log[3]: `Previous history file is at hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging/msrabi/.staging/job_1445182159119_0019/job_1445182159119_0019_1.jhist`
	============ Response ====================
LogTemplate[1]: `Previous history file is at hdfs://{ip_or_url}/tmp/hadoop-yarn/staging/msrabi/.staging/job_{job_id}/job_{job_id}_1.jhist`
	============ PostProcess ====================
	Post Template: `Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist`
	Post Template: `Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist`
	Post Template: `Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist`
	============ Aggregate ====================
	Aggregated Template:  Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist
[UpdateBucket] Logs: This iter found: 19, total: 179392/179993, remain: 601. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 98 -> 79, remain buckets: 34
Update Success: Time for one update logs: 0.021225929260253906, template `Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist`
========================================================================================


Iteration 184
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 49, Total Buckets: 269
Sampling from 20 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-39/172.22.149.145"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":49594;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-39/172.22.149.145"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":62270;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-39/172.22.149.145"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":49594;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MSRA-SA-41/10.190.173.170"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":55226;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "04DN8IQ/10.86.164.15"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":62304;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{local_host}"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;
[UpdateBucket] Logs: This iter found: 25, total: 179417/179993, remain: 576. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 49 -> 24, remain buckets: 34
[TemplateDB] Try Merge: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;` | `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-75dgdam1.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-<*>.fareast.corp.microsoft.com":<*>;`
[TemplateDB] Merged: -> `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-<*>.fareast.corp.microsoft.com":<*>;`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 30/30, in child Bucket [262]
[UpdateBucket] Logs: This iter found: 0, total: 179417/179993, remain: 576. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 24 -> 24, remain buckets: 34
[TemplateDB] Update Indexes: 30 -> 30 for `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-<*>.fareast.corp.microsoft.com":<*>;`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-<*>.fareast.corp.microsoft.com":<*>;`
Update Success: Time for one update logs: 0.021210908889770508, template `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-fnanli5.fareast.corp.microsoft.com":<*>;`
========================================================================================


Iteration 185
Sample 3 from current logs bucket: ID: 69, Len: 6, Bucket Size: 48, Total Buckets: 269
Sampling from 47 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Stopping IPC Server listener on 32070`, MaxSim Log: `Stopping IPC Server listener on 19911`.
	============  Query  ====================
	Log[1]: `Stopping IPC Server listener on 32070`
	Log[2]: `Stopping IPC Server listener on 24300`
	Log[3]: `Stopping IPC Server listener on 63282`
	============ Response ====================
LogTemplate[1]: `Stopping IPC Server listener on {port}`  
LogTemplate[2]: `Stopping IPC Server listener on {port}`  
LogTemplate[3]: `Stopping IPC Server listener on {port}`  
	============ PostProcess ====================
	Post Template: `Stopping IPC Server listener on <*>`
	Post Template: `Stopping IPC Server listener on <*>`
	Post Template: `Stopping IPC Server listener on <*>`
	============ Aggregate ====================
	Aggregated Template:  Stopping IPC Server listener on <*>
[UpdateBucket] Logs: This iter found: 48, total: 179465/179993, remain: 528. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 79 -> 31, remain buckets: 33
Update Success: Time for one update logs: 0.020078182220458984, template `Stopping IPC Server listener on <*>`
========================================================================================


Iteration 186
Sample 3 from current logs bucket: ID: 232, Len: 9, Bucket Size: 47, Total Buckets: 269
Sampling from 46 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `attempt_1445087491445_0005_r_000000_1 given a go for committing the task output.`, MaxSim Log: `attempt_1445062781478_0018_r_000000_1000 given a go for committing the task output.`.
	============  Query  ====================
	Log[1]: `attempt_1445087491445_0005_r_000000_1 given a go for committing the task output.`
	Log[2]: `attempt_1445175094696_0002_r_000000_0 given a go for committing the task output.`
	Log[3]: `attempt_1445144423722_0022_r_000000_0 given a go for committing the task output.`
	============ Response ====================
LogTemplate[1]: `attempt_{timestamp}_r_{number}_1 given a go for committing the task output.`  
LogTemplate[2]: `attempt_{timestamp}_r_{number}_0 given a go for committing the task output.`  
LogTemplate[3]: `attempt_{timestamp}_r_{number}_0 given a go for committing the task output.`  
	============ PostProcess ====================
	Post Template: `<*> given a go for committing the task output.`
	Post Template: `<*> given a go for committing the task output.`
	Post Template: `<*> given a go for committing the task output.`
	============ Aggregate ====================
	Aggregated Template:  <*> given a go for committing the task output.
[UpdateBucket] Logs: This iter found: 47, total: 179512/179993, remain: 481. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 52 -> 5, remain buckets: 32
Update Success: Time for one update logs: 0.006743907928466797, template `<*> given a go for committing the task output.`
========================================================================================


Iteration 187
Sample 3 from current logs bucket: ID: 214, Len: 7, Bucket Size: 46, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.1667. Anchor: `Waiting for application to be successfully unregistered.`, MaxSim Log: `Reporting fetch failure for attempt_1445087491445_0004_m_000005_0 to jobtracker.`.
	============  Query  ====================
	Log[1]: `Waiting for application to be successfully unregistered.`
	============ Response ====================
LogTemplate[1]: `Waiting for application to be successfully unregistered.`
	============ PostProcess ====================
	Post Template: `Waiting for application to be successfully unregistered.`
	============ Aggregate ====================
	Aggregated Template:  Waiting for application to be successfully unregistered.
[UpdateBucket] Logs: This iter found: 45, total: 179557/179993, remain: 436. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 59 -> 14, remain buckets: 32
Update Success: Time for one update logs: 0.08120012283325195, template `Waiting for application to be successfully unregistered.`
========================================================================================


Iteration 188
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 40, Total Buckets: 269
Sampling from 26 logs failed
	============  Query  ====================
	Log[1]: `ReduceTask metrics system stopped.`
	============ Response ====================
LogTemplate[1]: `ReduceTask metrics system stopped.`
	============ PostProcess ====================
	Post Template: `ReduceTask metrics system stopped.`
	============ Aggregate ====================
	Aggregated Template:  ReduceTask metrics system stopped.
[UpdateBucket] Logs: This iter found: 15, total: 179572/179993, remain: 421. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 40 -> 25, remain buckets: 32
[TemplateDB] Try Merge: `ReduceTask metrics system stopped.` | `MapTask metrics system stopped.`
[TemplateDB] Reject Merge, Remain Template: `ReduceTask metrics system stopped.`
Update Success: Time for one update logs: 0.03150677680969238, template `ReduceTask metrics system stopped.`
========================================================================================


Iteration 189
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 38, Total Buckets: 269
Sampling from 23 logs failed
	============  Query  ====================
	Log[1]: `Merging 4 intermediate segments out of a total of 13`
	============ Response ====================
LogTemplate[1]: `Merging {number} intermediate segments out of a total of {total}`
	============ PostProcess ====================
	Post Template: `Merging <*> intermediate segments out of a total of <*>`
	============ Aggregate ====================
	Aggregated Template:  Merging <*> intermediate segments out of a total of <*>
[UpdateBucket] Logs: This iter found: 7, total: 179579/179993, remain: 414. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 45 -> 38, remain buckets: 32
Update Success: Time for one update logs: 0.008208990097045898, template `Merging <*> intermediate segments out of a total of <*>`
========================================================================================


Iteration 190
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 37, Total Buckets: 269
Sampling from 29 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742931_2130`, MaxSim Log: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742903_2102`.
	============  Query  ====================
	Log[1]: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742931_2130`
	============ Response ====================
LogTemplate[1] Abandoning BP-{num1}-{ip}-{num2}:{blk_id}
	============ PostProcess ====================
	Post Template: `Abandoning BP-<*>:blk_1073742931_2130`
	============ Aggregate ====================
	Aggregated Template:  Abandoning BP-<*>:blk_1073742931_2130
[UpdateBucket] Logs: This iter found: 1, total: 179580/179993, remain: 413. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 37 -> 36, remain buckets: 32
Update Success: Time for one update logs: 0.010590791702270508, template `Abandoning BP-<*>:blk_1073742931_2130`
========================================================================================


Iteration 191
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 36, Total Buckets: 269
Sampling from 28 logs, Sim Level: 1, MaxSim to anchor: 0.3333. Anchor: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742903_2102`, MaxSim Log: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742515_1710`.
	============  Query  ====================
	Log[1]: `Abandoning BP-1347369012-10.190.173.170-1444972147527:blk_1073742903_2102`
	============ Response ====================
LogTemplate[1]: `Abandoning BP-{num1}-{ip}-{num2}:{blk_id}`
	============ PostProcess ====================
	Post Template: `Abandoning BP-<*>`
	============ Aggregate ====================
	Aggregated Template:  Abandoning BP-<*>
[UpdateBucket] Logs: This iter found: 29, total: 179609/179993, remain: 384. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 36 -> 7, remain buckets: 32
[TemplateDB] Try Merge: `Abandoning BP-<*>` | `Abandoning BP-<*>:blk_1073742931_2130`
	Post Template: `Abandoning BP-<*>`
[TemplateDB] Merged: -> `Abandoning BP-<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 30/30, in child Bucket [1, 2, 3, 4, 5]
Update Success: Time for one update logs: 0.01578211784362793, template `Abandoning BP-<*>`
========================================================================================


Iteration 192
Sample 3 from current logs bucket: ID: 252, Len: 14, Bucket Size: 34, Total Buckets: 269
Sampling from 6 logs, Sim Level: 2, MaxSim to anchor: 0.1200. Anchor: `Recovery is enabled. Will try to recover from previous life on best effort basis.`, MaxSim Log: `Diagnostics report from attempt_1445182159119_0004_m_000004_0: Error: java.io.IOException: There is not enough space on the disk`.
	============  Query  ====================
	Log[1]: `Recovery is enabled. Will try to recover from previous life on best effort basis.`
	============ Response ====================
LogTemplate[1]: `Recovery is enabled. Will try to recover from previous life on best effort basis.`
	============ PostProcess ====================
	Post Template: `Recovery is enabled. Will try to recover from previous life on best effort basis.`
	============ Aggregate ====================
	Aggregated Template:  Recovery is enabled. Will try to recover from previous life on best effort basis.
[UpdateBucket] Logs: This iter found: 15, total: 179624/179993, remain: 369. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 34 -> 19, remain buckets: 32
Update Success: Time for one update logs: 0.007605075836181641, template `Recovery is enabled. Will try to recover from previous life on best effort basis.`
========================================================================================


Iteration 193
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 31, Total Buckets: 269
Sampling from 3 logs, Sim Level: 1, MaxSim to anchor: 0.7143. Anchor: `Read completed tasks from history 9`, MaxSim Log: `Read completed tasks from history 13`.
	============  Query  ====================
	Log[1]: `Read completed tasks from history 9`
	Log[2]: `Read completed tasks from history 13`
	Log[3]: `Read completed tasks from history 10`
	============ Response ====================
LogTemplate[1]: `Read completed tasks from history {task_number}`  
LogTemplate[2]: `Read completed tasks from history {task_number}`  
LogTemplate[3]: `Read completed tasks from history {task_number}`  
	============ PostProcess ====================
	Post Template: `Read completed tasks from history <*>`
	Post Template: `Read completed tasks from history <*>`
	Post Template: `Read completed tasks from history <*>`
	============ Aggregate ====================
	Aggregated Template:  Read completed tasks from history <*>
[UpdateBucket] Logs: This iter found: 11, total: 179635/179993, remain: 358. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 31 -> 20, remain buckets: 32
Update Success: Time for one update logs: 0.019159793853759766, template `Read completed tasks from history <*>`
========================================================================================


Iteration 194
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 31, Total Buckets: 269
Sampling from 15 logs, Sim Level: 2, MaxSim to anchor: 0.8182. Anchor: `TaskAttempt killed because it ran on unusable node MININT-FNANLI5.fareast.corp.microsoft.com:55629. AttemptId:attempt_1445087491445_0002_m_000006_1`, MaxSim Log: `TaskAttempt killed because it ran on unusable node MININT-FNANLI5.fareast.corp.microsoft.com:55629. AttemptId:attempt_1445087491445_0004_m_000005_0`.
	============  Query  ====================
	Log[1]: `TaskAttempt killed because it ran on unusable node MININT-FNANLI5.fareast.corp.microsoft.com:55629. AttemptId:attempt_1445087491445_0002_m_000006_1`
	Log[2]: `TaskAttempt killed because it ran on unusable node 04DN8IQ.fareast.corp.microsoft.com:55452. AttemptId:attempt_1445087491445_0004_m_000004_0`
	Log[3]: `TaskAttempt killed because it ran on unusable node MININT-FNANLI5.fareast.corp.microsoft.com:55135. AttemptId:attempt_1445087491445_0010_m_000008_0`
	============ Response ====================
LogTemplate[1]: `TaskAttempt killed because it ran on unusable node {node}. AttemptId:{attempt_id}`
LogTemplate[2]: `TaskAttempt killed because it ran on unusable node {node}. AttemptId:{attempt_id}`
LogTemplate[3]: `TaskAttempt killed because it ran on unusable node {node}. AttemptId:{attempt_id}`
	============ PostProcess ====================
	Post Template: `TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>`
	Post Template: `TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>`
	Post Template: `TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>`
	============ Aggregate ====================
	Aggregated Template:  TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>
[UpdateBucket] Logs: This iter found: 25, total: 179660/179993, remain: 333. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 38 -> 13, remain buckets: 32
Update Success: Time for one update logs: 0.014156103134155273, template `TaskAttempt killed because it ran on unusable node <*> AttemptId:<*>`
========================================================================================


Iteration 195
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 25, Total Buckets: 269
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `History url is http://MININT-FNANLI5.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445144423722_0020`, MaxSim Log: `History url is http://MININT-FNANLI5.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445175094696_0003`.
	============  Query  ====================
	Log[1]: `History url is http://MININT-FNANLI5.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445144423722_0020`
	Log[2]: `History url is http://04DN8IQ.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445182159119_0020`
	Log[3]: `History url is http://MININT-FNANLI5.fareast.corp.microsoft.com:19888/jobhistory/job/job_1445182159119_0018`
	============ Response ====================
LogTemplate[1]: `History url is http://{ip_or_url}:19888/jobhistory/job/job_{job_id}`
	============ PostProcess ====================
	Post Template: `History url is http://<*>:19888/jobhistory/job/job_<*>`
	Post Template: `History url is http://<*>:19888/jobhistory/job/job_<*>`
	Post Template: `History url is http://<*>:19888/jobhistory/job/job_<*>`
	============ Aggregate ====================
	Aggregated Template:  History url is http://<*>:19888/jobhistory/job/job_<*>
[UpdateBucket] Logs: This iter found: 19, total: 179679/179993, remain: 314. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 25 -> 6, remain buckets: 32
[TemplateDB] Try Merge: `History url is http://<*>:19888/jobhistory/job/job_<*>` | `History url is http://MSRA-SA-<*>.fareast.corp.microsoft.com:19888/jobhistory/job/<*>`
	Post Template: `History url is http://<*>`
[TemplateDB] Merged: -> `History url is http://<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 48/48, in child Bucket [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]
[UpdateBucket] Logs: This iter found: 0, total: 179679/179993, remain: 314. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 6 -> 6, remain buckets: 32
[TemplateDB] Update Indexes: 48 -> 48 for `History url is http://<*>`
[TemplateBaseUpdate] Match unparsed logs 0 with new template `History url is http://<*>`
Update Success: Time for one update logs: 0.06808710098266602, template `History url is http://<*>:19888/jobhistory/job/job_<*>`
========================================================================================


Iteration 196
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 25, Total Buckets: 269
Sampling from 6 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d`, MaxSim Log: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent@13bb724a`.
	============  Query  ====================
	Log[1]: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent@7317849d`
	Log[2]: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent@13bb724a`
	Log[3]: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletionEvent@2890300b`
	============ Response ====================
LogTemplate[1]: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.{event_type}@{hash}`
	============ PostProcess ====================
	Post Template: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>`
	Post Template: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>`
	Post Template: `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>`
	============ Aggregate ====================
	Aggregated Template:  Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>
[UpdateBucket] Logs: This iter found: 4, total: 179683/179993, remain: 310. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 46 -> 42, remain buckets: 32
Update Success: Time for one update logs: 0.012926101684570312, template `Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>`
========================================================================================


Iteration 197
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 24, Total Buckets: 269
Sampling from 7 logs, Sim Level: 3, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":25859;`, MaxSim Log: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":29630;`.
	============  Query  ====================
	Log[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/127.0.0.1"; destination host is: "10.190.173.170":25859;`
	Log[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-75DGDAM1/10.86.165.66"; destination host is: "04dn8iq.fareast.corp.microsoft.com":49470;`
	Log[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "MININT-FNANLI5/10.86.169.121"; destination host is: "04dn8iq.fareast.corp.microsoft.com":51086;`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/{ip_address}"; destination host is: "{hostname_or_ip_address}":{port};`
LogTemplate[2]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/{ip_address}"; destination host is: "{server_address}":{port};`
LogTemplate[3]: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>{hostname}/{ip_address}"; destination host is: "{server_address}":{port};`
	============ PostProcess ====================
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;
[UpdateBucket] Logs: This iter found: 14, total: 179697/179993, remain: 296. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 24 -> 10, remain buckets: 32
[TemplateDB] Try Merge: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;` | `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "minint-<*>.fareast.corp.microsoft.com":<*>;`
	Post Template: `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
[TemplateDB] Merged: -> `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 44/44, in child Bucket [262]
Update Success: Time for one update logs: 0.011547088623046875, template `Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;`
========================================================================================


Iteration 198
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 21, Total Buckets: 269
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.6667. Anchor: `1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com`, MaxSim Log: `2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com`.
	============  Query  ====================
	Log[1]: `1 failures on node MININT-FNANLI5.fareast.corp.microsoft.com`
	Log[2]: `1 failures on node 04DN8IQ.fareast.corp.microsoft.com`
	Log[3]: `2 failures on node MININT-FNANLI5.fareast.corp.microsoft.com`
	============ Response ====================
LogTemplate[1]: `1 failures on node {node}`
LogTemplate[2]: `1 failures on node {node}`
LogTemplate[3]: `2 failures on node {node}`
	============ PostProcess ====================
	Post Template: `<*> failures on node <*>`
	Post Template: `<*> failures on node <*>`
	Post Template: `<*> failures on node <*>`
	============ Aggregate ====================
	Aggregated Template:  <*> failures on node <*>
[UpdateBucket] Logs: This iter found: 10, total: 179707/179993, remain: 286. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 42 -> 32, remain buckets: 32
Update Success: Time for one update logs: 0.014419794082641602, template `<*> failures on node <*>`
========================================================================================


Iteration 199
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 20, Total Buckets: 269
Sampling from 17 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743510_2729`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742860_2056`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179707/179993, remain: 286. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 20 -> 20, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 20, Total Buckets: 269
Sampling from 17 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743654_2877`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743032_2244`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179707/179993, remain: 286. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 20 -> 20, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 20, Total Buckets: 269
Sampling from 17 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743654_2877`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179707/179993, remain: 286. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 20 -> 20, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073742514_1708`
[UpdateBucket] Logs: This iter found: 1, total: 179708/179993, remain: 285. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 20 -> 19, remain buckets: 32
Update Success: Time for one update logs: 0.012202978134155273, template `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073742514_1708`
========================================================================================


Iteration 200
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 19, Total Buckets: 269
Sampling from 16 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743655_2878`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743654_2877`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743032_2244`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179708/179993, remain: 285. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 19 -> 19, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 19, Total Buckets: 269
Sampling from 16 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743655_2878`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743509_2728`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743032_2244`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179708/179993, remain: 285. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 19 -> 19, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 1 times when updating is not successful
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 19, Total Buckets: 269
Sampling from 16 logs, Sim Level: 3, MaxSim to anchor: 0.7143. Anchor: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`, MaxSim Log: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743655_2878`.
	============  Query  ====================
	Log[1]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731`
	Log[2]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743655_2878`
	Log[3]: `DFSOutputStream ResponseProcessor exception for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743032_2244`
	============ Response ====================
LogTemplate[1]: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ PostProcess ====================
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`
	============ Aggregate ====================
	Aggregated Template:  DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>
[UpdateBucket] Logs: This iter found: 0, total: 179708/179993, remain: 285. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 19 -> 19, remain buckets: 32
Update failed: Template can not match logs `DFSOutputStream ResponseProcessor exception for block BP-<*>:<blk_id>`. Retry query
Update failed. Retry 2 times failed. Try to get a compromise response
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073743512_2731`
[UpdateBucket] Logs: This iter found: 1, total: 179709/179993, remain: 284. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 19 -> 18, remain buckets: 32
[TemplateDB] Try Merge: `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073743512_2731` | `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073742514_1708`
	Post Template: `DFSOutputStream ResponseProcessor exception for block BP-<*>`
[TemplateDB] Merged: -> `DFSOutputStream ResponseProcessor exception for block BP-<*>`
[TemplateBaseUpdate] Update previous logs with merged template, succeed/all: 2/2, in child Bucket [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]
[UpdateBucket] Logs: This iter found: 12, total: 179721/179993, remain: 272. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 18 -> 6, remain buckets: 32
[TemplateDB] Update Indexes: 2 -> 14 for `DFSOutputStream ResponseProcessor exception for block BP-<*>`
[TemplateBaseUpdate] Match unparsed logs 12 with new template `DFSOutputStream ResponseProcessor exception for block BP-<*>`
Update Success: Time for one update logs: 0.03310990333557129, template `DFSOutputStream ResponseProcessor exception for block BP-<*>:blk_1073743512_2731`
========================================================================================


Iteration 201
Sample 3 from current logs bucket: ID: 223, Len: 8, Bucket Size: 19, Total Buckets: 269
Sampling from 18 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Container complete event for unknown container id container_1445062781478_0018_01_000012`, MaxSim Log: `Container complete event for unknown container id container_1445062781478_0018_01_000013`.
	============  Query  ====================
	Log[1]: `Container complete event for unknown container id container_1445062781478_0018_01_000012`
	Log[2]: `Container complete event for unknown container id container_1445062781478_0013_01_000013`
	Log[3]: `Container complete event for unknown container id container_1445076437777_0003_01_000013`
	============ Response ====================
LogTemplate[1]: `Container complete event for unknown container id container_<*>_<*>_<*>_<*>`  
LogTemplate[2]: `Container complete event for unknown container id container_<*>_<*>_<*>_<*>`  
LogTemplate[3]: `Container complete event for unknown container id container_<*>_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Container complete event for unknown container id <*>`
	Post Template: `Container complete event for unknown container id <*>`
	Post Template: `Container complete event for unknown container id <*>`
	============ Aggregate ====================
	Aggregated Template:  Container complete event for unknown container id <*>
[UpdateBucket] Logs: This iter found: 19, total: 179740/179993, remain: 253. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 32 -> 13, remain buckets: 31
Update Success: Time for one update logs: 0.01419687271118164, template `Container complete event for unknown container id <*>`
========================================================================================


Iteration 202
Sample 3 from current logs bucket: ID: 252, Len: 14, Bucket Size: 19, Total Buckets: 269
Sampling from 6 logs, Sim Level: 2, MaxSim to anchor: 0.0769. Anchor: `Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out`, MaxSim Log: `Task: attempt_1445182159119_0004_m_000004_0 - exited : java.io.IOException: There is not enough space on the disk`.
	============  Query  ====================
	Log[1]: `Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out`
	============ Response ====================
LogTemplate[1]: `Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for {file}`
	============ PostProcess ====================
	Post Template: `Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>`
	============ Aggregate ====================
	Aggregated Template:  Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>
[UpdateBucket] Logs: This iter found: 1, total: 179741/179993, remain: 252. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 19 -> 18, remain buckets: 31
Update Success: Time for one update logs: 0.008877992630004883, template `Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>`
========================================================================================


Iteration 203
Sample 3 from current logs bucket: ID: 244, Len: 12, Bucket Size: 18, Total Buckets: 269
Sampling from 13 logs, Sim Level: 2, MaxSim to anchor: 0.6000. Anchor: `Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708 in pipeline 10.190.173.170:50010, 10.86.164.9:50010: bad datanode 10.86.164.9:50010`, MaxSim Log: `Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742863_2059 in pipeline 10.190.173.170:50010, 10.86.169.121:50010: bad datanode 10.86.169.121:50010`.
	============  Query  ====================
	Log[1]: `Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073742514_1708 in pipeline 10.190.173.170:50010, 10.86.164.9:50010: bad datanode 10.86.164.9:50010`
	Log[2]: `Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743032_2244 in pipeline 172.22.149.145:50010, 10.86.169.121:50010: bad datanode 10.86.169.121:50010`
	Log[3]: `Error Recovery for block BP-1347369012-10.190.173.170-1444972147527:blk_1073743512_2731 in pipeline 10.86.169.121:50010, 10.190.173.170:50010: bad datanode 10.190.173.170:50010`
	============ Response ====================
LogTemplate[1]: `Error Recovery for block BP-<*>-<*>-<*>:blk_<*>_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>`  
LogTemplate[2]: `Error Recovery for block BP-<*>-<*>-<*>:blk_<*>_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>`  
LogTemplate[3]: `Error Recovery for block BP-<*>-<*>-<*>:blk_<*>_<*> in pipeline <*>:<*>, <*>:<*>: bad datanode <*>:<*>`  
	============ PostProcess ====================
	Post Template: `Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>`
	Post Template: `Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>`
	Post Template: `Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>`
	============ Aggregate ====================
	Aggregated Template:  Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>
[UpdateBucket] Logs: This iter found: 14, total: 179755/179993, remain: 238. 
[UpdateBucket] Buckets: Checked 2 ([243, 244]), Parent Bucket size: 18 -> 4, remain buckets: 31
Update Success: Time for one update logs: 0.005960941314697266, template `Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>`
========================================================================================


Iteration 204
Sample 3 from current logs bucket: ID: 252, Len: 14, Bucket Size: 18, Total Buckets: 269
Sampling from 5 logs, Sim Level: 2, MaxSim to anchor: 0.8667. Anchor: `Task: attempt_1445182159119_0004_m_000004_0 - exited : java.io.IOException: There is not enough space on the disk`, MaxSim Log: `Task: attempt_1445182159119_0015_m_000005_0 - exited : java.io.IOException: There is not enough space on the disk`.
	============  Query  ====================
	Log[1]: `Task: attempt_1445182159119_0004_m_000004_0 - exited : java.io.IOException: There is not enough space on the disk`
	Log[2]: `Task: attempt_1445182159119_0015_m_000005_0 - exited : java.io.IOException: There is not enough space on the disk`
	Log[3]: `Task: attempt_1445182159119_0015_m_000006_0 - exited : java.io.IOException: There is not enough space on the disk`
	============ Response ====================
LogTemplate[1]: `Task: attempt_<*> - exited : java.io.IOException: There is not enough space on the disk`
LogTemplate[2]: `Task: attempt_<*> - exited : java.io.IOException: There is not enough space on the disk`
LogTemplate[3]: `Task: attempt_<*> - exited : java.io.IOException: There is not enough space on the disk`
	============ PostProcess ====================
	Post Template: `Task: <*> - exited : java.io.IOException: There is not enough space on the disk`
	Post Template: `Task: <*> - exited : java.io.IOException: There is not enough space on the disk`
	Post Template: `Task: <*> - exited : java.io.IOException: There is not enough space on the disk`
	============ Aggregate ====================
	Aggregated Template:  Task: <*> - exited : java.io.IOException: There is not enough space on the disk
[UpdateBucket] Logs: This iter found: 6, total: 179761/179993, remain: 232. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 18 -> 12, remain buckets: 31
Update Success: Time for one update logs: 0.01008915901184082, template `Task: <*> - exited : java.io.IOException: There is not enough space on the disk`
========================================================================================


Iteration 205
Sample 3 from current logs bucket: ID: 54, Len: 5, Bucket Size: 15, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `ReduceTask metrics system shutdown complete.`
	============ Response ====================
LogTemplate[1]: `ReduceTask metrics system shutdown complete.`
	============ PostProcess ====================
	Post Template: `ReduceTask metrics system shutdown complete.`
	============ Aggregate ====================
	Aggregated Template:  ReduceTask metrics system shutdown complete.
[UpdateBucket] Logs: This iter found: 15, total: 179776/179993, remain: 217. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 32 -> 17, remain buckets: 30
[TemplateDB] Try Merge: `ReduceTask metrics system shutdown complete.` | `MapTask metrics system shutdown complete.`
[TemplateDB] Reject Merge, Remain Template: `ReduceTask metrics system shutdown complete.`
Update Success: Time for one update logs: 0.015449047088623047, template `ReduceTask metrics system shutdown complete.`
========================================================================================


Iteration 206
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 14, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Exception while unregistering`
	============ Response ====================
LogTemplate[1]: `Exception while unregistering`
	============ PostProcess ====================
	Post Template: `Exception while unregistering`
	============ Aggregate ====================
	Aggregated Template:  Exception while unregistering
[UpdateBucket] Logs: This iter found: 3, total: 179779/179993, remain: 214. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 14 -> 11, remain buckets: 30
Update Success: Time for one update logs: 0.008977890014648438, template `Exception while unregistering`
========================================================================================


Iteration 207
Sample 1 from current logs bucket: ID: 215, Len: 7, Bucket Size: 13, Total Buckets: 269
Sampling from 9 logs, Sim Level: 1, MaxSim to anchor: 0.7500. Anchor: `Added attempt_1445144423722_0020_m_000002_1 to list of failed maps`, MaxSim Log: `Added attempt_1445144423722_0020_m_000001_1 to list of failed maps`.
	============  Query  ====================
	Log[1]: `Added attempt_1445144423722_0020_m_000002_1 to list of failed maps`
	Log[2]: `Added attempt_1445182159119_0003_m_000000_2 to list of failed maps`
	Log[3]: `Added attempt_1445144423722_0020_m_000001_1 to list of failed maps`
	============ Response ====================
LogTemplate[1]: `Added attempt_<*> to list of failed maps`
LogTemplate[2]: `Added attempt_<*> to list of failed maps`
LogTemplate[3]: `Added attempt_<*> to list of failed maps`
	============ PostProcess ====================
	Post Template: `Added <*> to list of failed maps`
	Post Template: `Added <*> to list of failed maps`
	Post Template: `Added <*> to list of failed maps`
	============ Aggregate ====================
	Aggregated Template:  Added <*> to list of failed maps
[UpdateBucket] Logs: This iter found: 10, total: 179789/179993, remain: 204. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 14 -> 4, remain buckets: 30
Update Success: Time for one update logs: 0.07114315032958984, template `Added <*> to list of failed maps`
========================================================================================


Iteration 208
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 13, Total Buckets: 269
Sampling from 5 logs, Sim Level: 2, MaxSim to anchor: 0.7778. Anchor: `Task: attempt_1445182159119_0004_m_000004_0 - exited : java.io.IOException: Spill failed`, MaxSim Log: `Task: attempt_1445182159119_0015_m_000005_0 - exited : java.io.IOException: Spill failed`.
	============  Query  ====================
	Log[1]: `Task: attempt_1445182159119_0004_m_000004_0 - exited : java.io.IOException: Spill failed`
	Log[2]: `Task: attempt_1445182159119_0015_m_000006_0 - exited : java.io.IOException: Spill failed`
	Log[3]: `Task: attempt_1445182159119_0015_m_000005_0 - exited : java.io.IOException: Spill failed`
	============ Response ====================
LogTemplate[1]: `Task: attempt_{job_id}_m_{task_id}_{attempt_id}_0 - exited : java.io.IOException: Spill failed`
	============ PostProcess ====================
	Post Template: `Task: <*> - exited : java.io.IOException: Spill failed`
	Post Template: `Task: <*> - exited : java.io.IOException: Spill failed`
	Post Template: `Task: <*> - exited : java.io.IOException: Spill failed`
	============ Aggregate ====================
	Aggregated Template:  Task: <*> - exited : java.io.IOException: Spill failed
[UpdateBucket] Logs: This iter found: 3, total: 179792/179993, remain: 201. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 13 -> 10, remain buckets: 30
Update Success: Time for one update logs: 0.010870933532714844, template `Task: <*> - exited : java.io.IOException: Spill failed`
========================================================================================


Iteration 209
Sample 3 from current logs bucket: ID: 242, Len: 11, Bucket Size: 13, Total Buckets: 269
Sampling from 5 logs, Sim Level: 1, MaxSim to anchor: 0.8333. Anchor: `DFS chooseDataNode: got # 1 IOException, will wait for 723.7852941897946 msec.`, MaxSim Log: `DFS chooseDataNode: got # 1 IOException, will wait for 154.4690359206521 msec.`.
	============  Query  ====================
	Log[1]: `DFS chooseDataNode: got # 1 IOException, will wait for 723.7852941897946 msec.`
	Log[2]: `DFS chooseDataNode: got # 1 IOException, will wait for 154.4690359206521 msec.`
	Log[3]: `DFS chooseDataNode: got # 1 IOException, will wait for 2558.365341350332 msec.`
	============ Response ====================
LogTemplate[1]: `DFS chooseDataNode: got # 1 IOException, will wait for {time} msec.`
	============ PostProcess ====================
	Post Template: `DFS chooseDataNode: got # <*> IOException, will wait for <*> msec.`
	Post Template: `DFS chooseDataNode: got # <*> IOException, will wait for <*> msec.`
	Post Template: `DFS chooseDataNode: got # <*> IOException, will wait for <*> msec.`
	============ Aggregate ====================
	Aggregated Template:  DFS chooseDataNode: got # <*> IOException, will wait for <*> msec.
[UpdateBucket] Logs: This iter found: 6, total: 179798/179993, remain: 195. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 13 -> 7, remain buckets: 30
Update Success: Time for one update logs: 0.0065691471099853516, template `DFS chooseDataNode: got # <*> IOException, will wait for <*> msec.`
========================================================================================


Iteration 210
Sample 3 from current logs bucket: ID: 249, Len: 13, Bucket Size: 12, Total Buckets: 269
Sampling from 11 logs, Sim Level: 2, MaxSim to anchor: 0.7333. Anchor: `Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`, MaxSim Log: `Diagnostics report from attempt_1445144423722_0020_m_000007_0: cleanup failed for container container_1445144423722_0020_01_000009 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`
	Log[2]: `Diagnostics report from attempt_1445144423722_0023_m_000001_0: cleanup failed for container container_1445144423722_0023_01_000003 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-39.fareast.corp.microsoft.com`
	Log[3]: `Diagnostics report from attempt_1445144423722_0020_m_000000_0: cleanup failed for container container_1445144423722_0020_01_000002 : java.lang.IllegalArgumentException: java.net.UnknownHostException: 04DN8IQ.fareast.corp.microsoft.com`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>_m_<*>_<*>_<*> : cleanup failed for container container_<*>_<*>_<*>_<*>_<*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: {hostname}`
LogTemplate[2]: `Diagnostics report from attempt_<*>_m_<*>_<*>_<*> : cleanup failed for container container_<*>_<*>_<*>_<*>_<*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: {hostname}`
LogTemplate[3]: `Diagnostics report from attempt_<*>_m_<*>_<*>_<*> : cleanup failed for container container_<*>_<*>_<*>_<*>_<*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: {hostname}`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*> : cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	Post Template: `Diagnostics report from <*> : cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	Post Template: `Diagnostics report from <*> : cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*> : cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
[UpdateBucket] Logs: This iter found: 0, total: 179798/179993, remain: 195. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 12 -> 12, remain buckets: 30
Update failed: Template can not match logs `Diagnostics report from <*> : cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 249, Len: 13, Bucket Size: 12, Total Buckets: 269
Sampling from 11 logs, Sim Level: 2, MaxSim to anchor: 0.7333. Anchor: `Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`, MaxSim Log: `Diagnostics report from attempt_1445144423722_0020_m_000007_0: cleanup failed for container container_1445144423722_0020_01_000009 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445144423722_0020_m_000006_0: cleanup failed for container container_1445144423722_0020_01_000008 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-41.fareast.corp.microsoft.com`
	Log[2]: `Diagnostics report from attempt_1445144423722_0023_m_000000_0: cleanup failed for container container_1445144423722_0023_01_000002 : java.lang.IllegalArgumentException: java.net.UnknownHostException: 04DN8IQ.fareast.corp.microsoft.com`
	Log[3]: `Diagnostics report from attempt_1445144423722_0020_m_000009_0: cleanup failed for container container_1445144423722_0020_01_000011 : java.lang.IllegalArgumentException: java.net.UnknownHostException: MSRA-SA-39.fareast.corp.microsoft.com`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_{attempt_id}_m_{m_id}_0: cleanup failed for container container_{container_id}_01_{sub_id} : java.lang.IllegalArgumentException: java.net.UnknownHostException: {host_name}`
LogTemplate[2]: `Diagnostics report from attempt_{attempt_id}_m_{m_id}_0: cleanup failed for container container_{container_id}_01_{sub_id} : java.lang.IllegalArgumentException: java.net.UnknownHostException: {host_name}`
LogTemplate[3]: `Diagnostics report from attempt_{attempt_id}_m_{m_id}_0: cleanup failed for container container_{container_id}_01_{sub_id} : java.lang.IllegalArgumentException: java.net.UnknownHostException: {host_name}`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	Post Template: `Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	Post Template: `Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
[UpdateBucket] Logs: This iter found: 12, total: 179810/179993, remain: 183. 
[UpdateBucket] Buckets: Checked 5 ([245, 246, 247, 248, 249]), Parent Bucket size: 12 -> 0, remain buckets: 29
Update Success: Time for one update logs: 0.008101224899291992, template `Diagnostics report from <*>: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>`
========================================================================================


Iteration 211
Sample 3 from current logs bucket: ID: 252, Len: 14, Bucket Size: 12, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.8667. Anchor: `Diagnostics report from attempt_1445182159119_0004_m_000004_0: Error: java.io.IOException: There is not enough space on the disk`, MaxSim Log: `Diagnostics report from attempt_1445182159119_0015_m_000005_0: Error: java.io.IOException: There is not enough space on the disk`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445182159119_0004_m_000004_0: Error: java.io.IOException: There is not enough space on the disk`
	Log[2]: `Diagnostics report from attempt_1445182159119_0015_m_000005_0: Error: java.io.IOException: There is not enough space on the disk`
	Log[3]: `Diagnostics report from attempt_1445182159119_0015_m_000006_0: Error: java.io.IOException: There is not enough space on the disk`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>_<*>_m_<*>_<*>: Error: java.io.IOException: There is not enough space on the disk`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk`
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk`
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk
[UpdateBucket] Logs: This iter found: 12, total: 179822/179993, remain: 171. 
[UpdateBucket] Buckets: Checked 3 ([250, 251, 252]), Parent Bucket size: 12 -> 0, remain buckets: 28
Update Success: Time for one update logs: 0.009377002716064453, template `Diagnostics report from <*>: Error: java.io.IOException: There is not enough space on the disk`
========================================================================================


Iteration 212
Sample 3 from current logs bucket: ID: 266, Len: 43, Bucket Size: 12, Total Buckets: 269
Sampling from 11 logs, Sim Level: 4, MaxSim to anchor: 0.9512. Anchor: `Cannot assign container Container: [ContainerId: container_1445062781478_0018_01_000013, NodeId: MININT-75DGDAM1.fareast.corp.microsoft.com:51951, NodeHttpAddress: MININT-75DGDAM1.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.165.66:51951 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`, MaxSim Log: `Cannot assign container Container: [ContainerId: container_1445062781478_0013_01_000014, NodeId: MININT-75DGDAM1.fareast.corp.microsoft.com:51951, NodeHttpAddress: MININT-75DGDAM1.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.165.66:51951 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`.
	============  Query  ====================
	Log[1]: `Cannot assign container Container: [ContainerId: container_1445062781478_0018_01_000013, NodeId: MININT-75DGDAM1.fareast.corp.microsoft.com:51951, NodeHttpAddress: MININT-75DGDAM1.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.165.66:51951 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`
	Log[2]: `Cannot assign container Container: [ContainerId: container_1445062781478_0015_01_000012, NodeId: MSRA-SA-39.fareast.corp.microsoft.com:49130, NodeHttpAddress: MSRA-SA-39.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 172.22.149.145:49130 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`
	Log[3]: `Cannot assign container Container: [ContainerId: container_1445182159119_0004_01_000015, NodeId: 04DN8IQ.fareast.corp.microsoft.com:64260, NodeHttpAddress: 04DN8IQ.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.86.164.138:64260 }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`
	============ Response ====================
LogTemplate[1]: `Cannot assign container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: {priority}, Token: Token { kind: ContainerToken, service: {service_address} }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`

LogTemplate[2]: `Cannot assign container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: {priority}, Token: Token { kind: ContainerToken, service: {service_address} }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`

LogTemplate[3]: `Cannot assign container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: {priority}, Token: Token { kind: ContainerToken, service: {service_address} }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true`
	============ PostProcess ====================
	Post Template: `Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true`
	Post Template: `Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true`
	Post Template: `Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true`
	============ Aggregate ====================
	Aggregated Template:  Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true
[UpdateBucket] Logs: This iter found: 12, total: 179834/179993, remain: 159. 
[UpdateBucket] Buckets: Checked 1 ([266]), Parent Bucket size: 12 -> 0, remain buckets: 27
Update Success: Time for one update logs: 0.008555173873901367, template `Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true`
========================================================================================


Iteration 213
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 11, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Graceful stop failed`
	============ Response ====================
LogTemplate[1]: `Graceful stop failed`
	============ PostProcess ====================
	Post Template: `Graceful stop failed`
	============ Aggregate ====================
	Aggregated Template:  Graceful stop failed
[UpdateBucket] Logs: This iter found: 3, total: 179837/179993, remain: 156. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 11 -> 8, remain buckets: 27
Update Success: Time for one update logs: 0.006762027740478516, template `Graceful stop failed`
========================================================================================


Iteration 214
Sample 1 from current logs bucket: ID: 59, Len: 5, Bucket Size: 11, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `In stop, writing event MAP_ATTEMPT_FAILED`, MaxSim Log: `In stop, writing event TASK_FINISHED`.
	============  Query  ====================
	Log[1]: `In stop, writing event MAP_ATTEMPT_FAILED`
	Log[2]: `In stop, writing event TASK_FINISHED`
	Log[3]: `In stop, writing event JOB_FINISHED`
	============ Response ====================
LogTemplate[1]: `In stop, writing event {event_type}`  
LogTemplate[2]: `In stop, writing event {event_type}`  
LogTemplate[3]: `In stop, writing event {event_type}`  
	============ PostProcess ====================
	Post Template: `In stop, writing event <*>`
	Post Template: `In stop, writing event <*>`
	Post Template: `In stop, writing event <*>`
	============ Aggregate ====================
	Aggregated Template:  In stop, writing event <*>
[UpdateBucket] Logs: This iter found: 6, total: 179843/179993, remain: 150. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 17 -> 11, remain buckets: 27
Update Success: Time for one update logs: 0.014011859893798828, template `In stop, writing event <*>`
========================================================================================


Iteration 215
Sample 3 from current logs bucket: ID: 258, Len: 20, Bucket Size: 11, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8889. Anchor: `Failed to connect to /172.22.149.145:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`, MaxSim Log: `Failed to connect to /10.190.173.170:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`.
	============  Query  ====================
	Log[1]: `Failed to connect to /172.22.149.145:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
	Log[2]: `Failed to connect to /10.190.173.170:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
	============ Response ====================
LogTemplate[1]: `Failed to connect to /{ip}:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
LogTemplate[2]: `Failed to connect to /{ip}:50010 for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
	============ PostProcess ====================
	Post Template: `Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
	Post Template: `Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
	============ Aggregate ====================
	Aggregated Template:  Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information
[UpdateBucket] Logs: This iter found: 10, total: 179853/179993, remain: 140. 
[UpdateBucket] Buckets: Checked 1 ([258]), Parent Bucket size: 11 -> 1, remain buckets: 27
Update Success: Time for one update logs: 0.005236148834228516, template `Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information`
========================================================================================


Iteration 216
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 10, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.7778. Anchor: `Diagnostics report from attempt_1445182159119_0004_m_000004_0: Error: java.io.IOException: Spill failed`, MaxSim Log: `Diagnostics report from attempt_1445182159119_0015_m_000005_0: Error: java.io.IOException: Spill failed`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445182159119_0004_m_000004_0: Error: java.io.IOException: Spill failed`
	Log[2]: `Diagnostics report from attempt_1445182159119_0015_m_000006_0: Error: java.io.IOException: Spill failed`
	Log[3]: `Diagnostics report from attempt_1445182159119_0015_m_000005_0: Error: java.io.IOException: Spill failed`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>: Error: java.io.IOException: Spill failed`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: Spill failed`
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: Spill failed`
	Post Template: `Diagnostics report from <*>: Error: java.io.IOException: Spill failed`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Error: java.io.IOException: Spill failed
[UpdateBucket] Logs: This iter found: 6, total: 179859/179993, remain: 134. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 10 -> 4, remain buckets: 27
Update Success: Time for one update logs: 0.01399993896484375, template `Diagnostics report from <*>: Error: java.io.IOException: Spill failed`
========================================================================================


Iteration 217
Sample 3 from current logs bucket: ID: 262, Len: 29, Bucket Size: 10, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.9200. Anchor: `Communication exception: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to 10.190.173.170:25859 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`, MaxSim Log: `Communication exception: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to 10.190.173.170:29630 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`.
	============  Query  ====================
	Log[1]: `Communication exception: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to 10.190.173.170:25859 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	Log[2]: `Communication exception: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to 10.190.173.170:29630 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.net.NoRouteToHostException: No Route to Host from {hostname}/{ip} to {destination_ip}:{port} failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: {url}`
	============ PostProcess ====================
	Post Template: `Communication exception: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
	Post Template: `Communication exception: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
[UpdateBucket] Logs: This iter found: 10, total: 179869/179993, remain: 124. 
[UpdateBucket] Buckets: Checked 1 ([262]), Parent Bucket size: 10 -> 0, remain buckets: 26
Update Success: Time for one update logs: 0.0066220760345458984, template `Communication exception: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
========================================================================================


Iteration 218
Sample 3 from current logs bucket: ID: 257, Len: 19, Bucket Size: 9, Total Buckets: 269
Sampling from 8 logs, Sim Level: 2, MaxSim to anchor: 0.8000. Anchor: `Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]`, MaxSim Log: `Slow ReadProcessor read fields took 49366ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 172.22.149.145:50010]`.
	============  Query  ====================
	Log[1]: `Slow ReadProcessor read fields took 65020ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.86.169.121:50010, 10.190.173.170:50010]`
	Log[2]: `Slow ReadProcessor read fields took 48944ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [172.22.149.145:50010, 10.86.169.121:50010]`
	Log[3]: `Slow ReadProcessor read fields took 48906ms (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: [10.190.173.170:50010, 10.86.169.121:50010]`
	============ Response ====================
LogTemplate[1]: `Slow ReadProcessor read fields took {time}ms (threshold={threshold}ms); ack: seqno: {seqno} status: {status} status: {status} downstreamAckTimeNanos: {downstreamAckTimeNanos}, targets: [{ip_or_url}:{port}, {ip_or_url}:{port}]`  
LogTemplate[2]: `Slow ReadProcessor read fields took {time}ms (threshold={threshold}ms); ack: seqno: {seqno} status: {status} status: {status} downstreamAckTimeNanos: {downstreamAckTimeNanos}, targets: [{ip_or_url}:{port}, {ip_or_url}:{port}]`  
LogTemplate[3]: `Slow ReadProcessor read fields took {time}ms (threshold={threshold}ms); ack: seqno: {seqno} status: {status} status: {status} downstreamAckTimeNanos: {downstreamAckTimeNanos}, targets: [{ip_or_url}:{port}, {ip_or_url}:{port}]`  
	============ PostProcess ====================
	Post Template: `Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*> targets: [<*>, <*>]`
	Post Template: `Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*> targets: [<*>, <*>]`
	Post Template: `Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*> targets: [<*>, <*>]`
	============ Aggregate ====================
	Aggregated Template:  Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*> targets: [<*>, <*>]
[UpdateBucket] Logs: This iter found: 9, total: 179878/179993, remain: 115. 
[UpdateBucket] Buckets: Checked 1 ([257]), Parent Bucket size: 9 -> 0, remain buckets: 25
Update Success: Time for one update logs: 0.005146026611328125, template `Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: <*> status: <*> status: <*> downstreamAckTimeNanos: <*> targets: [<*>, <*>]`
========================================================================================


Iteration 219
Sample 3 from current logs bucket: ID: 264, Len: 31, Bucket Size: 9, Total Buckets: 269
Sampling from 6 logs, Sim Level: 2, MaxSim to anchor: 0.9375. Anchor: `Releasing unassigned and invalid container Container: [ContainerId: container_1445062781478_0018_01_000012, NodeId: MININT-FNANLI5.fareast.corp.microsoft.com:64642, NodeHttpAddress: MININT-FNANLI5.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.169.121:64642 }, ]. RM may have assignment issues`, MaxSim Log: `Releasing unassigned and invalid container Container: [ContainerId: container_1445076437777_0003_01_000012, NodeId: MININT-FNANLI5.fareast.corp.microsoft.com:64642, NodeHttpAddress: MININT-FNANLI5.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.169.121:64642 }, ]. RM may have assignment issues`.
	============  Query  ====================
	Log[1]: `Releasing unassigned and invalid container Container: [ContainerId: container_1445062781478_0018_01_000012, NodeId: MININT-FNANLI5.fareast.corp.microsoft.com:64642, NodeHttpAddress: MININT-FNANLI5.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.169.121:64642 }, ]. RM may have assignment issues`
	Log[2]: `Releasing unassigned and invalid container Container: [ContainerId: container_1445182159119_0013_01_000012, NodeId: MSRA-SA-41.fareast.corp.microsoft.com:10769, NodeHttpAddress: MSRA-SA-41.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.190.173.170:10769 }, ]. RM may have assignment issues`
	Log[3]: `Releasing unassigned and invalid container Container: [ContainerId: container_1445062781478_0013_01_000013, NodeId: 04DN8IQ.fareast.corp.microsoft.com:64484, NodeHttpAddress: 04DN8IQ.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 10.86.164.9:64484 }, ]. RM may have assignment issues`
	============ Response ====================
LogTemplate[1]: `Releasing unassigned and invalid container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ]. RM may have assignment issues`  
LogTemplate[2]: `Releasing unassigned and invalid container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ]. RM may have assignment issues`  
LogTemplate[3]: `Releasing unassigned and invalid container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ]. RM may have assignment issues`  
	============ PostProcess ====================
	Post Template: `Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues`
	Post Template: `Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues`
	Post Template: `Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues`
	============ Aggregate ====================
	Aggregated Template:  Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues
[UpdateBucket] Logs: This iter found: 7, total: 179885/179993, remain: 108. 
[UpdateBucket] Buckets: Checked 1 ([264]), Parent Bucket size: 9 -> 2, remain buckets: 25
Update Success: Time for one update logs: 0.005018949508666992, template `Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues`
========================================================================================


Iteration 220
Sample 3 from current logs bucket: ID: 11, Len: 3, Bucket Size: 8, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Assigned from earlierFailedMaps`
	============ Response ====================
LogTemplate[1]: `Assigned from {placeholder}`
	============ PostProcess ====================
	Post Template: `Assigned from <*>`
	============ Aggregate ====================
	Aggregated Template:  Assigned from <*>
[UpdateBucket] Logs: This iter found: 8, total: 179893/179993, remain: 100. 
[UpdateBucket] Buckets: Checked 6 ([6, 7, 8, 9, 10, 11]), Parent Bucket size: 8 -> 0, remain buckets: 24
[TemplateDB] Try Merge: `Assigned from <*>` | `Assigned to <*>`
[TemplateDB] Reject Merge, Remain Template: `Assigned from <*>`
Update Success: Time for one update logs: 0.009710073471069336, template `Assigned from <*>`
========================================================================================


Iteration 221
Sample 1 from current logs bucket: ID: 261, Len: 27, Bucket Size: 8, Total Buckets: 269
Sampling from 7 logs, Sim Level: 2, MaxSim to anchor: 0.9286. Anchor: `Assigning container Container: [ContainerId: container_1445182159119_0003_01_000016, NodeId: 04DN8IQ.fareast.corp.microsoft.com:64260, NodeHttpAddress: 04DN8IQ.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.86.164.138:64260 }, ] to fast fail map`, MaxSim Log: `Assigning container Container: [ContainerId: container_1445182159119_0004_01_000014, NodeId: 04DN8IQ.fareast.corp.microsoft.com:64260, NodeHttpAddress: 04DN8IQ.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.86.164.138:64260 }, ] to fast fail map`.
	============  Query  ====================
	Log[1]: `Assigning container Container: [ContainerId: container_1445182159119_0003_01_000016, NodeId: 04DN8IQ.fareast.corp.microsoft.com:64260, NodeHttpAddress: 04DN8IQ.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.86.164.138:64260 }, ] to fast fail map`
	Log[2]: `Assigning container Container: [ContainerId: container_1445182159119_0004_01_000016, NodeId: MSRA-SA-41.fareast.corp.microsoft.com:10769, NodeHttpAddress: MSRA-SA-41.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 10.190.173.170:10769 }, ] to fast fail map`
	Log[3]: `Assigning container Container: [ContainerId: container_1445182159119_0015_01_000013, NodeId: MSRA-SA-39.fareast.corp.microsoft.com:28345, NodeHttpAddress: MSRA-SA-39.fareast.corp.microsoft.com:8042, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: 172.22.149.145:28345 }, ] to fast fail map`
	============ Response ====================
LogTemplate[1]: `Assigning container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ] to fast fail map`
LogTemplate[2]: `Assigning container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ] to fast fail map`
LogTemplate[3]: `Assigning container Container: [ContainerId: {container_id}, NodeId: {node_id}, NodeHttpAddress: {node_http_address}, Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: {service_ip_port} }, ] to fast fail map`
	============ PostProcess ====================
	Post Template: `Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map`
	Post Template: `Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map`
	Post Template: `Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map`
	============ Aggregate ====================
	Aggregated Template:  Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map
[UpdateBucket] Logs: This iter found: 8, total: 179901/179993, remain: 92. 
[UpdateBucket] Buckets: Checked 1 ([261]), Parent Bucket size: 8 -> 0, remain buckets: 23
Update Success: Time for one update logs: 0.005366086959838867, template `Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map`
========================================================================================


Iteration 222
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 7, Total Buckets: 269
	============  Query  ====================
	Log[1]: `DFS Read`
	============ Response ====================
LogTemplate[1]: `DFS Read`
	============ PostProcess ====================
	Post Template: `DFS Read`
	============ Aggregate ====================
	Aggregated Template:  DFS Read
[UpdateBucket] Logs: This iter found: 3, total: 179904/179993, remain: 89. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 7 -> 4, remain buckets: 23
Update Success: Time for one update logs: 0.0073490142822265625, template `DFS Read`
========================================================================================


Iteration 223
Sample 1 from current logs bucket: ID: 237, Len: 10, Bucket Size: 7, Total Buckets: 269
Sampling from 6 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Diagnostics report from attempt_1445062781478_0017_m_000002_0: AttemptID:attempt_1445062781478_0017_m_000002_0 Timed out after 600 secs`, MaxSim Log: `Diagnostics report from attempt_1445062781478_0017_m_000008_0: AttemptID:attempt_1445062781478_0017_m_000008_0 Timed out after 600 secs`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445062781478_0017_m_000002_0: AttemptID:attempt_1445062781478_0017_m_000002_0 Timed out after 600 secs`
	Log[2]: `Diagnostics report from attempt_1445087491445_0009_r_000000_0: AttemptID:attempt_1445087491445_0009_r_000000_0 Timed out after 600 secs`
	Log[3]: `Diagnostics report from attempt_1445076437777_0004_r_000000_0: AttemptID:attempt_1445076437777_0004_r_000000_0 Timed out after 600 secs`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_{attempt_id}: AttemptID:{attempt_id} Timed out after 600 secs`
LogTemplate[2]: `Diagnostics report from attempt_{attempt_id}: AttemptID:{attempt_id} Timed out after 600 secs`
LogTemplate[3]: `Diagnostics report from attempt_{attempt_id}: AttemptID:{attempt_id} Timed out after 600 secs`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs`
	Post Template: `Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs`
	Post Template: `Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs
[UpdateBucket] Logs: This iter found: 7, total: 179911/179993, remain: 82. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 13 -> 6, remain buckets: 22
Update Success: Time for one update logs: 0.012465953826904297, template `Diagnostics report from <*>: AttemptID:<*> Timed out after <*> secs`
========================================================================================


Iteration 224
Sample 3 from current logs bucket: ID: 242, Len: 11, Bucket Size: 7, Total Buckets: 269
Sampling from 3 logs failed
	============  Query  ====================
	Log[1]: `Error communicating with RM: Could not contact RM after 360000 milliseconds.`
	============ Response ====================
LogTemplate[1]: `Error communicating with RM: Could not contact RM after {milliseconds} milliseconds.`
	============ PostProcess ====================
	Post Template: `Error communicating with RM: Could not contact RM after <*> milliseconds.`
	============ Aggregate ====================
	Aggregated Template:  Error communicating with RM: Could not contact RM after <*> milliseconds.
[UpdateBucket] Logs: This iter found: 3, total: 179914/179993, remain: 79. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 7 -> 4, remain buckets: 22
Update Success: Time for one update logs: 0.008635997772216797, template `Error communicating with RM: Could not contact RM after <*> milliseconds.`
========================================================================================


Iteration 225
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 6, Total Buckets: 269
Sampling from 5 logs failed
	============  Query  ====================
	Log[1]: `Reduce preemption successful attempt_1445087491445_0004_r_000000_1000`
	============ Response ====================
LogTemplate[1]: `Reduce preemption successful attempt_<*>_<*>_r_<*>_<*>`
	============ PostProcess ====================
	Post Template: `Reduce preemption successful <*>`
	============ Aggregate ====================
	Aggregated Template:  Reduce preemption successful <*>
[UpdateBucket] Logs: This iter found: 1, total: 179915/179993, remain: 78. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 6 -> 5, remain buckets: 22
Update Success: Time for one update logs: 0.020852088928222656, template `Reduce preemption successful <*>`
========================================================================================


Iteration 226
Sample 3 from current logs bucket: ID: 57, Len: 5, Bucket Size: 6, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Runnning cleanup for the task`
	============ Response ====================
LogTemplate[1]: `Runnning cleanup for the task`
	============ PostProcess ====================
	Post Template: `Runnning cleanup for the task`
	============ Aggregate ====================
	Aggregated Template:  Runnning cleanup for the task
[UpdateBucket] Logs: This iter found: 6, total: 179921/179993, remain: 72. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 11 -> 5, remain buckets: 21
Update Success: Time for one update logs: 0.012434959411621094, template `Runnning cleanup for the task`
========================================================================================


Iteration 227
Sample 1 from current logs bucket: ID: 78, Len: 6, Bucket Size: 6, Total Buckets: 269
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.7143. Anchor: `Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0`, MaxSim Log: `Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0`.
	============  Query  ====================
	Log[1]: `Task cleanup failed for attempt attempt_1445144423722_0020_m_000002_0`
	Log[2]: `Task cleanup failed for attempt attempt_1445144423722_0020_m_000001_0`
	============ Response ====================
LogTemplate[1]: `Task cleanup failed for attempt attempt_<*>_<*>_<*>_<*>_<*>`  
LogTemplate[2]: `Task cleanup failed for attempt attempt_<*>_<*>_<*>_<*>_<*>`  
	============ PostProcess ====================
	Post Template: `Task cleanup failed for attempt <*>`
	Post Template: `Task cleanup failed for attempt <*>`
	============ Aggregate ====================
	Aggregated Template:  Task cleanup failed for attempt <*>
[UpdateBucket] Logs: This iter found: 2, total: 179923/179993, remain: 70. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 6 -> 4, remain buckets: 21
Update Success: Time for one update logs: 0.02123117446899414, template `Task cleanup failed for attempt <*>`
========================================================================================


Iteration 228
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 6, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8182. Anchor: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_1445087491445_0004`, MaxSim Log: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_1445087491445_0007`.
	============  Query  ====================
	Log[1]: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_1445087491445_0004`
	Log[2]: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_1445087491445_0007`
	============ Response ====================
LogTemplate[1]: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: {attempt_id}`  
LogTemplate[2]: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: {attempt_id}`  
	============ PostProcess ====================
	Post Template: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>`
	Post Template: `Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>`
	============ Aggregate ====================
	Aggregated Template:  Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>
[UpdateBucket] Logs: This iter found: 2, total: 179925/179993, remain: 68. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 6 -> 4, remain buckets: 21
Update Success: Time for one update logs: 0.011827945709228516, template `Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>`
========================================================================================


Iteration 229
Sample 3 from current logs bucket: ID: 265, Len: 32, Bucket Size: 6, Total Buckets: 269
Sampling from 3 logs, Sim Level: 2, MaxSim to anchor: 0.9310. Anchor: `Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`, MaxSim Log: `Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`.
	============  Query  ====================
	Log[1]: `Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	Log[2]: `Diagnostics report from attempt_1445144423722_0020_m_000002_0: Error: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	Log[3]: `Diagnostics report from attempt_1445144423722_0020_m_000001_0: Error: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Response ====================
LogTemplate[1]: `Task: {task_id} - exited : {error_type}: {error_message} from {source} to {destination} failed on {failure_reason}: {detailed_error_message}; For more details see: {link}`

LogTemplate[2]: `Diagnostics report from {task_id}: Error: {error_type}: {error_message} from {source} to {destination} failed on {failure_reason}: {detailed_error_message}; For more details see: {link}`

LogTemplate[3]: `Diagnostics report from {task_id}: Error: {error_type}: {error_message} from {source} to {destination} failed on {failure_reason}: {detailed_error_message}; For more details see: {link}`
	============ PostProcess ====================
	Post Template: `Task: <*> - exited : <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>`
	Post Template: `Diagnostics report from <*>: Error: <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>`
	Post Template: `Diagnostics report from <*>: Error: <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Error: <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>
[UpdateBucket] Logs: This iter found: 4, total: 179929/179993, remain: 64. 
[UpdateBucket] Buckets: Checked 1 ([265]), Parent Bucket size: 6 -> 2, remain buckets: 21
Update Success: Time for one update logs: 0.005018711090087891, template `Diagnostics report from <*>: Error: <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>`
========================================================================================


Iteration 230
Sample 3 from current logs bucket: ID: 48, Len: 4, Bucket Size: 5, Total Buckets: 269
Sampling from 4 logs, Sim Level: 1, MaxSim to anchor: 0.6000. Anchor: `Last retry, killing attempt_1445175094696_0004_m_000005_0`, MaxSim Log: `Last retry, killing attempt_1445175094696_0004_m_000000_0`.
	============  Query  ====================
	Log[1]: `Last retry, killing attempt_1445175094696_0004_m_000005_0`
	Log[2]: `Last retry, killing attempt_1445175094696_0004_m_000006_0`
	Log[3]: `Last retry, killing attempt_1445175094696_0004_m_000000_0`
	============ Response ====================
LogTemplate[1]: `Last retry, killing attempt_<*>_<*>_<*>_<*>_<*>`

LogTemplate[2]: `Last retry, killing attempt_<*>_<*>_<*>_<*>_<*>`

LogTemplate[3]: `Last retry, killing attempt_<*>_<*>_<*>_<*>_<*>`
	============ PostProcess ====================
	Post Template: `Last retry, killing <*>`
	Post Template: `Last retry, killing <*>`
	Post Template: `Last retry, killing <*>`
	============ Aggregate ====================
	Aggregated Template:  Last retry, killing <*>
[UpdateBucket] Logs: This iter found: 5, total: 179934/179993, remain: 59. 
[UpdateBucket] Buckets: Checked 37 ([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), Parent Bucket size: 5 -> 0, remain buckets: 20
Update Success: Time for one update logs: 0.03101491928100586, template `Last retry, killing <*>`
========================================================================================


Iteration 231
Sample 3 from current logs bucket: ID: 59, Len: 5, Bucket Size: 5, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Process Thread Dump: Communication exception`
	============ Response ====================
LogTemplate[1]: `Process Thread Dump: Communication exception`
	============ PostProcess ====================
	Post Template: `Process Thread Dump: Communication exception`
	============ Aggregate ====================
	Aggregated Template:  Process Thread Dump: Communication exception
[UpdateBucket] Logs: This iter found: 5, total: 179939/179993, remain: 54. 
[UpdateBucket] Buckets: Checked 11 ([49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), Parent Bucket size: 5 -> 0, remain buckets: 19
Update Success: Time for one update logs: 0.014706134796142578, template `Process Thread Dump: Communication exception`
========================================================================================


Iteration 232
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 5, Total Buckets: 269
Sampling from 2 logs, Sim Level: 2, MaxSim to anchor: 0.0625. Anchor: `Connection retry failed with 4 attempts in 180 seconds`, MaxSim Log: `Failed to connect to MININT-FNANLI5.fareast.corp.microsoft.com:13562 with 1 map outputs`.
	============  Query  ====================
	Log[1]: `Connection retry failed with 4 attempts in 180 seconds`
	============ Response ====================
LogTemplate[1]: `Connection retry failed with {number} attempts in {time} seconds`
	============ PostProcess ====================
	Post Template: `Connection retry failed with <*> attempts in <*> seconds`
	============ Aggregate ====================
	Aggregated Template:  Connection retry failed with <*> attempts in <*> seconds
[UpdateBucket] Logs: This iter found: 1, total: 179940/179993, remain: 53. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 5 -> 4, remain buckets: 19
Update Success: Time for one update logs: 0.015684127807617188, template `Connection retry failed with <*> attempts in <*> seconds`
========================================================================================


Iteration 233
Sample 3 from current logs bucket: ID: 267, Len: 46, Bucket Size: 5, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.9444. Anchor: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`, MaxSim Log: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`.
	============  Query  ====================
	Log[1]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	Log[2]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	Log[3]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	============ Response ====================
LogTemplate[1]: `Could not obtain BP-<*>-{ip_or_url}-<*>:blk_<*>_<*> from any node: java.io.IOException: No live nodes contain block BP-<*>-{ip_or_url}-<*>:blk_<*>_<*> after checking nodes = [<ip_or_url>:50010, {ip_or_url}:50010], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:50010 {ip_or_url}:50010 Dead nodes: {ip_or_url}:50010 <ip_or_url>:50010. Will get new block locations from namenode and retry...`
	============ PostProcess ====================
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<ip_or_url>:<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:<*> <*> Dead nodes: <*> <ip_or_url>:<*>. Will get new block locations from namenode and retry...`
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<ip_or_url>:<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:<*> <*> Dead nodes: <*> <ip_or_url>:<*>. Will get new block locations from namenode and retry...`
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<ip_or_url>:<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:<*> <*> Dead nodes: <*> <ip_or_url>:<*>. Will get new block locations from namenode and retry...`
	============ Aggregate ====================
	Aggregated Template:  Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<ip_or_url>:<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:<*> <*> Dead nodes: <*> <ip_or_url>:<*>. Will get new block locations from namenode and retry...
[UpdateBucket] Logs: This iter found: 0, total: 179940/179993, remain: 53. 
[UpdateBucket] Buckets: Checked 1 ([267]), Parent Bucket size: 5 -> 5, remain buckets: 19
Update failed: Template can not match logs `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<ip_or_url>:<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <ip_or_url>:<*> <*> Dead nodes: <*> <ip_or_url>:<*>. Will get new block locations from namenode and retry...`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 267, Len: 46, Bucket Size: 5, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.9444. Anchor: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`, MaxSim Log: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`.
	============  Query  ====================
	Log[1]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741828_1004 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	Log[2]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073741827_1003 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	Log[3]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry...`
	============ Response ====================
LogTemplate[1]: `Could not obtain BP-<*>-{ip_or_url}-<*>:{blk_id} from any node: java.io.IOException: No live nodes contain block BP-<*>-{ip_or_url}-<*>:{blk_id} after checking nodes = [<*>, <*>, <*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*>, <*> Dead nodes: <*>, <*>. Will get new block locations from namenode and retry...`

LogTemplate[2]: `Could not obtain BP-<*>-{ip_or_url}-<*>:{blk_id} from any node: java.io.IOException: No live nodes contain block BP-<*>-{ip_or_url}-<*>:{blk_id} after checking nodes = [<*>, <*>, <*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*>, <*> Dead nodes: <*>, <*>. Will get new block locations from namenode and retry...`

LogTemplate[3]: `Could not obtain BP-<*>-{ip_or_url}-<*>:{blk_id} from any node: java.io.IOException: No live nodes contain block BP-<*>-{ip_or_url}-<*>:{blk_id} after checking nodes = [<*>, <*>, <*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*>, <*> Dead nodes: <*>, <*>. Will get new block locations from namenode and retry...`
	============ PostProcess ====================
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
	Post Template: `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
	============ Aggregate ====================
	Aggregated Template:  Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...
[UpdateBucket] Logs: This iter found: 5, total: 179945/179993, remain: 48. 
[UpdateBucket] Buckets: Checked 1 ([267]), Parent Bucket size: 5 -> 0, remain buckets: 18
Update Success: Time for one update logs: 0.006190061569213867, template `Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
========================================================================================


Iteration 234
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 4, Total Buckets: 269
	============  Query  ====================
	Log[1]: `DataStreamer Exception`
	============ Response ====================
LogTemplate[1]: `DataStreamer Exception`
	============ PostProcess ====================
	Post Template: `DataStreamer Exception`
	============ Aggregate ====================
	Aggregated Template:  DataStreamer Exception
[UpdateBucket] Logs: This iter found: 3, total: 179948/179993, remain: 45. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 4 -> 1, remain buckets: 18
Update Success: Time for one update logs: 0.00964498519897461, template `DataStreamer Exception`
========================================================================================


Iteration 235
Sample 1 from current logs bucket: ID: 78, Len: 6, Bucket Size: 4, Total Buckets: 269
Sampling from 3 logs failed
	============  Query  ====================
	Log[1]: `JobHistoryEventHandler notified that forceJobCompletion is false`
	============ Response ====================
LogTemplate[1]: `JobHistoryEventHandler notified that forceJobCompletion is false`
	============ PostProcess ====================
	Post Template: `JobHistoryEventHandler notified that forceJobCompletion is false`
	============ Aggregate ====================
	Aggregated Template:  JobHistoryEventHandler notified that forceJobCompletion is false
[UpdateBucket] Logs: This iter found: 2, total: 179950/179993, remain: 43. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 4 -> 2, remain buckets: 18
[TemplateDB] Try Merge: `JobHistoryEventHandler notified that forceJobCompletion is false` | `JobHistoryEventHandler notified that forceJobCompletion is true`
[TemplateDB] Reject Merge, Remain Template: `JobHistoryEventHandler notified that forceJobCompletion is false`
Update Success: Time for one update logs: 0.020240306854248047, template `JobHistoryEventHandler notified that forceJobCompletion is false`
========================================================================================


Iteration 236
Sample 3 from current logs bucket: ID: 224, Len: 8, Bucket Size: 4, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Unable to parse prior job history, aborting recovery`
	============ Response ====================
LogTemplate[1]: `Unable to parse prior job history, aborting recovery`
	============ PostProcess ====================
	Post Template: `Unable to parse prior job history, aborting recovery`
	============ Aggregate ====================
	Aggregated Template:  Unable to parse prior job history, aborting recovery
[UpdateBucket] Logs: This iter found: 4, total: 179954/179993, remain: 39. 
[UpdateBucket] Buckets: Checked 9 ([216, 217, 218, 219, 220, 221, 222, 223, 224]), Parent Bucket size: 4 -> 0, remain buckets: 17
Update Success: Time for one update logs: 0.01138615608215332, template `Unable to parse prior job history, aborting recovery`
========================================================================================


Iteration 237
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 4, Total Buckets: 269
Sampling from 2 logs failed
	============  Query  ====================
	Log[1]: `Failed to connect to MININT-FNANLI5.fareast.corp.microsoft.com:13562 with 1 map outputs`
	============ Response ====================
LogTemplate[1]: `Failed to connect to {ip_or_url} with {number} map outputs`
	============ PostProcess ====================
	Post Template: `Failed to connect to <*> with <*> map outputs`
	============ Aggregate ====================
	Aggregated Template:  Failed to connect to <*> with <*> map outputs
[UpdateBucket] Logs: This iter found: 1, total: 179955/179993, remain: 38. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 4 -> 3, remain buckets: 17
Update Success: Time for one update logs: 0.011140108108520508, template `Failed to connect to <*> with <*> map outputs`
========================================================================================


Iteration 238
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 4, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8182. Anchor: `Found jobId job_1445175094696_0003 to have not been closed. Will close`, MaxSim Log: `Found jobId job_1445144423722_0023 to have not been closed. Will close`.
	============  Query  ====================
	Log[1]: `Found jobId job_1445175094696_0003 to have not been closed. Will close`
	Log[2]: `Found jobId job_1445144423722_0023 to have not been closed. Will close`
	============ Response ====================
LogTemplate[1]: `Found jobId {job_id} to have not been closed. Will close`
LogTemplate[2]: `Found jobId {job_id} to have not been closed. Will close`
	============ PostProcess ====================
	Post Template: `Found jobId <*> to have not been closed. Will close`
	Post Template: `Found jobId <*> to have not been closed. Will close`
	============ Aggregate ====================
	Aggregated Template:  Found jobId <*> to have not been closed. Will close
[UpdateBucket] Logs: This iter found: 2, total: 179957/179993, remain: 36. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 4 -> 2, remain buckets: 17
Update Success: Time for one update logs: 0.0076961517333984375, template `Found jobId <*> to have not been closed. Will close`
========================================================================================


Iteration 239
Sample 3 from current logs bucket: ID: 242, Len: 11, Bucket Size: 4, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.6667. Anchor: `Diagnostics report from attempt_1445182159119_0003_r_000000_0: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3`, MaxSim Log: `Diagnostics report from attempt_1445182159119_0014_r_000000_0: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1`.
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445182159119_0003_r_000000_0: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3`
	Log[2]: `Diagnostics report from attempt_1445182159119_0014_r_000000_0: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>_<*>_r_<*>_<*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
	Post Template: `Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>
[UpdateBucket] Logs: This iter found: 4, total: 179961/179993, remain: 32. 
[UpdateBucket] Buckets: Checked 4 ([239, 240, 241, 242]), Parent Bucket size: 4 -> 0, remain buckets: 16
Update Success: Time for one update logs: 0.009711742401123047, template `Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
========================================================================================


Iteration 240
Sample 3 from current logs bucket: ID: 244, Len: 12, Bucket Size: 4, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Could not parse the old history file. Will not have old AMinfos`
	============ Response ====================
LogTemplate[1]: `Could not parse the old history file. Will not have old AMinfos`
	============ PostProcess ====================
	Post Template: `Could not parse the old history file. Will not have old AMinfos`
	============ Aggregate ====================
	Aggregated Template:  Could not parse the old history file. Will not have old AMinfos
[UpdateBucket] Logs: This iter found: 4, total: 179965/179993, remain: 28. 
[UpdateBucket] Buckets: Checked 2 ([243, 244]), Parent Bucket size: 4 -> 0, remain buckets: 15
Update Success: Time for one update logs: 0.0061953067779541016, template `Could not parse the old history file. Will not have old AMinfos`
========================================================================================


Iteration 241
Sample 3 from current logs bucket: ID: 215, Len: 7, Bucket Size: 3, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Could not contact RM after 360000 milliseconds.`
	============ Response ====================
LogTemplate[1]: `Could not contact RM after {milliseconds} milliseconds.`
	============ PostProcess ====================
	Post Template: `Could not contact RM after <*> milliseconds.`
	============ Aggregate ====================
	Aggregated Template:  Could not contact RM after <*> milliseconds.
[UpdateBucket] Logs: This iter found: 3, total: 179968/179993, remain: 25. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 4 -> 1, remain buckets: 14
Update Success: Time for one update logs: 0.07207894325256348, template `Could not contact RM after <*> milliseconds.`
========================================================================================


Iteration 242
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 3, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.0588. Anchor: `IPC Server handler 29 on 58622 caught an exception`, MaxSim Log: `Shuffle failed : local error on this node: 04DN8IQ/10.86.164.138`.
	============  Query  ====================
	Log[1]: `IPC Server handler 29 on 58622 caught an exception`
	============ Response ====================
LogTemplate[1]: `IPC Server handler <*> on <*> caught an exception`
	============ PostProcess ====================
	Post Template: `IPC Server handler <*> on <*> caught an exception`
	============ Aggregate ====================
	Aggregated Template:  IPC Server handler <*> on <*> caught an exception
[UpdateBucket] Logs: This iter found: 1, total: 179969/179993, remain: 24. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 3 -> 2, remain buckets: 14
Update Success: Time for one update logs: 0.010560035705566406, template `IPC Server handler <*> on <*> caught an exception`
========================================================================================


Iteration 243
Sample 3 from current logs bucket: ID: 256, Len: 18, Bucket Size: 3, Total Buckets: 269
Sampling from 2 logs, Sim Level: 1, MaxSim to anchor: 0.0312. Anchor: `Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information`, MaxSim Log: `Service JobHistoryEventHandler failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.`.
	============  Query  ====================
	Log[1]: `Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information`
	============ Response ====================
LogTemplate[1]: `Failed to connect to /{ip_or_url} for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information`
	============ PostProcess ====================
	Post Template: `Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information`
	============ Aggregate ====================
	Aggregated Template:  Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information
[UpdateBucket] Logs: This iter found: 1, total: 179970/179993, remain: 23. 
[UpdateBucket] Buckets: Checked 1 ([256]), Parent Bucket size: 3 -> 2, remain buckets: 14
Update Success: Time for one update logs: 0.006123781204223633, template `Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information`
========================================================================================


Iteration 244
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.0909. Anchor: `Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6a6585ee`, MaxSim Log: `Error closing writer for JobID: job_1445144423722_0023`.
	============  Query  ====================
	Log[1]: `Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6a6585ee`
	============ Response ====================
LogTemplate[1]: `Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@{api}`
	============ PostProcess ====================
	Post Template: `Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@<*>`
	============ Aggregate ====================
	Aggregated Template:  Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@<*>
[UpdateBucket] Logs: This iter found: 1, total: 179971/179993, remain: 22. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 2 -> 1, remain buckets: 14
Update Success: Time for one update logs: 0.021195173263549805, template `Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@<*>`
========================================================================================


Iteration 245
Sample 3 from current logs bucket: ID: 233, Len: 9, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Shuffle failed : local error on this node: 04DN8IQ/10.86.164.138`
	============ Response ====================
LogTemplate[1]: `Shuffle failed : local error on this node: {node_id}/{ip}`
	============ PostProcess ====================
	Post Template: `Shuffle failed : local error on this node: <*>`
	============ Aggregate ====================
	Aggregated Template:  Shuffle failed : local error on this node: <*>
[UpdateBucket] Logs: This iter found: 2, total: 179973/179993, remain: 20. 
[UpdateBucket] Buckets: Checked 9 ([225, 226, 227, 228, 229, 230, 231, 232, 233]), Parent Bucket size: 2 -> 0, remain buckets: 13
Update Success: Time for one update logs: 0.00710606575012207, template `Shuffle failed : local error on this node: <*>`
========================================================================================


Iteration 246
Sample 3 from current logs bucket: ID: 238, Len: 10, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8000. Anchor: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3`, MaxSim Log: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1`.
	============  Query  ====================
	Log[1]: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3`
	Log[2]: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1`
	============ Response ====================
LogTemplate[1]: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#{placeholder}`
	============ PostProcess ====================
	Post Template: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
	Post Template: `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
	============ Aggregate ====================
	Aggregated Template:  Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>
[UpdateBucket] Logs: This iter found: 2, total: 179975/179993, remain: 18. 
[UpdateBucket] Buckets: Checked 5 ([234, 235, 236, 237, 238]), Parent Bucket size: 2 -> 0, remain buckets: 12
Update Success: Time for one update logs: 0.010527849197387695, template `Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>`
========================================================================================


Iteration 247
Sample 3 from current logs bucket: ID: 254, Len: 15, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Diagnostics report from attempt_1445182159119_0002_m_000007_0: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out`
	============ Response ====================
LogTemplate[1]: `Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_<*>_<*>_<*>/<*>`
	============ PostProcess ====================
	Post Template: `Diagnostics report from <*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_<*>_<*>_<*>`
	============ Aggregate ====================
	Aggregated Template:  Diagnostics report from <*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_<*>_<*>_<*>
[UpdateBucket] Logs: This iter found: 2, total: 179977/179993, remain: 16. 
[UpdateBucket] Buckets: Checked 2 ([253, 254]), Parent Bucket size: 2 -> 0, remain buckets: 11
Update Success: Time for one update logs: 0.005425930023193359, template `Diagnostics report from <*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_<*>_<*>_<*>`
========================================================================================


Iteration 248
Sample 3 from current logs bucket: ID: 255, Len: 16, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8824. Anchor: `Task: attempt_1445182159119_0003_m_000000_0 - failed due to FSError: java.io.IOException: There is not enough space on the disk`, MaxSim Log: `Task: attempt_1445182159119_0004_m_000000_0 - failed due to FSError: java.io.IOException: There is not enough space on the disk`.
	============  Query  ====================
	Log[1]: `Task: attempt_1445182159119_0003_m_000000_0 - failed due to FSError: java.io.IOException: There is not enough space on the disk`
	Log[2]: `Task: attempt_1445182159119_0004_m_000000_0 - failed due to FSError: java.io.IOException: There is not enough space on the disk`
	============ Response ====================
LogTemplate[1]: `Task: attempt_<*> - failed due to FSError: java.io.IOException: There is not enough space on the disk`
LogTemplate[2]: `Task: attempt_<*> - failed due to FSError: java.io.IOException: There is not enough space on the disk`
	============ PostProcess ====================
	Post Template: `Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk`
	Post Template: `Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk`
	============ Aggregate ====================
	Aggregated Template:  Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk
[UpdateBucket] Logs: This iter found: 2, total: 179979/179993, remain: 14. 
[UpdateBucket] Buckets: Checked 1 ([255]), Parent Bucket size: 2 -> 0, remain buckets: 10
Update Success: Time for one update logs: 0.004346132278442383, template `Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk`
========================================================================================


Iteration 249
Sample 3 from current logs bucket: ID: 256, Len: 18, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.8889. Anchor: `Service JobHistoryEventHandler failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.`, MaxSim Log: `Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.`.
	============  Query  ====================
	Log[1]: `Service JobHistoryEventHandler failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.`
	Log[2]: `Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.`
	============ Response ====================
LogTemplate[1]: `Service {service_name} failed in state STOPPED; cause: {exception_type}: {exception_message}`
LogTemplate[2]: `Service {service_name} failed in state STOPPED; cause: {exception_type}: {exception_message}`
	============ PostProcess ====================
	Post Template: `Service <*> failed in state STOPPED; cause: <*>: <*>`
	Post Template: `Service <*> failed in state STOPPED; cause: <*>: <*>`
	============ Aggregate ====================
	Aggregated Template:  Service <*> failed in state STOPPED; cause: <*>: <*>
[UpdateBucket] Logs: This iter found: 2, total: 179981/179993, remain: 12. 
[UpdateBucket] Buckets: Checked 1 ([256]), Parent Bucket size: 2 -> 0, remain buckets: 9
Update Success: Time for one update logs: 0.005786895751953125, template `Service <*> failed in state STOPPED; cause: <*>: <*>`
========================================================================================


Iteration 250
Sample 3 from current logs bucket: ID: 263, Len: 30, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Response ====================
LogTemplate[1]: `Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from {hostname}/{ip} to {server}:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: {url}`
	============ PostProcess ====================
	Post Template: `Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
	============ Aggregate ====================
	Aggregated Template:  Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
[UpdateBucket] Logs: This iter found: 2, total: 179983/179993, remain: 10. 
[UpdateBucket] Buckets: Checked 1 ([263]), Parent Bucket size: 2 -> 0, remain buckets: 8
Update Success: Time for one update logs: 0.0045468807220458984, template `Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
========================================================================================


Iteration 251
Sample 3 from current logs bucket: ID: 264, Len: 31, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs failed
	============  Query  ====================
	Log[1]: `Exception running child : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Response ====================
LogTemplate[1]: `Exception running child : java.net.NoRouteToHostException: No Route to Host from {hostname}/{ip} to {server}:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: {url}`
	============ PostProcess ====================
	Post Template: `Exception running child : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
	============ Aggregate ====================
	Aggregated Template:  Exception running child : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>
[UpdateBucket] Logs: This iter found: 2, total: 179985/179993, remain: 8. 
[UpdateBucket] Buckets: Checked 1 ([264]), Parent Bucket size: 2 -> 0, remain buckets: 7
Update Success: Time for one update logs: 0.005445241928100586, template `Exception running child : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>`
========================================================================================


Iteration 252
Sample 3 from current logs bucket: ID: 265, Len: 32, Bucket Size: 2, Total Buckets: 269
Sampling from 1 logs, Sim Level: 1, MaxSim to anchor: 0.9310. Anchor: `Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`, MaxSim Log: `Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`.
	============  Query  ====================
	Log[1]: `Task: attempt_1445144423722_0020_m_000002_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	Log[2]: `Task: attempt_1445144423722_0020_m_000001_0 - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Response ====================
LogTemplate[1]: `Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
LogTemplate[2]: `Task: attempt_<*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ PostProcess ====================
	Post Template: `Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	Post Template: `Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
	============ Aggregate ====================
	Aggregated Template:  Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
[UpdateBucket] Logs: This iter found: 2, total: 179987/179993, remain: 6. 
[UpdateBucket] Buckets: Checked 1 ([265]), Parent Bucket size: 2 -> 0, remain buckets: 6
Update Success: Time for one update logs: 0.005499839782714844, template `Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost`
========================================================================================


Iteration 253
Sample 3 from current logs bucket: ID: 5, Len: 2, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Preempting attempt_1445087491445_0004_r_000000_1000`
	============ Response ====================
LogTemplate[1]: `Preempting attempt_<*>_<*>_<*>_<*>_<*>`
	============ PostProcess ====================
	Post Template: `Preempting <*>`
	============ Aggregate ====================
	Aggregated Template:  Preempting <*>
[UpdateBucket] Logs: This iter found: 1, total: 179988/179993, remain: 5. 
[UpdateBucket] Buckets: Checked 5 ([1, 2, 3, 4, 5]), Parent Bucket size: 1 -> 0, remain buckets: 5
[TemplateDB] Try Merge: `Preempting <*>` | `Launching <*>`
[TemplateDB] Reject Merge, Remain Template: `Preempting <*>`
Update Success: Time for one update logs: 0.008933067321777344, template `Preempting <*>`
========================================================================================


Iteration 254
Sample 3 from current logs bucket: ID: 78, Len: 6, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Error closing writer for JobID: job_1445144423722_0023`
	============ Response ====================
LogTemplate[1]: `Error closing writer for JobID: {job_id}`
	============ PostProcess ====================
	Post Template: `Error closing writer for JobID: <*>`
	============ Aggregate ====================
	Aggregated Template:  Error closing writer for JobID: <*>
[UpdateBucket] Logs: This iter found: 1, total: 179989/179993, remain: 4. 
[UpdateBucket] Buckets: Checked 19 ([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]), Parent Bucket size: 1 -> 0, remain buckets: 4
Update Success: Time for one update logs: 0.009824037551879883, template `Error closing writer for JobID: <*>`
========================================================================================


Iteration 255
Sample 3 from current logs bucket: ID: 214, Len: 7, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Reporting fetch failure for attempt_1445087491445_0004_m_000005_0 to jobtracker.`
	============ Response ====================
LogTemplate[1]: `Reporting fetch failure for {attempt_id} to {service}.`
	============ PostProcess ====================
	Post Template: `Reporting fetch failure for <*> to <*>.`
	============ Aggregate ====================
	Aggregated Template:  Reporting fetch failure for <*> to <*>.
[UpdateBucket] Logs: This iter found: 1, total: 179990/179993, remain: 3. 
[UpdateBucket] Buckets: Checked 137 ([79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215]), Parent Bucket size: 1 -> 0, remain buckets: 3
Update Success: Time for one update logs: 0.07824277877807617, template `Reporting fetch failure for <*> to <*>.`
========================================================================================


Iteration 256
Sample 3 from current logs bucket: ID: 258, Len: 20, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `IPC Server handler 29 on 58622, call statusUpdate(attempt_1445094324383_0003_m_000000_0, org.apache.hadoop.mapred.MapTaskStatus@cdcdbf7), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.86.169.121:52490 Call#68 Retry#0: output error`
	============ Response ====================
LogTemplate[1]: `IPC Server handler <*> on <port>, call statusUpdate(<job_id>, <api>), rpc version=<rpc_version>, client version=<client_version>, methodsFingerPrint=<fingerprint> from <ip_or_url> Call#<call_num> Retry#<retry_num>: output error`
	============ PostProcess ====================
	Post Template: `IPC Server handler <*> on <port>, call statusUpdate(<job_id>, <api>), rpc version=<rpc_version>, client version=<client_version>, methodsFingerPrint=<fingerprint> from <ip_or_url> Call#<call_num> Retry#<retry_num>: output error`
	============ Aggregate ====================
	Aggregated Template:  IPC Server handler <*> on <port>, call statusUpdate(<job_id>, <api>), rpc version=<rpc_version>, client version=<client_version>, methodsFingerPrint=<fingerprint> from <ip_or_url> Call#<call_num> Retry#<retry_num>: output error
[UpdateBucket] Logs: This iter found: 0, total: 179990/179993, remain: 3. 
[UpdateBucket] Buckets: Checked 1 ([258]), Parent Bucket size: 1 -> 1, remain buckets: 3
Update failed: Template can not match logs `IPC Server handler <*> on <port>, call statusUpdate(<job_id>, <api>), rpc version=<rpc_version>, client version=<client_version>, methodsFingerPrint=<fingerprint> from <ip_or_url> Call#<call_num> Retry#<retry_num>: output error`. Retry query
Update failed. Retry 0 times when updating is not successful
Sample 3 from current logs bucket: ID: 258, Len: 20, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `IPC Server handler 29 on 58622, call statusUpdate(attempt_1445094324383_0003_m_000000_0, org.apache.hadoop.mapred.MapTaskStatus@cdcdbf7), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.86.169.121:52490 Call#68 Retry#0: output error`
	============ Response ====================
LogTemplate[1]: `IPC Server handler <{handler_num}> on {port_num}, call statusUpdate(<{attempt_id}>, {api}@{api_id}), rpc version={rpc_ver}, client version={client_ver}, methodsFingerPrint={fingerprint} from {ip_or_url}:{port} Call#{call_num} Retry#{retry_num}: {message}`
	============ PostProcess ====================
	Post Template: `IPC Server handler <*> on <*> call statusUpdate(<*>, <*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: <*>`
	============ Aggregate ====================
	Aggregated Template:  IPC Server handler <*> on <*> call statusUpdate(<*>, <*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: <*>
[UpdateBucket] Logs: This iter found: 1, total: 179991/179993, remain: 2. 
[UpdateBucket] Buckets: Checked 1 ([258]), Parent Bucket size: 1 -> 0, remain buckets: 2
Update Success: Time for one update logs: 0.0056819915771484375, template `IPC Server handler <*> on <*> call statusUpdate(<*>, <*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: <*>`
========================================================================================


Iteration 257
Sample 3 from current logs bucket: ID: 260, Len: 24, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Communication exception: java.net.ConnectException: Call From MSRA-SA-39/172.22.149.145 to minint-fnanli5.fareast.corp.microsoft.com:49594 failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused`
	============ Response ====================
LogTemplate[1]: `Communication exception: java.net.ConnectException: Call From {server}/{ip_or_url} to {server}.fareast.corp.microsoft.com:{port} failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: {url}`
	============ PostProcess ====================
	Post Template: `Communication exception: java.net.ConnectException: Call From <*> to <*>.fareast.corp.microsoft.com:<*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>`
	============ Aggregate ====================
	Aggregated Template:  Communication exception: java.net.ConnectException: Call From <*> to <*>.fareast.corp.microsoft.com:<*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>
[UpdateBucket] Logs: This iter found: 1, total: 179992/179993, remain: 1. 
[UpdateBucket] Buckets: Checked 1 ([260]), Parent Bucket size: 1 -> 0, remain buckets: 1
Update Success: Time for one update logs: 0.006554126739501953, template `Communication exception: java.net.ConnectException: Call From <*> to <*>.fareast.corp.microsoft.com:<*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>`
========================================================================================


Iteration 258
Sample 3 from current logs bucket: ID: 268, Len: 47, Bucket Size: 1, Total Buckets: 269
	============  Query  ====================
	Log[1]: `Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010 10.86.169.121:50010. Will get new block locations from namenode and retry...`
	============ Response ====================
LogTemplate[1]: `Could not obtain {BP_id}:{blk_id} from any node: java.io.IOException: No live nodes contain block {BP_id}:{blk_id} after checking nodes = [{ip}:50010, {ip}:50010], ignoredNodes = null No live nodes contain current block Block locations: {ip}:50010 {ip}:50010 Dead nodes: {ip}:50010 {ip}:50010 {ip}:50010. Will get new block locations from namenode and retry...`
	============ PostProcess ====================
	Post Template: `Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
	============ Aggregate ====================
	Aggregated Template:  Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...
[UpdateBucket] Logs: This iter found: 1, total: 179993/179993, remain: 0. 
[UpdateBucket] Buckets: Checked 1 ([268]), Parent Bucket size: 1 -> 0, remain buckets: 0
Update Success: Time for one update logs: 0.005956888198852539, template `Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...`
========================================================================================


Original df_logs: (179993, 4), Clustering df_logs: (179993, 6)
Saved Hadoop_log_structured.csv to ./saved_results/LUNAR-single/Hadoop/Hadoop_full.log_structured.csv
Saved Hadoop_log_templates.csv to ./saved_results/LUNAR-single/Hadoop/Hadoop_full.log_templates.csv
Total parsingg time: 334.8801097869873 seconds
Total query time: 308.0070698261261 seconds, 277 queries
Avg. query time: 1.111938840096526 seconds
Total pure match time: 26.873039960861206 seconds

=== Evaluation on Hadoop ===
Evaluate parsing result: ./saved_results/LUNAR-single/Hadoop/Hadoop_full.log_structured.csv
Start compute grouping accuracy
  0%|          | 0/236 [00:00<?, ?it/s] 13%|█▎        | 31/236 [00:00<00:00, 301.32it/s] 26%|██▋       | 62/236 [00:00<00:00, 288.95it/s] 39%|███▊      | 91/236 [00:00<00:00, 282.61it/s] 51%|█████▏    | 121/236 [00:00<00:00, 286.36it/s] 64%|██████▎   | 150/236 [00:00<00:00, 282.79it/s] 76%|███████▌  | 179/236 [00:00<00:00, 278.93it/s] 88%|████████▊ | 208/236 [00:00<00:00, 280.40it/s]100%|██████████| 236/236 [00:00<00:00, 281.66it/s]
Grouping_Accuracy (GA): 0.9410, FGA: 0.9275,
Grouping Accuracy calculation done. [Time taken: 0.909]
Parsing_Accuracy (PA): 0.8399
Parsing Accuracy calculation done. [Time taken: 0.012]
  0%|          | 0/247 [00:00<?, ?it/s]100%|██████████| 247/247 [00:00<00:00, 16719.81it/s]
1-num-951, {'<*> TaskAttempt Transitioned from <*> to <*>'} | {'<*> TaskAttempt Transitioned from NEW to UNASSIGNED'}
2-num-906, {'<*> TaskAttempt Transitioned from <*> to <*>'} | {'<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED'}
3-num-30, {'Abandoning <*>'} | {'Abandoning BP-<*>'}
4-num-138, {'Added filter <*> (class=<*>) to context <*>'} | {'Added filter AM_PROXY_FILTER (class=<*>) to context <*>'}
5-num-5795, {'Address change detected. Old: <*> New: <*>'} | {'Address change detected. Old: msra-sa-41/<*> New: msra-sa-<*>'}
6-num-8, {'Assigned from earlierFailedMaps'} | {'Assigned from <*>'}
7-num-73, {'Assigned to reduce'} | {'Assigned to <*>'}
8-num-472, {'Assigning <*> with <*> to <*>'} | {'Assigning <*> with <*> to fetcher#<*>'}
9-num-8, {'Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:<*>, Priority: <*> Token: Token { kind: <*> service: <*> }, ] to fast fail map'} | {'Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] to fast fail map'}
10-num-962, {'Auth successful for <*> (auth:<*>)'} | {'Auth successful for <*> (auth:SIMPLE)'}
11-num-12, {'Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <*> Priority: <*> Token: <*> ] for a map as either container memory less than required <*> or no pending map tasks - maps.isEmpty=<*>'} | {'Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ] for a map as either container memory less than required <memory:<*>, vCores:1> or no pending map tasks - maps.isEmpty=true'}
12-num-44, {'Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>'} | {'Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: "<*>"; destination host is: "<*>":<*>;'}
13-num-1, {'Communication exception: java.net.ConnectException: Call From <*> to <*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>'} | {'Communication exception: java.net.ConnectException: Call From <*> to <*>.fareast.corp.microsoft.com:<*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: <*>'}
14-num-94, {'Copied to done location: <*>'} | {'Copied to done location: hdfs://<*>/tmp/hadoop-yarn/staging'}
15-num-94, {'Copying <*> to <*>'} | {'Copying hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_1<*> to hdfs://<*>/tmp/hadoop-yarn/staging'}
16-num-216, {'Could not delete <*>'} | {'Could not delete hdfs://<*>'}
17-num-1, {'Could not obtain <*> from any node: <*> No live nodes contain block <*> after checking nodes = <*> ignoredNodes = <*> No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...'} | {'Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [<*>, <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...'}
18-num-5, {'Could not obtain <*> from any node: <*> No live nodes contain block <*> after checking nodes = <*> ignoredNodes = <*> No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...'} | {'Could not obtain BP-<*> from any node: java.io.IOException: No live nodes contain block BP-<*> after checking nodes = [<*>, <*> <*>], ignoredNodes = null No live nodes contain current block Block locations: <*> Dead nodes: <*> Will get new block locations from namenode and retry...'}
19-num-14, {'DFSOutputStream ResponseProcessor exception for block <*>'} | {'DFSOutputStream ResponseProcessor exception for block BP-<*>'}
20-num-226, {'Default file system [<*>]'} | {'Default file system [hdfs://<*>]'}
21-num-45, {'Deleting staging directory <*>'} | {'Deleting staging directory hdfs://<*> <*>/.staging/job_<*>_<*>'}
22-num-4, {'Diagnostics report from <*>: Error: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>'} | {'Diagnostics report from <*>: Error: <*>: <*> from <*> to <*> failed on <*>: <*>; For more details see: <*>'}
23-num-6, {'Diagnostics report from <*>: java.io.IOException: Spill failed'} | {'Diagnostics report from <*>: Error: java.io.IOException: Spill failed'}
24-num-4, {'Diagnostics report from <*>: Error: <*>: error in shuffle in fetcher#<*>'} | {'Diagnostics report from <*>: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>'}
25-num-2, {'Diagnostics report from <*>: Error: <*>: Could not find any valid local directory for <*>'} | {'Diagnostics report from <*>: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_<*>_<*>_<*>'}
26-num-14, {'Error Recovery for block <*> in pipeline <*> <*>: bad datanode <*>'} | {'Error Recovery for block BP-<*> in pipeline <*> <*>: bad datanode <*>'}
27-num-4, {'Error writing History Event: <*>'} | {'Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>'}
28-num-1, {'Exception running child : <*>: Could not find any valid local directory for <*>'} | {'Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for <*>'}
29-num-69, {'Extract jar:<*> to <*>'} | {'Extract jar:file:<*>!/webapps/mapreduce to <*>'}
30-num-5300, {'Failed to renew lease for <*> for <*> seconds. Will retry shortly ...'} | {'Failed to renew lease for [<*>] for <*> seconds. Will retry shortly ...'}
31-num-48, {'History url is <*>'} | {'History url is http://<*>'}
32-num-1, {'IPC Server handler <*> on <*> call statusUpdate(<*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: output error'} | {'IPC Server handler <*> on <*> call statusUpdate(<*>, <*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*> Call#<*> Retry#<*>: <*>'}
33-num-1, {'Ignoring exception during close for <*>'} | {'Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@<*>'}
34-num-2, {'JobHistoryEventHandler notified that forceJobCompletion is <*>'} | {'JobHistoryEventHandler notified that forceJobCompletion is false'}
35-num-50, {'JobHistoryEventHandler notified that forceJobCompletion is <*>'} | {'JobHistoryEventHandler notified that forceJobCompletion is true'}
36-num-69, {'Kind: <*> Service: <*> Ident: (<*>)'} | {'Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)'}
37-num-909, {'Kind: <*> Service: <*> Ident: (<*>)'} | {'Kind: mapreduce.job, Service: <*> Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)'}
38-num-69, {'Logging to <*>(<*>) via <*>'} | {'Logging to org.slf4j.impl.Log4jLoggerAdapter(<*>) via <*>'}
39-num-69, {'MRAppMaster launching normal, non-uberized, multi-container job <*>'} | {'MRAppMaster launching normal, non-uberized, multi-container job <*>.'}
40-num-69, {'<*> metrics system started'} | {'MRAppMaster metrics system started'}
41-num-834, {'Map output collector class = <*>$<*>'} | {'Map output collector class = <*>'}
42-num-302, {'<*> metrics system shutdown complete.'} | {'MapTask metrics system shutdown complete.'}
43-num-838, {'<*> metrics system started'} | {'MapTask metrics system started'}
44-num-302, {'<*> metrics system stopped.'} | {'MapTask metrics system stopped.'}
45-num-141, {'Moved tmp to done: <*>'} | {'Moved tmp to done: hdfs://<*>/tmp/hadoop-yarn/staging'}
46-num-104, {'Notify JHEH isAMLastRetry: <*>', 'Notify RMCommunicator isAMLastRetry: <*>'} | {'Notify <*> isAMLastRetry: <*>'}
47-num-69, {'OutputCommitter is <*>'} | {'OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter'}
48-num-19, {'Previous history file is at <*>'} | {'Previous history file is at hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job_<*>_1.jhist'}
49-num-834, {'Processing split: <*>'} | {'Processing split: hdfs://<*>'}
50-num-838, {'Processing the event EventType: <*> for container <*> taskAttempt <*>'} | {'Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container <*> taskAttempt <*>'}
51-num-906, {'Processing the event EventType: <*> for container <*> taskAttempt <*>'} | {'Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container <*> taskAttempt <*>'}
52-num-69, {'Putting shuffle token in serviceData'} | {'Putting shuffle token in <*>'}
53-num-96, {'Recovering task <*> from prior app attempt, status was <*>'} | {'Recovering task <*> from prior app attempt, status was SUCCEEDED'}
54-num-15, {'<*> metrics system shutdown complete.'} | {'ReduceTask metrics system shutdown complete.'}
55-num-71, {'<*> metrics system started'} | {'ReduceTask metrics system started'}
56-num-15, {'<*> metrics system stopped.'} | {'ReduceTask metrics system stopped.'}
57-num-7, {'Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <*> Priority: <*> Token: <*>]. RM may have assignment issues'} | {'Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:<*>, vCores:1>, Priority: <*> Token: Token <*> }, ]. RM may have assignment issues'}
58-num-1, {'Reporting fetch failure for <*>.'} | {'Reporting fetch failure for <*> to <*>.'}
59-num-47, {'Result of canCommit for <*>'} | {'Result of canCommit for <*>:true'}
60-num-2, {'Service <*> failed in state <*>; cause: <*>: Attempt to process a enum when a union was expected.'} | {'Service <*> failed in state STOPPED; cause: <*>: <*>'}
61-num-69, {'Size of containertokens_dob is <*>'} | {'Size of <*> is <*>'}
62-num-909, {'Sleeping for <*> before retrying again. Got null now.'} | {'Sleeping for <*> before retrying again. Got <*> now.'}
63-num-217, {'Socket Reader <*> for port <*> readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]'} | {'Socket Reader <*> for port <*>: readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]'}
64-num-69, {'Started <*>'} | {'Started HttpServer2$SelectChannelConnectorWithSafeStartup@<*>'}
65-num-302, {'Stopping <*> metrics system...'} | {'Stopping MapTask metrics system...'}
66-num-15, {'Stopping <*> metrics system...'} | {'Stopping ReduceTask metrics system...'}
67-num-6, {'Successfully connected to <*> for <*>'} | {'Successfully connected to <*> for BP-<*>'}
68-num-2, {'Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: <*>'} | {'Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/<*> to msra-sa-<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost'}
69-num-69, {'The job-conf file on the remote FS is <*>'} | {'The job-conf file on the remote FS is <*>/job.xml'}
70-num-69, {'The job-jar file on the remote FS is <*>'} | {'The job-jar file on the remote FS is hdfs://<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>/job.jar'}
71-num-905, {'Using ResourceCalculatorProcessTree : <*>'} | {'Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>'}
72-num-71, {'Using ShuffleConsumerPlugin: <*>'} | {'Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>'}
73-num-138, {'Using callQueue class <*>'} | {'Using callQueue class java.util.concurrent.<*>'}
74-num-69, {'Web app <*> started at <*>'} | {'Web app /mapreduce started at <*>'}
75-num-138, {'adding path spec: <*>'} | {'adding path spec: <*>/*'}
76-num-472, {'assigned <*> of <*> to <*> to fetcher#<*>'} | {'assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>'}
77-num-664, {'fetcher#<*> about to shuffle output of map <*>: <*> len: <*> to DISK'} | {'fetcher#<*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK'}
78-num-469, {'for url=<*> sent hash and received reply'} | {'for url=<*>/mapOutput?job=<*>&reduce=<*>&map=<*> sent hash and received reply'}
79-num-56, {'<*> is deprecated. Instead, use <*>'} | {'mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords'}
80-num-907, {'mapreduce.cluster.local.dir for child: <*>'} | {'mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>'}
81-num-907, {'<*> is deprecated. Instead, use <*>'} | {'session.id is deprecated. Instead, use <*>'}
PTA: 0.6721, RTA: 0.7034 FTA: 0.6874
Identify : 247, Groundtruth : 236
Template-level accuracy calculation done. [Time taken: 0.065]
Finish parsing logs: Hadoop
Output dir: ./saved_results/LUNAR-single
